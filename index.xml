<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tacy - Notes</title>
    <link>http://tacy.github.io/</link>
    <description>Recent content on Tacy - Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 20 Aug 2017 21:38:52 +0800</lastBuildDate>
    
        <atom:link href="http://tacy.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>http://tacy.github.io/about/</link>
      <pubDate>Sun, 20 Aug 2017 21:38:52 +0800</pubDate>
      
      <guid>http://tacy.github.io/about/</guid>
      
        <description>&lt;p&gt;Hugo is a static site engine written in Go.&lt;/p&gt;

&lt;p&gt;It makes use of a variety of open source projects including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/cobra&#34;&gt;Cobra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/viper&#34;&gt;Viper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/jWalterWeatherman&#34;&gt;J Walter Weatherman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/cast&#34;&gt;Cast&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Learn more and contribute on &lt;a href=&#34;https://github.com/gohugoio&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Linux trace</title>
      <link>http://tacy.github.io/post/trace/</link>
      <pubDate>Wed, 02 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/trace/</guid>
      
        <description>

&lt;h1 id=&#34;trace-4-13&#34;&gt;TRACE[^4]&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h1&gt;

&lt;p&gt;linux下的trace，这里只讨论function相关的分析，event和计数器不涉及。从两个维度讨论，首先是根据运行态：分为kernel和userland；其次根据trace方式：分为静态分析和动态分析。&lt;/p&gt;

&lt;h2 id=&#34;kernel&#34;&gt;Kernel&lt;/h2&gt;

&lt;p&gt;kernel空间下，静态分析是指tracepoint，动态分析是指kprobe&lt;/p&gt;

&lt;h3 id=&#34;静态分析&#34;&gt;静态分析&lt;/h3&gt;

&lt;p&gt;是指代码里面已经埋下了探针（probe），可以对这些探针进行分析，没有探针的地方不能trace，探针列表可以通过perf查看：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#sudo perf list tracepoint
...
syscalls:sys_enter_getcpu                          [Tracepoint event]
syscalls:sys_exit_getcpu                           [Tracepoint event]
tcp:tcp_destroy_sock                               [Tracepoint event]
tcp:tcp_probe                                      [Tracepoint event]
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;静态分析有两种方式：ftrace和perf&lt;/p&gt;

&lt;h4 id=&#34;ftrace-7-8&#34;&gt;ftrace&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/h4&gt;

&lt;p&gt;ftrace是linux下的主要trace框架，linux实现了一个tracefs文件系统（类似proc的虚文件系统，驻留在内存），挂载在/sys/kernel/debug/tracing目录下，里面包括所有ftrace相关的内容，ftrace就是通过配置该目录下的文件，完成tracing。&lt;/p&gt;

&lt;p&gt;ftrace里面涉及到静态分析的除了tracepoint之外，另外还有一个部分叫function，分别介绍&lt;/p&gt;

&lt;h5 id=&#34;function&#34;&gt;function&lt;/h5&gt;

&lt;p&gt;traceing目录下，带function字样的文件都和function有关，文件available_filter_functions里面包括了所有能trace的function（在没有添加任何filter的情况下）。如果你需要开启function tracer（更多的tracer，查看文件available_tracers，里面包括了系统支持哪些tracer），只需要执行命令：&lt;code&gt;echo function &amp;gt; current_tracer&lt;/code&gt;，启用之后，你能查看function trace的输出和输出格式定义：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#cat trace|head -10
# tracer: function
#
#                              _-----=&amp;gt; irqs-off
#                             / _----=&amp;gt; need-resched
#                            | / _---=&amp;gt; hardirq/softirq
#                            || / _--=&amp;gt; preempt-depth
#                            ||| /     delay
#           TASK-PID   CPU#  ||||    TIMESTAMP  FUNCTION
#              | |       |   ||||       |         |
           gdbus-1275  [001] .... 11758.901088: unix_poll &amp;lt;-sock_poll
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你查看trace的内容，你会发现内容太多，你很难找到有价值的东西，绝大部分时候，你不是对整个系统的调用感兴趣，你只想看你关心的内容，ftrace提供了function filter来进行trace过滤：通过设置&lt;code&gt;set_ftrace_filter  set_ftrace_notrace  set_ftrace_pid&lt;/code&gt;三个文件，你能过滤需要trace的function。&lt;/p&gt;

&lt;p&gt;最简单的做法是看看available_filter_functions里面有些什么，里面的这些function都是可以用，例如我关心tcp_sendmsg：&lt;code&gt;echo tcp_sendmsg &amp;gt; set_ftrace_filter&lt;/code&gt;，这样function tracer就只会记录tcp_sendmsg这个function。当然filter也支持“*”号通配符，支持三种写法：“*key/&lt;em&gt;key&lt;/em&gt;/key*”。也支持模块过滤“echo :mod:ext3 &amp;gt; set_ftrace_filter”&lt;/p&gt;

&lt;p&gt;另外，filter也支持“Format: &lt;function&gt;:&lt;trigger&gt;[:count]”这类的写法，通过它你能实现：某个function调用了，就tracingoff/tracingon/stacktrace/snapshot/dump/cpudump。例如：&lt;code&gt;echo do_trap:traceoff:3 &amp;gt; set_ftrace_filter&lt;/code&gt;，do_trap调用三次，停止trace。&lt;/p&gt;

&lt;p&gt;如果你需要看到调用栈，可以设置：&lt;code&gt;echo 1 &amp;gt; options/func_stack_trace&lt;/code&gt;，但是必须注意，该操作容易导致问题，务必需要先设置filter，缩小trace范围，否则容易导致系统问题。&lt;/p&gt;

&lt;p&gt;这里主要说一下tracepoint相关内容。tracing目录下有一个events目录，里面就是所有的kernel tracepoint，内容和&lt;code&gt;perf list tracepoint&lt;/code&gt;输出一致，只是这里是目录结构呈现。
trace方法就是找到对应的tracepoint，例如tcp_probe，进入到该目录下（events/tcp/tcp_probe），通过命令&lt;code&gt;echo 1 &amp;gt; enable&lt;/code&gt;激活该探针，然后你就可以回到tracing目录下，查看trace文件内容，里面能看到trace内容，输出格式可以参考探针目录下的format文件。&lt;/p&gt;

&lt;p&gt;另外你也能设置filter，根据条件过滤事件；你也能设置triger，当条件满足的时候，触发定义的action，例如stracktrace，输出栈到trace文件&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tracing]# cat available_filter_functions |grep tcp_sendmsg
bpf_tcp_sendmsg
tcp_sendmsg_locked
tcp_sendmsg
[root@tacyArch tracing]# echo tcp_sendmsg &amp;gt; set_ftrace_filter
[root@tacyArch tracing]# echo function &amp;gt; current_tracer
[root@tacyArch tracing]# cat trace
# tracer: function
#
#                              _-----=&amp;gt; irqs-off
#                             / _----=&amp;gt; need-resched
#                            | / _---=&amp;gt; hardirq/softirq
#                            || / _--=&amp;gt; preempt-depth
#                            ||| /     delay
#           TASK-PID   CPU#  ||||    TIMESTAMP  FUNCTION
#              | |       |   ||||       |         |
           vvv-631   [003] .... 33440.208482: tcp_sendmsg &amp;lt;-sock_sendmsg
  NetworkManager-555   [002] .... 33446.836585: tcp_sendmsg &amp;lt;-sock_sendmsg
            curl-26180 [001] .... 33449.150367: tcp_sendmsg &amp;lt;-sock_sendmsg
           vvv-4083  [002] .... 33456.700836: tcp_sendmsg &amp;lt;-sock_sendmsg

[root@tacyArch tracing]# echo &amp;gt; current_tracer
bash: echo: write error: Invalid argument
[root@tacyArch tracing]# echo nop &amp;gt;current_tracer
[root@tacyArch tracing]# echo &amp;gt; set_ftrace_filter
[root@tacyArch tracing]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;总的来说，function tracer最大的问题就是给出的信息太模糊，有用的信息太少，也无法扩展（你只能enable它）。很多时候，虽然知道function被调用，知道调用的pid和comm，但光有这些信息对于解决问题是不够的。&lt;/p&gt;

&lt;h5 id=&#34;tracepoint&#34;&gt;tracepoint&lt;/h5&gt;

&lt;p&gt;tracing里面的events目录，包含了所有的tracepoint，每一个tracepoint都以目录存在，目录下面是针对该tracepoint的配置文件:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tcp_receive_reset]# ls
enable  filter  format  hist  id  trigger

[root@tacyArch tcp_receive_reset]# cat format
name: tcp_receive_reset
ID: 1133
format:
        field:unsigned short common_type;       offset:0;       size:2; signed:0;
        field:unsigned char common_flags;       offset:2;       size:1; signed:0;
        field:unsigned char common_preempt_count;       offset:3;       size:1; signed:0;
        field:int common_pid;   offset:4;       size:4; signed:1;

        field:const void * skaddr;      offset:8;       size:8; signed:0;
        field:__u16 sport;      offset:16;      size:2; signed:0;
        field:__u16 dport;      offset:18;      size:2; signed:0;
        field:__u8 saddr[4];    offset:20;      size:4; signed:0;
        field:__u8 daddr[4];    offset:24;      size:4; signed:0;
        field:__u8 saddr_v6[16];        offset:28;      size:16;        signed:0;
        field:__u8 daddr_v6[16];        offset:44;      size:16;        signed:0;
        field:__u64 sock_cookie;        offset:64;      size:8; signed:0;

print fmt: &amp;quot;sport=%hu dport=%hu saddr=%pI4 daddr=%pI4 saddrv6=%pI6c daddrv6=%pI6c sock_cookie=%llx&amp;quot;, REC-&amp;gt;sport, REC-&amp;gt;dport, REC-&amp;gt;saddr, REC-&amp;gt;daddr, REC-&amp;gt;saddr_v6, REC-&amp;gt;daddr_v6, REC-&amp;gt;sock_cookie

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;enable文件用来控制开关，filter可以用来做事件过滤，format是tracepoint的输出内容定义，hist做事件统计，id就是tracepoint的标识，trigger可以条件触发action。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tracing]# echo 1 &amp;gt; events/tcp/tcp_receive_reset/enable
[root@tacyArch tracing]# cat trace
# tracer: nop
#
#                              _-----=&amp;gt; irqs-off
#                             / _----=&amp;gt; need-resched
#                            | / _---=&amp;gt; hardirq/softirq
#                            || / _--=&amp;gt; preempt-depth
#                            ||| /     delay
#           TASK-PID   CPU#  ||||    TIMESTAMP  FUNCTION
#              | |       |   ||||       |         |
            curl-26346 [001] .... 33819.317760: tcp_receive_reset: sport=44248 dport=8080 saddr=0.0.0.0 daddr=0.0.0.0 saddrv6=::1 daddrv6=::1 sock_cookie=1
            curl-26346 [001] .... 33819.317892: tcp_receive_reset: sport=49690 dport=8080 saddr=127.0.0.1 daddr=127.0.0.1 saddrv6=::ffff:127.0.0.1 daddrv6=::ffff:127.0.0.1 sock_cookie=2
[root@tacyArch tracing]# echo 0 &amp;gt; events/tcp/tcp_receive_reset/enable
[root@tacyArch tracing]#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的输出更友好，基本上你关心的内容都给你输出了：通过上面内容，你能知道curl从127.0.0.1:8080接收到一个reset包。&lt;/p&gt;

&lt;p&gt;tracepoint能帮助你解决很多问题，当然tracepoint数量有限，有可能你关心的点正好没有，只能等着看新版本的kernel能否提供&lt;/p&gt;

&lt;h4 id=&#34;perf&#34;&gt;perf&lt;/h4&gt;

&lt;p&gt;perf位于kernel源代码的tools下，linux的主要性能分析工具之一，perf提供很多功能，这里我们只谈它和tracepoint有关的部分（perf不能操作ftrace中的function tracer），以tcp_probe这个tracepoint为例，操作也很简单：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch ~]# perf record -e &#39;tcp:tcp_probe&#39; -a
^C[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 1.460 MB perf.data (3 samples) ]

[root@tacyArch ~]# perf script
 irq/69-brcmf_pc 19366 [003] 99975.473448: tcp:tcp_probe: src=192.168.1.21:44404 dest=203.208.xx.xx:443 mark=0 data_len=0 snd_nxt=0x66d5014 snd_una=0x66d5014 snd_cwnd=16 ssthresh=21&amp;gt;
 irq/69-brcmf_pc 19366 [003] 99977.000673: tcp:tcp_probe: src=192.168.1.21:59262 dest=xx.201.xx.119:80 mark=0 data_len=60 snd_nxt=0x6ec6b07d snd_una=0x6ec6b07d snd_cwnd=55 ssthresh&amp;gt;
 irq/69-brcmf_pc 19366 [003] 99977.057786: tcp:tcp_probe: src=192.168.1.21:59262 dest=xx.201.xx.119:80 mark=0 data_len=0 snd_nxt=0x6ec6b0a1 snd_una=0x6ec6b07d snd_cwnd=55 ssthresh=&amp;gt;
[root@tacyArch ~]#

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;动态分析&#34;&gt;动态分析&lt;/h3&gt;

&lt;p&gt;动态分析，当某函数没有预先在代码中埋下探针的时候，系统能够动态给它添加探针的分析方式。在kernel中，这些动态添加的探针也被称为kprobe。kernel把所有的可symbol输出在/proc/kallsyms文件中，你可以对这里面的所有symbol添加探针。kprobe可以说是linux中最牛逼的trace手段。&lt;/p&gt;

&lt;p&gt;动态分析也支持ftrace和perf两种方式。两者的选择：优先选择perf，perf会做错误检验，不容易导致问题，ftrace的话就需要你特别小心，这里可是在kernel层面的操作，一个不小心，系统可能会挂起或者中断。&lt;/p&gt;

&lt;h4 id=&#34;ftrace-6&#34;&gt;ftrace&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/h4&gt;

&lt;p&gt;/proc/kallsyms里面所有的symbol都能添加kprobe，kprobe和function tracer无关，无需启用function tracer。你只需定义好event，写入到kprobe_events即可，ftrace会自动在/sys/kernel/debug/tracing/events下创建kprobe目录，并在该目录下为每个kprobe创建类似tracepoint的目录，之后你只需要通过enable文件来控制启用还是禁用。event的语法如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Synopsis of kprobe_events
-------------------------
  p[:[GRP/]EVENT] [MOD:]SYM[+offs]|MEMADDR [FETCHARGS]	: Set a probe
  r[MAXACTIVE][:[GRP/]EVENT] [MOD:]SYM[+0] [FETCHARGS]	: Set a return probe
  -:[GRP/]EVENT						: Clear a probe

 GRP		: Group name. If omitted, use &amp;quot;kprobes&amp;quot; for it.
 EVENT		: Event name. If omitted, the event name is generated
		  based on SYM+offs or MEMADDR.
 MOD		: Module name which has given SYM.
 SYM[+offs]	: Symbol+offset where the probe is inserted.
 MEMADDR	: Address where the probe is inserted.
 MAXACTIVE	: Maximum number of instances of the specified function that
		  can be probed simultaneously, or 0 for the default value
		  as defined in Documentation/kprobes.txt section 1.3.1.

 FETCHARGS	: Arguments. Each probe can have up to 128 args.
  %REG		: Fetch register REG
  @ADDR		: Fetch memory at ADDR (ADDR should be in kernel)
  @SYM[+|-offs]	: Fetch memory at SYM +|- offs (SYM should be a data symbol)
  $stackN	: Fetch Nth entry of stack (N &amp;gt;= 0)
  $stack	: Fetch stack address.
  $retval	: Fetch return value.(*)
  $comm		: Fetch current task comm.
  +|-offs(FETCHARG) : Fetch memory at FETCHARG +|- offs address.(**)
  NAME=FETCHARG : Set NAME as the argument name of FETCHARG.
  FETCHARG:TYPE : Set TYPE as the type of FETCHARG. Currently, basic types
		  (u8/u16/u32/u64/s8/s16/s32/s64), hexadecimal types
		  (x8/x16/x32/x64), &amp;quot;string&amp;quot; and bitfield are supported.

  (*) only for return probe.
  (**) this is useful for fetching a field of data structures.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们来创建一个event：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tracing]# echo &#39;p:tcp_sendmsg tcp_sendmsg&#39; &amp;gt; /sys/kernel/debug/tracing/kprobe_events
[root@tacyArch tracing]# cat kprobe_events
p:kprobes/tcp_sendmsg tcp_sendmsg
[root@tacyArch tracing]# ls events/kprobes/tcp_sendmsg/
enable  filter  format  hist  id  trigger
[root@tacyArch tracing]# cat events/kprobes/tcp_sendmsg/format
name: tcp_sendmsg
ID: 1638
format:
        field:unsigned short common_type;       offset:0;       size:2; signed:0;
        field:unsigned char common_flags;       offset:2;       size:1; signed:0;
        field:unsigned char common_preempt_count;       offset:3;       size:1; signed:0;
        field:int common_pid;   offset:4;       size:4; signed:1;

        field:unsigned long __probe_ip; offset:8;       size:8; signed:0;

print fmt: &amp;quot;(%lx)&amp;quot;, REC-&amp;gt;__probe_ip

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;定义好之后，启用该probe进行trace（设置enable等于1）:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tracing]# echo 1 &amp;gt; events/kprobes/tcp_sendmsg/enable
[root@tacyArch tracing]# cat trace |head -10
# tracer: nop
#
#                              _-----=&amp;gt; irqs-off
#                             / _----=&amp;gt; need-resched
#                            | / _---=&amp;gt; hardirq/softirq
#                            || / _--=&amp;gt; preempt-depth
#                            ||| /     delay
#           TASK-PID   CPU#  ||||    TIMESTAMP  FUNCTION
#              | |       |   ||||       |         |
            curl-21745 [001] ...1 27996.148112: tcp_sendmsg: (tcp_sendmsg+0x0/0x40)
[root@tacyArch tracing]# echo 0 &amp;gt; events/kprobes/tcp_sendmsg/enable
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看起来和ftrace的function tracer差不多，这就尴尬了？&lt;/p&gt;

&lt;p&gt;继续努力，接下来，我们看看怎么查看调用参数，先看看tcp_sendmsg代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch src]# gdb /lib/modules/4.19.12-arch1-1-ARCH/build/vmlinux
...
For help, type &amp;quot;help&amp;quot;.
Type &amp;quot;apropos word&amp;quot; to search for commands related to &amp;quot;word&amp;quot;...
Reading symbols from /lib/modules/4.19.12-arch1-1-ARCH/build/vmlinux...done.
(gdb) directory /home/tacy/workspace/archlinux-linux/
Source directories searched: /home/tacy/workspace/archlinux-linux:$cdir:$cwd
(gdb) li tcp_sendmsg
1434            return err;
1435    }
1436    EXPORT_SYMBOL_GPL(tcp_sendmsg_locked);
1437
1438    int tcp_sendmsg(struct sock *sk, struct msghdr *msg, size_t size)
1439    {
1440            int ret;
1441
1442            lock_sock(sk);
1443            ret = tcp_sendmsg_locked(sk, msg, size);

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;tcp_sendmsg有3个调用参数，我们希望能看到发送包的大小：size，第三个参数的寄存器使用的是rdx（参考System V ABI AMD64&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;，找到每个register定义），我们重新定义一个probe，覆盖之前的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tracing]# echo &#39;probe:tcp_sendmsg tcp_sendmsg size=%dx&#39; &amp;gt; kprobe_events
[root@tacyArch tracing]# cat events/kprobes/tcp_sendmsg/format
name: tcp_sendmsg
ID: 1639
format:
        field:unsigned short common_type;       offset:0;       size:2; signed:0;
        field:unsigned char common_flags;       offset:2;       size:1; signed:0;
        field:unsigned char common_preempt_count;       offset:3;       size:1; signed:0;
        field:int common_pid;   offset:4;       size:4; signed:1;

        field:unsigned long __probe_ip; offset:8;       size:8; signed:0;
        field:u64 size; offset:16;      size:8; signed:0;

print fmt: &amp;quot;(%lx) size=0x%Lx&amp;quot;, REC-&amp;gt;__probe_ip, REC-&amp;gt;size
[root@tacyArch tracing]# echo 1 &amp;gt; events/kprobes/tcp_sendmsg/enable
[root@tacyArch tracing]# cat trace
# tracer: nop
#
#                              _-----=&amp;gt; irqs-off
#                             / _----=&amp;gt; need-resched
#                            | / _---=&amp;gt; hardirq/softirq
#                            || / _--=&amp;gt; preempt-depth
#                            ||| /     delay
#           TASK-PID   CPU#  ||||    TIMESTAMP  FUNCTION
#              | |       |   ||||       |         |
            curl-22314 [000] ...1 29227.292645: tcp_sendmsg: (tcp_sendmsg+0x0/0x40) size=0x4c
[root@tacyArch tracing]# echo 0 &amp;gt; events/kprobes/tcp_sendmsg/enable
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;干的不错，能看到包大小了，能不能继续进一步，看看socket信息呢？&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;(gdb) print (int)&amp;amp;((struct sock *)0)-&amp;gt;__sk_common
$1 = 0
(gdb) print (int)&amp;amp;((struct sock_common *)0)-&amp;gt;skc_daddr
$2 = 0
(gdb) print (int)&amp;amp;((struct sock_common *)0)-&amp;gt;skc_rcv_saddr
$3 = 4
(gdb) print (int)&amp;amp;((struct sock_common *)0)-&amp;gt;skc_dport
$4 = 12
(gdb) print (int)&amp;amp;((struct sock_common *)0)-&amp;gt;skc_num
$5 = 14
[root@tacyArch tracing]# echo &#39;probe:tcp_sendmsg tcp_sendmsg dst=+0(%di):x32 dport=+12(%di):x16 src=+4(%di):x32 sport=+14(%di):x16 size=%dx&#39; &amp;gt; kprobe_events
[root@tacyArch tracing]# echo 1 &amp;gt; events/kprobes/tcp_sendmsg/enable
[root@tacyArch tracing]# tail -2 trace
            curl-25876 [001] ...1 37339.320598: tcp_sendmsg: (tcp_sendmsg+0x0/0x40) dst=0x64e959ca dport=0x5000 src=0x670aa8c0 sport=0xa4f0 size=0x4c
            curl-25878 [000] ...1 37340.118164: tcp_sendmsg: (tcp_sendmsg+0x0/0x40) dst=0x64e959ca dport=0x5000 src=0x670aa8c0 sport=0xa4f2 size=0x4c
[root@tacyArch tracing]# echo 0 &amp;gt; events/kprobes/tcp_sendmsg/enable
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个就厉害啦，少年，有没有跃跃欲试的感觉，还不赶紧操练一下去（写个脚本把地址转换一下呗）！&lt;/p&gt;

&lt;p&gt;总结一下就是，终于寻得屠龙宝刀在手。。。唯一的遗憾就是不能做复杂程序处理。&lt;/p&gt;

&lt;h4 id=&#34;perf-1&#34;&gt;perf&lt;/h4&gt;

&lt;p&gt;首先需要说明的是，perf无法操作ftrace里面的function tracer，它只能定义和操作kprobe（当然也可以定义uprobe，后面会有描述），perf-probe其实操作的也是/sys/kernel/debug/tracing/kprobe_event。但是通过perf-probe定义probe的好处就是会有校验，不容易出错&lt;/p&gt;

&lt;p&gt;还是以tcp_sendmsg为例，添加和使用probe的方式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch ~]#perf probe --add tcp_sendmsg  // 无参数版本
Added new event:
  probe:tcp_sendmsg    (on tcp_sendmsg)

You can now use it in all perf tools, such as:

        perf record -e probe:tcp_sendmsg -aR sleep 1


[root@tacyArch ~]# perf probe --list
  probe:tcp_sendmsg    (on tcp_sendmsg@net/ipv4/tcp.c)

[root@tacyArch ~]# perf probe -d probe:tcp_sendmsg  //删除

[root@tacyArch tracing]# perf probe &#39;tcp_sendmsg tcp_sendmsg dst=+0(%di):x32 dport=+12(%di):x16 src=+4(%di):x32 sport=+14(%di):x16 size=%dx&#39;  //有参数

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;有了probe之后，你就可以对该probe进行trace操作了，操作方法和静态分析中的perf类似&lt;/p&gt;

&lt;p&gt;如果你的kernel安装了debug info，perf能更简单的定义probe，同样上面显示socket信息的tcp_sendmsg，如果有debuginfo，你不用去找寄存器和偏移，直接使用变量名：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tracing]# perf probe &#39;tcp_sendmsg size sk-&amp;gt;__sk_common.skc_daddr sk-&amp;gt;__sk_common.skc_dport sk-&amp;gt;__sk_common.skc_rcv_saddr sk-&amp;gt;__sk_common.skc_num&#39;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外，在有debuginfo的情况下，你可以不借助gdb，直接用perf查看代码和变量：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# perf probe -L tcp_sendmsg:0+10   # 查看tcp_sendmsg代码0~10行，如果你的源文件放在自己目录里面，通过-x参数指定
&amp;lt;tcp_sendmsg@/home/tacy/workspace/archlinux-linux/net/ipv4/tcp.c:0&amp;gt;
      0  int tcp_sendmsg(struct sock *sk, struct msghdr *msg, size_t size)
      1  {
      2         int ret;

      4         lock_sock(sk);
      5         ret = tcp_sendmsg_locked(sk, msg, size);
      6         release_sock(sk);

      8         return ret;
      9  }
         EXPORT_SYMBOL(tcp_sendmsg);

         /*

# perf probe -V tcp_sendmsg        # 查看tcp_sendmsg参数
Available variables at tcp_sendmsg
        @&amp;lt;tcp_sendmsg+0&amp;gt;
                int     ret
                size_t  size
                struct msghdr*  msg
                struct sock*    sk

# perf probe --add &#39;tcp_sendmsg size&#39;  # 使用tcp_sendmsg参数，输出到结果中
# perf probe -V tcp_sendmsg:+9  # 可以查看函数内部变量，内部变量也能输出
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;userland&#34;&gt;userland&lt;/h2&gt;

&lt;p&gt;usersland的trace同样包括静态和动态两部分，但是这两部分我们也统一称为uprobe&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;，你可以在ftrace目录（/sys/kernel/debug/tracing）下的uprobe_events文件中找到你定义的所有uprobe event。&lt;/p&gt;

&lt;p&gt;uprobe event定义：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Synopsis of uprobe_tracer
-------------------------
  p[:[GRP/]EVENT] PATH:OFFSET [FETCHARGS] : Set a uprobe
  r[:[GRP/]EVENT] PATH:OFFSET [FETCHARGS] : Set a return uprobe (uretprobe)
  -:[GRP/]EVENT                           : Clear uprobe or uretprobe event

  GRP           : Group name. If omitted, &amp;quot;uprobes&amp;quot; is the default value.
  EVENT         : Event name. If omitted, the event name is generated based
                  on PATH+OFFSET.
  PATH          : Path to an executable or a library.
  OFFSET        : Offset where the probe is inserted.

  FETCHARGS     : Arguments. Each probe can have up to 128 args.
   %REG         : Fetch register REG
   @ADDR	: Fetch memory at ADDR (ADDR should be in userspace)
   @+OFFSET	: Fetch memory at OFFSET (OFFSET from same file as PATH)
   $stackN	: Fetch Nth entry of stack (N &amp;gt;= 0)
   $stack	: Fetch stack address.
   $retval	: Fetch return value.(*)
   $comm	: Fetch current task comm.
   +|-offs(FETCHARG) : Fetch memory at FETCHARG +|- offs address.(**)
   NAME=FETCHARG     : Set NAME as the argument name of FETCHARG.
   FETCHARG:TYPE     : Set TYPE as the type of FETCHARG. Currently, basic types
		       (u8/u16/u32/u64/s8/s16/s32/s64), hexadecimal types
		       (x8/x16/x32/x64), &amp;quot;string&amp;quot; and bitfield are supported.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;静态分析-1&#34;&gt;静态分析&lt;/h3&gt;

&lt;p&gt;一般称为USDT Probe，需要预先在代码中加探针（开发人员可以参考&lt;a href=&#34;https://www.sourceware.org/systemtap/wiki/AddingUserSpaceProbingToApps&#34;&gt;Adding User Space Probing to an Application&lt;/a&gt;，学习如何在代码里面埋探针），这类探针技术也叫DTRACE，来源于Solaris，很多软件支持，但是需要在编译时启用，例如java，就需要在编译时启用enable-dtrace编译参数(启用dtrace编译需要依赖systemtap-sdt-dev包，至少jdk编译需要）&lt;/p&gt;

&lt;p&gt;同样，我们也可以通过ftrace和perf两种方式操作它。但是ftrace操作方法复杂（主要是需要小心操作地址），方法参考&lt;a href=&#34;http://www.brendangregg.com/blog/2015-07-03/hacking-linux-usdt-ftrace.html&#34;&gt;Hacking Linux USDT with Ftrace&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;下面我们用openjdk为例，说明用户空间的静态分析方法。首先需要你的JDK启用了enable-dtrace，其次启动java应用的时候加上参数&lt;code&gt;-XX:+ExtendedDTraceProbes&lt;/code&gt;，查看USDT probe：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;readelf -n /usr/lib/jvm/java-10-openjdk/lib/server/libjvm.so
Displaying notes found in: .note.gnu.build-id
  Owner                 Data size       Description
  GNU                  0x00000014       NT_GNU_BUILD_ID (unique build ID bitstring)
    Build ID: deaa14871e0101bc717a00461519385ebdb010fd

Displaying notes found in: .note.stapsdt
  Owner                 Data size       Description
  stapsdt              0x0000004d       NT_STAPSDT (SystemTap probe descriptors)
    Provider: hotspot
    Name: class__loaded
    Location: 0x00000000005b5d7a, Base: 0x0000000000dbb1b2, Semaphore: 0x0000000000000000
    Arguments: 8@%r13 -4@%r14d 8@%rax 1@%r12b
  stapsdt              0x0000004c       NT_STAPSDT (SystemTap probe descriptors)
    Provider: hotspot
    Name: class__unloaded
    Location: 0x00000000005b5f11, Base: 0x0000000000dbb1b2, Semaphore: 0x0000000000000000
    Arguments: 8@%rbx -4@%r13d 8@%rax 1@$0
  stapsdt              0x00000071       NT_STAPSDT (SystemTap probe descriptors)
    Provider: hotspot
    Name: method__compile__begin

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;确保出处中有stapsdt字样&lt;/p&gt;

&lt;h4 id=&#34;ftrace&#34;&gt;ftrace&lt;/h4&gt;

&lt;p&gt;我们用method&lt;strong&gt;entry为例，操作如何通过ftrace来trace该probe。参考前面uprobe event的定义&lt;code&gt;p[:[GRP/]EVENT] PATH:OFFSET [FETCHARGS] : Set a uprobe&lt;/code&gt;，我们需要找到method&lt;/strong&gt;entry在libjvm.so中的位置，可以通过readelf找到：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tacy]# readelf -n /usr/lib/jvm/java-10-openjdk/lib/server/libjvm.so |tail +2659 -|head -5 -
  stapsdt              0x00000062       NT_STAPSDT (SystemTap probe descriptors)
    Provider: hotspot
    Name: method__entry
    Location: 0x0000000000bd21e5, Base: 0x0000000000dbb1b2, Semaphore: 0x0000000000000000
    Arguments: -8@%rax 8@%rdx -4@%ecx 8@%rsi -4@%edi 8@%r8 -4@%r9d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;method__entry的位置在0x0000000000bd21e5，应为libjvm.so是一个共享库，所以这个地址可以直接使用（如果非共享库，你还需要找到程序的base加载地址，location-base得到偏移）。&lt;/p&gt;

&lt;p&gt;readelf的输出中，可以看到method__entry的arguments，总共有7个（这里我也没搞明白为啥register的使用不用遵守System V ABI AMD64规范），具体每个参数的定义就需要去看代码了，我机器上找不到stp文件，只能看在线&lt;a href=&#34;https://github.com/mpujari/systemtap-tapset-openjdk9/blob/master/tapset-1.8.0/hotspot-1.8.0.stp.in#L411&#34;&gt;stp&lt;/a&gt;，引用在下面：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/* hotspot.method_entry (extended probe)
   Triggers when a method is entered.
   Sets thread_id to the current java thread id, class to the name of
   the class, method to the name of the method, and sig to the
   signature string of the method.
   Needs -XX:+ExtendedDTraceProbes.
*/
probe hotspot.method_entry =
  process(&amp;quot;@ABS_CLIENT_LIBJVM_SO@&amp;quot;).mark(&amp;quot;method__entry&amp;quot;),
  process(&amp;quot;@ABS_SERVER_LIBJVM_SO@&amp;quot;).mark(&amp;quot;method__entry&amp;quot;)
{
  name = &amp;quot;method_entry&amp;quot;;
  thread_id = $arg1;
  class = user_string_n($arg2, $arg3);
  method = user_string_n($arg4, $arg5);
  sig = user_string_n($arg6, $arg7);
  probestr = sprintf(&amp;quot;%s(thread_id=%d,class=&#39;%s&#39;,method=&#39;%s&#39;,sig=&#39;%s&#39;)&amp;quot;,
		     name, thread_id, class, method, sig);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;大致搞清楚每个参数的定义：arg1是线程id，arge2看起来里面包含了classname，arg3是classname的长度，依次类推，下面我们就可以来定义probe了：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tacy]# echo &#39;p:uprobes/method_entry /usr/lib/jvm/java-10-openjdk/lib/server/libjvm.so:0x0000000000bd21e5 arg1=%ax:s64 arg2=+0(%dx):string arg3=%cx:s32 arg4=+0(%si):string arg5=%di:s32 arg6=+0(%r8):string arg7=%r9:s32&#39; &amp;gt; uprobe_events
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;搞定，可以测试一下效果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tracing]# echo 1 &amp;gt;events/uprobes/method_entry/enable
[root@tacyArch tracing]# echo 0 &amp;gt;events/uprobes/method_entry/enable
[root@tacyArch tracing]# cat trace|grep hello
 http-nio-8080-e-31172 [003] d... 51704.118354: method_entry: (0x7f80e000d1e5) arg1=24 arg2=&amp;quot;hello/Greeting&amp;lt;init&amp;gt;(JLjava/lang/String;)V&amp;quot; arg3=14 arg4=&amp;quot;&amp;lt;init&amp;gt;(JLjava/lang/String;)V&amp;quot; arg5=6 arg6=&amp;quot;(JLjava/lang/String;)V&amp;quot; arg7=22
 http-nio-8080-e-31172 [003] d... 51704.134194: method_entry: (0x7f80e000d1e5) arg1=24 arg2=&amp;quot;hello/GreetinggetId()J&amp;quot; arg3=14 arg4=&amp;quot;getId()J&amp;quot; arg5=5 arg6=&amp;quot;()J&amp;quot; arg7=3
 http-nio-8080-e-31172 [003] d... 51704.134229: method_entry: (0x7f80e000d1e5) arg1=24 arg2=&amp;quot;hello/GreetinggetContent&amp;amp;()Ljava/lang/String;&amp;quot; arg3=14 arg4=&amp;quot;getContent&amp;amp;()Ljava/lang/String;&amp;quot; arg5=10 arg6=&amp;quot;()Ljava/lang/String;&amp;quot; arg7=20
 http-nio-8080-e-31173 [002] d... 51704.628421: method_entry: (0x7f80e000d1e5) arg1=25 arg2=&amp;quot;hello/GreetinggetId()J&amp;quot; arg3=14 arg4=&amp;quot;getId()J&amp;quot; arg5=5 arg6=&amp;quot;()J&amp;quot; arg7=3
 http-nio-8080-e-31173 [002] d... 51704.628476: method_entry: (0x7f80e000d1e5) arg1=25 arg2=&amp;quot;hello/GreetinggetContent&amp;amp;()Ljava/lang/String;&amp;quot; arg3=14 arg4=&amp;quot;getContent&amp;amp;()Ljava/lang/String;&amp;quot; arg5=10 arg6=&amp;quot;()Ljava/lang/String;&amp;quot; arg7=20
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面我们用grep来过滤我们想看到的class，其实不用这么麻烦，参考events的filter，你可以直接过滤掉你不想看到的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tracing]# echo &#39;arg2 ~ &amp;quot;hello*&amp;quot;&#39; &amp;gt; events/uprobes/method_entry/filter
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;牛，java的方法调用一览无遗，用这个来profile method响应时间，不用对应用做任何调整，想想都觉得不可思议（如果你需要获取每个method的调用时间，你需要定义一个return probe，参考uprobe event定义）&lt;/p&gt;

&lt;h4 id=&#34;perf-2&#34;&gt;perf&lt;/h4&gt;

&lt;p&gt;方法参考&lt;a href=&#34;http://www.brendangregg.com/perf.html#StaticUserTracing&#34;&gt;Static User Tracing&lt;/a&gt;，我简单描述一下jdk实现&lt;/p&gt;

&lt;p&gt;为了perf能操作USDT Probe，需要把它添加到perf buildcache：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/****************** sdt需要先添加到perf里面：**************/
/* 注意，perf操作sdt，建议切换到root运行，否则可能出一些奇怪问题，例如无法添加sdt到probe */
[root@tacyArch tracing]# perf buildid-cache --add /usr/lib/jvm/java-10-openjdk/lib/server/libjvm.so

[root@tacyArch tracing]# perf list sdt

List of pre-defined events (to be used in -e):

  sdt_hotspot:class__initialization__clinit          [SDT event]
  sdt_hotspot:class__initialization__concurrent      [SDT event]
  sdt_hotspot:class__initialization__end             [SDT event]
  sdt_hotspot:class__initialization__erroneous       [SDT event]
  sdt_hotspot:class__initialization__error           [SDT event]
  sdt_hotspot:class__initialization__recursive       [SDT event]
  sdt_hotspot:class__initialization__required        [SDT event]
  sdt_hotspot:class__initialization__super__failed   [SDT event]
  sdt_hotspot:class__loaded                          [SDT event]
  sdt_hotspot:class__unloaded                        [SDT event]
  sdt_hotspot:compiled__method__load                 [SDT event]
  sdt_hotspot:compiled__method__unload               [SDT event]
  sdt_hotspot:gc__begin                              [SDT event]
  sdt_hotspot:gc__end                                [SDT event]
  sdt_hotspot:mem__pool__gc__begin                   [SDT event]
  sdt_hotspot:mem__pool__gc__end                     [SDT event]
  sdt_hotspot:method__compile__begin                 [SDT event]
  sdt_hotspot:method__compile__end                   [SDT event]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;添加到buildcache之后，你才能用他们定义uprobe，执行trace操作，下面用gc&lt;strong&gt;begin示例（method&lt;/strong&gt;entry获取参数方法和ftrace一致，只是不需要去找offset）：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tacy]# perf probe --add sdt_hotspot:gc__begin                                                                                                                 [20/1846]
Added new events:
  sdt_hotspot:gc__begin (on %gc__begin in /usr/lib/jvm/java-10-openjdk/lib/server/libjvm.so)
  sdt_hotspot:gc__begin_1 (on %gc__begin in /usr/lib/jvm/java-10-openjdk/lib/server/libjvm.so)
  sdt_hotspot:gc__begin_2 (on %gc__begin in /usr/lib/jvm/java-10-openjdk/lib/server/libjvm.so)
  sdt_hotspot:gc__begin_3 (on %gc__begin in /usr/lib/jvm/java-10-openjdk/lib/server/libjvm.so)

You can now use it in all perf tools, such as:

        perf record -e sdt_hotspot:gc__begin_3 -aR sleep 1


[root@tacyArch tacy]# perf record -e &#39;sdt_hotspot:gc__begin,sdt_hotspot:gc__begin_1,sdt_hotspot:gc__begin_2,sdt_hotspot:gc__begin_3&#39; -a

^C[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 1.706 MB perf.data (11 samples) ]

[root@tacyArch tacy]# perf script
       VM Thread  7050 [000] 97761.385404: sdt_hotspot:gc__begin_2: (7f2cebede940) arg1=0
       VM Thread  6178 [000] 97762.596125: sdt_hotspot:gc__begin_2: (7f5430da5940) arg1=0
       VM Thread  6178 [003] 97762.863885: sdt_hotspot:gc__begin_2: (7f5430da5940) arg1=0
       VM Thread  6178 [002] 97763.374132: sdt_hotspot:gc__begin_3: (7f5430da5e31)
       VM Thread  6178 [002] 97763.374145: sdt_hotspot:gc__begin_2: (7f5430da5940) arg1=0
       VM Thread  6178 [002] 97763.388108: sdt_hotspot:gc__begin_2: (7f5430da5940) arg1=0
       VM Thread  6178 [001] 97764.320487: sdt_hotspot:gc__begin_2: (7f5430da5940) arg1=0
       VM Thread  6178 [000] 97765.442266: sdt_hotspot:gc__begin_3: (7f5430da5e31)
       VM Thread  6178 [000] 97765.442274: sdt_hotspot:gc__begin_2: (7f5430da5940) arg1=0
       VM Thread  6178 [001] 97765.462569: sdt_hotspot:gc__begin_2: (7f5430da5940) arg1=0
       VM Thread  6178 [002] 97766.663314: sdt_hotspot:gc__begin_2: (7f5430da5940) arg1=0

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;动态分析-1&#34;&gt;动态分析&lt;/h3&gt;

&lt;p&gt;动态添加uprobe和操作USDT probe差不多，简单说一下perf的方法&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@tacyArch tracing]# perf probe -x /lib64/libc.so.6 -F|grep malloc|head -10
cache_malloced
malloc
malloc_check
malloc_consolidate
malloc_get_state@GLIBC_2.2.5
malloc_hook_ini
malloc_info
malloc_init_state
malloc_printerr
malloc_set_state@GLIBC_2.2.5

[root@tacyArch tracing]# perf probe -x /lib64/libc.so.6 malloc
Added new event:
  probe_libc:malloc    (on malloc in /usr/lib/libc-2.28.so)

You can now use it in all perf tools, such as:

        perf record -e probe_libc:malloc -aR sleep 1

[root@tacyArch tracing]# cd
[root@tacyArch ~]# perf record -e probe_libc:malloc -a
^C[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 1.900 MB perf.data (3349 samples) ]

[root@tacyArch ~]# perf script |head -10
     soffice.bin   312 [001] 53221.883430: probe_libc:malloc: (7f2503f9a8d0)
     soffice.bin   312 [001] 53221.883453: probe_libc:malloc: (7f2503f9a8d0)
            java 30971 [003] 53221.941838: probe_libc:malloc: (7f3682e238d0)
            java 30971 [003] 53221.941875: probe_libc:malloc: (7f3682e238d0)
            java 30971 [003] 53221.941887: probe_libc:malloc: (7f3682e238d0)
            java 30971 [003] 53221.966116: probe_libc:malloc: (7f3682e238d0)
            java 30971 [003] 53221.966164: probe_libc:malloc: (7f3682e238d0)
            java 30971 [003] 53221.966260: probe_libc:malloc: (7f3682e238d0)
            java 30971 [003] 53221.966272: probe_libc:malloc: (7f3682e238d0)
     soffice.bin   312 [001] 53221.983791: probe_libc:malloc: (7f2503f9a8d0)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;上面介绍的内容，操作起来有一定复杂度，大牛Brendan Gregg提供了&lt;a href=&#34;https://github.com/brendangregg/perf-tools&#34;&gt;perf-tools&lt;/a&gt;工具集来简化操作，里面提供了很多非常实用的工具，大力推荐。另外大牛的&lt;a href=&#34;http://www.brendangregg.com/blog/2015-07-03/hacking-linux-usdt-ftrace.html&#34;&gt;blog&lt;/a&gt;建议反复阅读&lt;/p&gt;

&lt;p&gt;ftrace最大的问题是不可编程，无法做更多扩展，但是它不需要太新的kernel，对目前很多生产环境来说，这非常关键，而且ftrace也在持续改进，建议follow大牛@srostedt（kernel ftrace maintainer）。&lt;/p&gt;

&lt;p&gt;至于目前最热门的ebpf/bcc&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;，强烈建议学习，优点就是一句话：可编程。kernel至少都需要4.1（推荐4.8以上），RHEL7.6官方已经支持&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h2 id=&#34;相关知识&#34;&gt;相关知识&lt;/h2&gt;

&lt;h3 id=&#34;assambly-gdb&#34;&gt;assambly &amp;amp; gdb&lt;/h3&gt;

&lt;h3 id=&#34;dynamic-symbol-static-symbol&#34;&gt;dynamic symbol / static symbol&lt;/h3&gt;

&lt;p&gt;dynamic symbol是指动态链接的程序对外依赖的共享库symbol，程序运行时必须。static symbol这个需要编译时打开&lt;code&gt;-g&lt;/code&gt;开关才能看到，调试用&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:13&#34;&gt;&lt;a href=&#34;http://www.brendangregg.com/blog/2015-07-08/choosing-a-linux-tracer.html&#34;&gt;Choosing a Linux Tracer (2015)&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:13&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/trace/ftrace.txt&#34;&gt;ftrace document&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:7&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:8&#34;&gt;&lt;a href=&#34;https://lwn.net/Articles/370423/&#34;&gt;Secrets of the Ftrace function tracer&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:8&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/trace/kprobetrace.txt&#34;&gt;kprobe trace&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:6&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:9&#34;&gt;&lt;a href=&#34;http://cs.lmu.edu/~ray/notes/nasmtutorial/&#34;&gt;NASM Tutorial&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:9&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:10&#34;&gt;&lt;a href=&#34;https://github.com/hjl-tools/x86-psABI/wiki/x86-64-psABI-1.0.pdf&#34;&gt;X86 psABI&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:10&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/trace/uprobetracer.txt&#34;&gt;uprobe tracer&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:12&#34;&gt;&lt;a href=&#34;https://github.com/iovisor/bcc/blob/master/INSTALL.md&#34;&gt;iovisor bcc&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:12&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:11&#34;&gt;&lt;a href=&#34;https://github.com/iovisor/bcc/blob/master/INSTALL.md&#34;&gt;bcc install&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:11&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
      
    </item>
    
    <item>
      <title>ceph notes</title>
      <link>http://tacy.github.io/post/ceph/</link>
      <pubDate>Wed, 08 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/ceph/</guid>
      
        <description>

&lt;h1 id=&#34;ceph重要的概念&#34;&gt;ceph重要的概念&lt;/h1&gt;

&lt;p&gt;ceph底层是RADOS(A reliable, autonomous, distributed object storage), RADOS由OSD和MON组成, 是ceph核心.
  - OSD: Object Storage Device
  - MON: 维护整个ceph集群的全局状态(cluster map)&lt;/p&gt;

&lt;p&gt;另一个核心概念是CRUSH, ceph没有中心控制节点, 通过CRUSH算法结合MON维护的cluster map, 能够计算出任意对象的存储位置.&lt;/p&gt;

&lt;p&gt;Object
Pool
Placement Group
OSD
MON&lt;/p&gt;

&lt;h1 id=&#34;crush&#34;&gt;CRUSH&lt;/h1&gt;

&lt;p&gt;CRUSH是用来确定数据存储位置的算法, client利用CRUSH获得了直接和OSD交互的能力, ceph通过CRUSH实现了去中心化的架构, 避免了中心节点带来的SPOF, 性能瓶颈和物理限制, 实现了理论上的无限扩展能力.&lt;/p&gt;

&lt;h1 id=&#34;pg&#34;&gt;PG&lt;/h1&gt;

&lt;p&gt;每个Pool都有自己的PG个数定义, 在Pool创建之后, PG的个数就无法更改.&lt;/p&gt;

&lt;p&gt;首先需要了解的是, PG越多, 数据越分散, 推荐的计算方法:&lt;/p&gt;

&lt;p&gt;(N * 10) / R&lt;/p&gt;

&lt;p&gt;N代表OSD的个数, R代表副本数()&lt;/p&gt;

&lt;p&gt;PG状态&lt;/p&gt;

&lt;h1 id=&#34;实施建议&#34;&gt;实施建议&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;单个Host上的OSD不能太多,理论上你可以挂载到硬件上限, 但是需要考虑到当Host失败的时候, 会带来巨大的迁移流量和长的恢复时间.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;client&#34;&gt;client&lt;/h1&gt;

&lt;p&gt;当client需要写入文件到cluster中时, 首先从MON获取cluster map副本, 然后根据CRUSH算法获得PG id, 找到PG所属OSD set的Primary OSD(第一个), 之后client往该OSD写入数据, 副本由Primary OSD负责写入. 该写入操作完成需要等所有数据落盘(好像是写入journal就算完成?), 然后Primary OSD 返回ACK到client, 完成写入操作.&lt;/p&gt;

&lt;p&gt;当然其实前面还有事情要做, 先要把文件按照object大小切分成多个object, 然后每个object会存入到不同的PG.&lt;/p&gt;

&lt;h1 id=&#34;ceph性能相关&#34;&gt;ceph性能相关&lt;/h1&gt;

&lt;h2 id=&#34;写相关&#34;&gt;写相关&lt;/h2&gt;

&lt;h3 id=&#34;一次写入产生的数据量&#34;&gt;一次写入产生的数据量&lt;/h3&gt;

&lt;p&gt;1M数据写入3副本集群, 会产生6.4M左右的数据, 其中包括:
  - journal三份
  - data三份(含副本)
  - PG log
总计下来大概是6.4M左右&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>l2tp ipsec in linode</title>
      <link>http://tacy.github.io/post/l2tp-ipsec-in-linode/</link>
      <pubDate>Wed, 24 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/l2tp-ipsec-in-linode/</guid>
      
        <description>

&lt;p&gt;我参考的配置帖子: &lt;a href=&#34;https://raymii.org/s/tutorials/IPSEC_L2TP_vpn_with_Ubuntu_14.04.html&#34;&gt;https://raymii.org/s/tutorials/IPSEC_L2TP_vpn_with_Ubuntu_14.04.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;先注意下面问题:&lt;/p&gt;

&lt;h1 id=&#34;two-or-more-interfaces-found-checking-ip-forwarding-failed&#34;&gt;Two or more interfaces found, checking IP forwarding Failed&lt;/h1&gt;

&lt;p&gt;我的环境是: My Ubuntu 14.04 LTS Profile (Latest 64 bit (3.16.7-x86_64-linode49))&lt;/p&gt;

&lt;p&gt;如果已经配置了ip_forward, 没啥好说的, 直接升级openswan吧, ppa在这里:&lt;a href=&#34;https://launchpad.net/~openswan/+archive/ubuntu/ppa&#34;&gt;https://launchpad.net/~openswan/+archive/ubuntu/ppa&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;如果你用的是和我一样的配置, 那么先添加上面的ppa(貌似12.04没有上面的问题)&lt;/p&gt;

&lt;p&gt;然后按照下面的步骤操作:&lt;/p&gt;

&lt;h1 id=&#34;安装软件包&#34;&gt;安装软件包&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;apt-get update
apt-get install openswan xl2tpd ppp lsof
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;配置网络环境&#34;&gt;配置网络环境&lt;/h1&gt;

&lt;p&gt;配置IP转发禁用ICP重定向&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;echo &amp;quot;net.ipv4.ip_forward = 1&amp;quot; |  tee -a /etc/sysctl.conf
echo &amp;quot;net.ipv4.conf.all.accept_redirects = 0&amp;quot; |  tee -a /etc/sysctl.conf
echo &amp;quot;net.ipv4.conf.all.send_redirects = 0&amp;quot; |  tee -a /etc/sysctl.conf
echo &amp;quot;net.ipv4.conf.default.rp_filter = 0&amp;quot; |  tee -a /etc/sysctl.conf
echo &amp;quot;net.ipv4.conf.default.accept_source_route = 0&amp;quot; |  tee -a /etc/sysctl.conf
echo &amp;quot;net.ipv4.conf.default.send_redirects = 0&amp;quot; |  tee -a /etc/sysctl.conf
echo &amp;quot;net.ipv4.icmp_ignore_bogus_error_responses = 1&amp;quot; |  tee -a /etc/sysctl.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其他网卡也来一遍:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;for vpn in /proc/sys/net/ipv4/conf/*; do echo 0 &amp;gt; $vpn/accept_redirects; echo 0 &amp;gt; $vpn/send_redirects; done
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;最好让上面配置生效:&lt;/dt&gt;
&lt;dd&gt;sysctl -p&lt;/dd&gt;
&lt;dt&gt;配置iptables nat规则:&lt;/dt&gt;
&lt;dd&gt;iptables -t nat -A POSTROUTING -j SNAT &amp;ndash;to-source YOUR_PUBLIC_IP -o eth0&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;上面两条会在重启之后丢失, 为了让他们重启能生效, 放到rc.local里面(注意下面内容添加到 exit 0 这行前面):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;for vpn in /proc/sys/net/ipv4/conf/*; do echo 0 &amp;gt; $vpn/accept_redirects; echo 0 &amp;gt; $vpn/send_redirects; done

iptables -t nat -A POSTROUTING -j SNAT --to-source YOUR_PUBLIC_IP -o eth0

&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;配置openswan-ipsec&#34;&gt;配置Openswan(IPSEC)&lt;/h1&gt;

&lt;p&gt;修改/etc/ipsec.conf文件, 用下面内容替换:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;version 2 # conforms to second version of ipsec.conf specification

config setup
    dumpdir=/var/run/pluto/
    #in what directory should things started by setup (notably the Pluto daemon) be allowed to dump core?

    nat_traversal=yes
    #whether to accept/offer to support NAT (NAPT, also known as &amp;quot;IP Masqurade&amp;quot;) workaround for IPsec

    virtual_private=%v4:10.0.0.0/8,%v4:192.168.0.0/16,%v4:172.16.0.0/12,%v6:fd00::/8,%v6:fe80::/10
    #contains the networks that are allowed as subnet= for the remote client. In other words, the address ranges that may live behind a NAT router through which a client connects.

    protostack=netkey
    #decide which protocol stack is going to be used.

    force_keepalive=yes
    keep_alive=60
    # Send a keep-alive packet every 60 seconds.

conn L2TP-PSK-noNAT
    authby=secret
    #shared secret. Use rsasig for certificates.

    pfs=no
    #Disable pfs

    auto=add
    #the ipsec tunnel should be started and routes created when the ipsec daemon itself starts.

    keyingtries=3
    #Only negotiate a conn. 3 times.

    ikelifetime=8h
    keylife=1h

    ike=aes256-sha1,aes128-sha1,3des-sha1
    phase2alg=aes256-sha1,aes128-sha1,3des-sha1
    # https://lists.openswan.org/pipermail/users/2014-April/022947.html
    # specifies the phase 1 encryption scheme, the hashing algorithm, and the diffie-hellman group. The modp1024 is for Diffie-Hellman 2. Why &#39;modp&#39; instead of dh? DH2 is a 1028 bit encryption algorithm that modulo&#39;s a prime number, e.g. modp1028. See RFC 5114 for details or the wiki page on diffie hellmann, if interested.

    type=transport
    #because we use l2tp as tunnel protocol

    left=YOUR_PUBLIC_IP
    #fill in server IP above

    leftprotoport=17/1701
    right=%any
    rightprotoport=17/%any

    dpddelay=10
    # Dead Peer Dectection (RFC 3706) keepalives delay
    dpdtimeout=20
    #  length of time (in seconds) we will idle without hearing either an R_U_THERE poll from our peer, or an R_U_THERE_ACK reply.
    dpdaction=clear
    # When a DPD enabled peer is declared dead, what action should be taken. clear means the eroute and SA with both be cleared.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意把YOUR_PUBLIC_IP替换成你的服务器ip地址.&lt;/p&gt;

&lt;p&gt;设置你的shared secret:&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;编辑/etc/ipsec.secrets文件, 添加下面行:&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;YOUR_PUBLIC_IP %any: PSK &amp;ldquo;yousharedsecret&amp;rdquo;&lt;/p&gt;&lt;/dd&gt;
&lt;dt&gt;重启ipsec服务:&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;service ipsec restart&lt;/p&gt;&lt;/dd&gt;
&lt;dt&gt;验证配置:&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;ipsec verify&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;你应该看到下面输出:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Checking if IPsec got installed and started correctly:

Version check and ipsec on-path                   	[OK]
Openswan U2.6.42/K3.16.7-x86_64-linode49 (netkey)
See `ipsec --copyright&#39; for copyright information.
Checking for IPsec support in kernel              	[OK]
 NETKEY: Testing XFRM related proc values
         ICMP default/send_redirects              	[OK]
         ICMP default/accept_redirects            	[OK]
         XFRM larval drop                         	[OK]
Hardware random device check                      	[N/A]
Two or more interfaces found, checking IP forwarding	[OK]
Checking rp_filter                                	[ENABLED]
 /proc/sys/net/ipv4/conf/all/rp_filter            	[ENABLED]
Checking that pluto is running                    	[OK]
 Pluto listening for IKE on udp 500               	[OK]
 Pluto listening for IKE on tcp 500               	[NOT IMPLEMENTED]
 Pluto listening for IKE/NAT-T on udp 4500        	[OK]
 Pluto listening for IKE/NAT-T on tcp 4500        	[NOT IMPLEMENTED]
 Pluto listening for IKE on tcp 10000 (cisco)     	[NOT IMPLEMENTED]
Checking NAT and MASQUERADEing                    	[TEST INCOMPLETE]
Checking &#39;ip&#39; command                             	[OK]
Checking &#39;iptables&#39; command                       	[OK]
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;配置xl2tpd&#34;&gt;配置xl2tpd&lt;/h1&gt;

&lt;p&gt;编辑xl2tpd配置文件/etc/xl2tpd/xl2tpd.conf, 用下面内容替换:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[global]
ipsec saref = yes
saref refinfo = 30

;debug avp = yes
;debug network = yes
;debug state = yes
;debug tunnel = yes

[lns default]
ip range = 172.16.1.30-172.16.1.100
local ip = 172.16.1.1
refuse pap = yes
require authentication = yes
;ppp debug = yes
pppoptfile = /etc/ppp/options.xl2tpd
length bit = yes
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;配置ppp&#34;&gt;配置PPP&lt;/h1&gt;

&lt;p&gt;编辑ppp配置文件/etc/ppp/options.xl2tpd, 用下面内容替换, 如果该配置文件不存在, 手动创建它&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;require-mschap-v2
ms-dns 8.8.8.8
ms-dns 8.8.4.4
auth
mtu 1200
mru 1000
crtscts
hide-password
modem
name l2tpd
proxyarp
lcp-echo-interval 30
lcp-echo-failure 4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意其中的mtu和mru别随便改动, 我调到1400网络性能急剧下降, 分析了一下, 很多包重发现象, 当然如果你熟悉sniffer, 可以自己调整一下, 估计1300什么的应该是可以的.&lt;/p&gt;

&lt;p&gt;添加用户, 在/etc/ppp/chap-secrets文件中填加用户:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Secrets for authentication using CHAP
# client       server  secret                  IP addresses
alice          l2tpd   0F92E5FC2414101EA            *
bob            l2tpd   DF98F09F74C06A2F             *
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面就是你未来客户端拨号用的账户信息&lt;/p&gt;

&lt;p&gt;现在重启ipsec和xl2tpd服务:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;service ipsec restart
/etc/init.d/xl2tpd restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置完成了&lt;/p&gt;

&lt;h1 id=&#34;客户端配置&#34;&gt;客户端配置&lt;/h1&gt;

&lt;p&gt;我用的是ubuntu 12.04 , 直接用network-manager-l2tp插件就行. 至于其他的客户端, 直接google吧&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>本地KVM环境运行Kubernetes集群</title>
      <link>http://tacy.github.io/post/%E6%9C%AC%E5%9C%B0kvm%E7%8E%AF%E5%A2%83%E8%BF%90%E8%A1%8Ckubernetes%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Mon, 24 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/%E6%9C%AC%E5%9C%B0kvm%E7%8E%AF%E5%A2%83%E8%BF%90%E8%A1%8Ckubernetes%E9%9B%86%E7%BE%A4/</guid>
      
        <description>

&lt;p&gt;Kubernetes(后面简称为K8S)作为目前热门的容器集群管理软件, 很多人都希望能一探究竟, 但是它的文档大部分都是运行在IaaS平台之上, 对于没有IaaS环境的人来说, 还是有一定门槛, 这篇文章的目的就是让你能在自己的机器上搭建一个K8S集群.&lt;/p&gt;

&lt;p&gt;这里我采用的方式Kelsey Hightower提供的: [[&lt;a href=&#34;https://github.com/kelseyhightower/kubernetes-fleet-tutorial][Elastic&#34;&gt;https://github.com/kelseyhightower/kubernetes-fleet-tutorial][Elastic&lt;/a&gt; Kubernetes cluster with fleet and flannel]], 建议你先看看链接里的项目, 有一个大概的了解.&lt;/p&gt;

&lt;p&gt;主要用到的技术栈包括:
- KVM 底层虚拟化平台
- OpenVSwitch 虚拟交换机(取代bridge)
- CoreOS 轻量级的操作系统, 和Docker天然集成, 独特的升级机制(和Google Chrome一样[fn:1], 不是一个一个包升级, 而是Core的完整升级, 这样能保证整个环境的一致性)
- Fleet CoreOS管理集群管理工具, 就是一个配置管理工具, 当然只支持CoreOS, 类比的工具就是Chef/SaltStack一类的东西
- Flannel CoreOS提供的overlay网络软件, 为K8S提供网络服务
- Etcd  CoreOS提供的配置共享/服务发现的软件
- K8S Google开源的容器集群管理软件&lt;/p&gt;

&lt;p&gt;要完成整个配置, 你需要有一台至少8G RAM的机器, 少点估计也行, 但是建议还是多点, 毕竟要完成整个测试, 你需要有至少4个虚拟机, 如果需要跑监控的话 ,4G是打不住的.&lt;/p&gt;

&lt;p&gt;首先我们需要准备好的是我们的底层虚拟化环境, 其实没有想象的那么麻烦, 配置还是比较方便的.&lt;/p&gt;

&lt;h1 id=&#34;虚拟化环境准备&#34;&gt;虚拟化环境准备&lt;/h1&gt;

&lt;p&gt;我们这里测试机器用的是操作系统是Ubuntu 14.04, 最小安装即可, 配置好SSH, 如果你没有物理机, 也可以用虚拟机代替, 没啥影响, 保证虚拟机网络通就行.&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;安装虚拟化支持软件:&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;apt-get install qemu-kvm openvswitch-switch&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;配置OpenVSwitch&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;
$cat /etc/network/interface
auto ovsbr0
iface ovsbr0 inet static
   address 172.16.11.1
   network 172.16.11.0
   netmask 255.255.255.0
   broadcast 172.16.11.255

$ovs-vsctl add-br ovsbr0

$cat /etc/openvswitch/ovs-ifup
#!/bin/sh
switch=&#39;ovsbr0&#39;
/sbin/ifconfig $1 0.0.0.0 up
ovs-vsctl add-port ${switch} $1

$cat /etc/openvswitch/ovs-ifdown
#!/bin/sh
switch=&#39;ovsbr0&#39;
/sbin/ifconfig $1 0.0.0.0 down
ovs-vsctl del-port ${switch} $1

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;添加一个bridge ,然后添加到OVS里面, 同时编写两个脚本, 后面KVM命令行启动虚拟机要用到.&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;完成之后, 配置机器路由转发功能, 首先打开转发功能, 编辑/etc/sysctl.conf, 打开ip_forward=1那一行, 同时让配置生效:&lt;/dt&gt;
&lt;dd&gt;sysctl -p&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;配置iptables:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;iptables -I FORWARD -j ACCEPT
iptables -t nat -A POSTROUTING -s 172.16.11.0/24 ! -d 172.168.11.0/24 -j MASQUERADE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对所有172.16.11.0/24网段出去的流量做NAT, 同时转发所有的包. 这里只是测试环境, 所以我打开了所有包的转发, 当然你也能细粒度控制包转发.&lt;/p&gt;

&lt;p&gt;完成上面两步只后, 你还需要有一个dhcp server, 为你创建的虚拟机提供DHCP服务, 可以用dnsmasq这个软件来完成.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$apt-get install dnsmasq-base

$cat resolv.dnsmasq.conf
# Google&#39;s nameservers, for example
nameserver 8.8.8.8
nameserver 8.8.4.4

$dnsmasq --bind-interfaces --listen-address 172.16.11.1 --dhcp-range 172.16.11.100,172.16.11.200 --resolv-file=/home/tacy/coreos/config/resolv.dnsmasq.conf --dhcp-boot=pxelinux.0,roo,172.16.11.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样, 一个基本的虚拟化环境就差不多了.&lt;/p&gt;

&lt;h1 id=&#34;配置etcd&#34;&gt;配置etcd&lt;/h1&gt;

&lt;p&gt;这里需要简单介绍一下CoreOS这个操作系统, 不像其他传统的Linux发行版本, 他没有包管理机制, 只包括核心的一些软件, 升级操作是原子的, 不存在不一致问题.&lt;/p&gt;

&lt;p&gt;当运行系统检测到CoreOS有升级包的时候, 他会根据你选定的升级策略, 自动下载升级包更新, 但是他不会更新你当前正在运行的根分区(/usr被mount为只读), 因为他存在两个根分区, Active/Passive, 他升级的是Passive这个分区, 重启的时候, 切换Passive成为Active, 完成升级操作.&lt;/p&gt;

&lt;p&gt;CoreOS和Docker无缝集成, 预安装Docker, 如果你需要在CoreOS里面跑其他诊断工具, 比如tcpdump, 他通过创建一个fedora container来完成[fn:2].&lt;/p&gt;

&lt;p&gt;CoreOS采用Systemd做服务管理, Systemd也是目前热门的服务管理工具, 不远的将来会替换SysV和Upstart, 好处就是服务并行启动和好的依赖设计. 结合Cloud-Config, 解决CoreOS系统的预配置工作, 不依赖其他配置管理工具, 比如Chef等.&lt;/p&gt;

&lt;p&gt;同时CoreOS提供Fleet管理工具来管理CoreOS集群, Fleet通过发布Systemd Unit到集群成员, 实现服务配置.&lt;/p&gt;

&lt;p&gt;当然, CoreOS的整个体系中, 我们将要配置的Etcd无疑是最重要的一个, Etcd负责配置管理和服务发现, 是CoreOS的核心. K8S也用Etcd.&lt;/p&gt;

&lt;p&gt;介绍完了CoreOS, 我们来看怎么配置一个运行Etcd service的CoreOS.&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;Kelsey Hightower已经帮你编写好了Cloud-Config文件, 你需要先Clone一下上面提到的项目.&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;git clone &lt;a href=&#34;https://github.com/kelseyhightower/kubernetes-fleet-tutorial.git&#34;&gt;https://github.com/kelseyhightower/kubernetes-fleet-tutorial.git&lt;/a&gt;&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;找到config目录下的etcd.yml文件, 根据你的实际情况, 修改里面的ip地址信息, 我测试环境用的是172.16.11.10, 做相应修改, 同时吧ssh_authorized_keys替换成你的的公钥. 另外需要特别注意的是, 这里的网卡名称需要修改一下, 不是eno16777736, 改成eth0.&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;然后我们还需要下载一个CoreOS的KVM image. 去 [[&lt;a href=&#34;https://coreos.com/docs/running-coreos/platforms/qemu/][这里]&#34;&gt;https://coreos.com/docs/running-coreos/platforms/qemu/][这里]&lt;/a&gt;] 下载:&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;wget &lt;a href=&#34;http://stable.release.core-os.net/amd64-usr/current/coreos_production_qemu_image.img.bz2&#34;&gt;http://stable.release.core-os.net/amd64-usr/current/coreos_production_qemu_image.img.bz2&lt;/a&gt; -O - | bzcat &amp;gt; coreos_production_qemu_image.img&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;准备好之后, 我们就可以来启动一个etcd服务的CoreOS虚拟机了. 由于我们需要使用Cloud-Config文件启动, 你需要把配置文件放置到一个特定的位置, 我们先创建一个目录:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$mkdir -p tmp/openstack/latest
$cp etcd.yml tmp/openstack/latest/user_data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是把我们修改好的etcd.yml文件更名为user_data, 放置到/tmp/openstack/lastest目录下, 目录名的后两层不能修改, tmp可以任意. 这样CoreOS才能找到配置文件.&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;现在可以启动etcd server了, 在启动之前, 我们还做最后一步工作, 用coreos_production_qemu_image.img做base image, 建立一个新的img文件来写入etcd server的修改:&lt;/dt&gt;
&lt;dd&gt;$qemu-img create -f qcow2 -b ../template/coreos.img etcd.img&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;这里我重命名coreos_production_qemu_image.img为coreos.img, 启动etcd server:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$kvm -m 2048 -smp 2 \
-drive file=../images/etcd.img,if=virtio,cache=none,aio=native \
-fsdev local,id=conf,security_model=none,readonly,path=../config/etcd \
-device virtio-9p-pci,fsdev=conf,mount_tag=config-2 \
-net nic,vlan=0,model=virtio,macaddr=52:54:00:24:93:29\
-net tap,vlan=0,vhost=on,script=/etc/openvswitch/ovs-ifup,downscript=/etc/openvswitch/ovs-ifdown \
-nographic -serial file:../logs/etcd.log
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我的目录结构如下, Cloud-Config文件统一放到config目录, images下面存放虚拟机镜像, 虚拟机启动日志存放到logs目录:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;|-coreos
   |---bin
   |---config
   |-----etcd
   |-------openstack
   |---------latest
   |-----node
   |-------openstack
   |---------latest
   |---example
   |-----guestbook
   |---images
   |---logs
   |---temp
   |---template
   |---tools
   |---units
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;好了, 现在你的etcd server就配置好了,  当然你还需要配置两个环境变量:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ export ETCDCTL_PEERS=http://172.16.11.10:4001
$ export FLEETCTL_ENDPOINT=http://172.16.11.10:4001
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;同时在etcd创建flannel网络节点:&lt;/dt&gt;
&lt;dd&gt;$etcdctl mk /coreos.com/network/config &amp;lsquo;{&amp;ldquo;Network&amp;rdquo;:&amp;ldquo;10.0.0.0/16&amp;rdquo;}&amp;rsquo;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;用fleetctl验证一下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@momo1:~/coreos$ fleetctl list-machines
MACHINE         IP              METADATA
6a6e4c00...     172.16.11.10    role=etcd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在你可以继续配置其他虚拟机节点了, 这些节点用来运行K8S&lt;/p&gt;

&lt;h1 id=&#34;配置其他node&#34;&gt;配置其他Node&lt;/h1&gt;

&lt;dl&gt;
&lt;dt&gt;同样你需要基于coreos.img创建相应的img, 修改node.yml配置文件, 修正etcd server地址, 同时注意, node.yml里面的K8S下载用的是Google的云存储空间, 国内访问不了, 而且版本也是老的, 建议自己下载最新版本, 放置到本地, 如果你没有相关服务, 也可以临时用下面命令应急:&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;$python -m SimpleHTTPServer&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;配置完成之后验证一下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@momo1:~/kubernetes/server/kubernetes/server/bin$ fleetctl list-machines
MACHINE         IP              METADATA
127d44a9...     172.16.11.165   role=kubernetes
6a6e4c00...     172.16.11.10    role=etcd
7b0826fb...     172.16.11.132   role=kubernetes
bb8edb08...     172.16.11.178   role=kubernetes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到我这里创建了3个节点, 创建节点相关工作比较繁琐, 我写了一个脚本来完成:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@momo1:~/coreos/bin$ cat microcloud.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import random
import pickle
import argparse
import subprocess

parser = argparse.ArgumentParser(description=&#39;MicroCloud Ctl&#39;)

parser.add_argument(&#39;-i&#39;,
                    &#39;--image&#39;,
                    help=&#39;kvm node name&#39;,
                    required = True)
parser.add_argument(&#39;-c&#39;,
                    &#39;--clouddriver&#39;,
                    help=&#39;cloud config driver directory&#39;,
                    required = True)

args = parser.parse_args()
img = args.image
cdf = args.clouddriver

pypath = os.path.dirname(os.path.abspath(__file__))
node = img.split(&#39;/&#39;)[-1]
macaddrfile = &#39;{0}/../config/macaddr.list&#39;.format(pypath)
if not os.path.isfile(macaddrfile):
    with open(macaddrfile, &#39;wb+&#39;) as fd:
        pickle.dump({}, fd)
macs = {}
with open(macaddrfile, &#39;rb+&#39;) as fd:
    macs = pickle.load(fd)
mac = &#39;&#39;
if node in macs:
    mac = macs[node]
else:
    rands = [ 0x52, 0x54, 0x00,
              random.randint(0x00, 0x7f),
              random.randint(0x00, 0xff),
              random.randint(0x00, 0xff) ]
    mac = &#39;:&#39;.join(map(lambda x: &amp;quot;%02x&amp;quot; % x, rands))
    macs[node] = mac
    with open(macaddrfile, &#39;wb+&#39;) as fd:
        pickle.dump(macs, fd)

args = [&#39;qemu-system-x86_64&#39;, &#39;-enable-kvm&#39;,
        &#39;-m&#39;, &#39;2048&#39;,
        &#39;-smp&#39;, &#39;2&#39;,
        &#39;-drive&#39;, &#39;file={0},if=virtio,cache=none,aio=native&#39;.format(img),
        &#39;-fsdev&#39;, &#39;local,id=conf,security_model=none,readonly,path={0}&#39;.format(cdf),
        &#39;-device&#39;, &#39;virtio-9p-pci,fsdev=conf,mount_tag=config-2&#39;,
        &#39;-net&#39;, &#39;nic,vlan=0,model=virtio,macaddr={0}&#39;.format(mac),
        &#39;-net&#39;, &#39;tap,vlan=0,vhost=on,script=/etc/openvswitch/ovs-ifup,downscript=/etc/openvswitch/ovs-ifdown&#39;,
        &#39;-nographic&#39;,
        &#39;-serial&#39;, &#39;file:{0}/../logs/{1}.log&#39;.format(pypath, node)]

#os.execv(&#39;/usr/bin/qemu-system-x86_64&#39;, args)
process = subprocess.Popen([&#39;/usr/bin/qemu-system-x86_64&#39;] + args[1:],
                 stdout=subprocess.PIPE, stderr=subprocess.PIPE)
#stdout, stderr = process.communicate()
#print stdout, stderr
print process.returncode
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;有了这个脚本之后, 新建一个节点只需要创建一下img, 然后运行这个脚本就行了.&lt;/p&gt;

&lt;h1 id=&#34;通过fleet部署k8s&#34;&gt;通过fleet部署K8S&lt;/h1&gt;

&lt;p&gt;CoreOS部署好之后, 你现在可以用fleet完成K8S的部署, 使用Kelsey Hightower提供的units, 直接用下面命令完成部署:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ fleetctl start kube-proxy.service
$ fleetctl start kube-kubelet.service
$ fleetctl start kube-apiserver.service
$ fleetctl start kube-scheduler.service
$ fleetctl start kube-controller-manager.service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同样的问题, 这里下载地址都是Google存储, 国内无法访问, 而且版本也是老的, 建议自己下载最新版本和配置下载地址.&lt;/p&gt;

&lt;p&gt;完成之后, 你就有了一个本地运行的K8S集群.&lt;/p&gt;

&lt;p&gt;需要特别注意的是, 由于K8S是一个快速变化的项目, 很多信息容易过期, 建议去关注项目的Issue列表, 由于0.5版本的K8S里面的服务重新设计, Kelsey Hightower文档中相关信息就不对, 注意看CoreOS的日志.&lt;/p&gt;

&lt;p&gt;现在可以去部署Guestbook这个例子了.&lt;/p&gt;

&lt;h1 id=&#34;部署guestbook&#34;&gt;部署Guestbook&lt;/h1&gt;

&lt;p&gt;直接下载最新发布的K8S版本, 解压缩之后里面有example/guestbook目录, 这就是我们需要部署的例子, guestbook部署包括一个redis master, 2个redis slave和3个web节点.&lt;/p&gt;

&lt;p&gt;部署起来也和很简单, 直接通过kubectl工具即可完成:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl create -f redis-master.json
kubectl create -f redis-master-service.json
kubectl create -f redis-slave-controller.json
kubectl create -f redis-slave-service.json
kubectl create -f frontend-controller.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看看结果:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@momo1:~$ kubectl get pods
NAME                                   IMAGE(S)                   HOST                LABELS                                       STATUS
8f85c3e8-7481-11e4-8c27-52540015fd4a   brendanburns/redis-slave   172.16.11.132/      name=redisslave,uses=redis-master            Running
8f85ff95-7481-11e4-8c27-52540015fd4a   brendanburns/redis-slave   172.16.11.165/      name=redisslave,uses=redis-master            Running
4229efd3-751b-11e4-8c27-52540015fd4a   brendanburns/php-redis     172.16.11.132/      name=frontend,uses=redisslave,redis-master   Running
422ac57d-751b-11e4-8c27-52540015fd4a   brendanburns/php-redis     172.16.11.178/      name=frontend,uses=redisslave,redis-master   Running
422bd487-751b-11e4-8c27-52540015fd4a   brendanburns/php-redis     172.16.11.165/      name=frontend,uses=redisslave,redis-master   Running
redis-master                           dockerfile/redis           172.16.11.165/      name=redis-master                            Running
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就把guestbook部署完成了. 你在宿主机上可以直接通过80端口访问&lt;/p&gt;

&lt;h1 id=&#34;部署监控&#34;&gt;部署监控&lt;/h1&gt;

&lt;p&gt;K8S的监控可以用cAdvisor + heapster + Influxdb + Grafana来实现. 下面我们来说说怎么去部署这样一个方案&lt;/p&gt;

&lt;p&gt;首先需要做的是在每一个minions上运行cAdvisor作为一个Pod, 可以通过[[&lt;a href=&#34;https://github.com/GoogleCloudPlatform/kubernetes/blob/master/cluster/saltbase/salt/cadvisor/cadvisor.manifest#L1][static&#34;&gt;https://github.com/GoogleCloudPlatform/kubernetes/blob/master/cluster/saltbase/salt/cadvisor/cadvisor.manifest#L1][static&lt;/a&gt; manifest file]]来实现, 我们这里需要修改一下node节点的&lt;/p&gt;

&lt;h1 id=&#34;k8s存在的问题&#34;&gt;K8S存在的问题&lt;/h1&gt;

&lt;h2 id=&#34;服务对外暴露问题&#34;&gt;服务对外暴露问题&lt;/h2&gt;

&lt;p&gt;对于服务的对外暴露问题, service提供的是一个虚的地址, 这对于内部路由没有问题(kube-proxy+iptables), 但是对于需要对外暴露的服务, 比如guestbook里面的web服务, 就没有很好的办法了(在GCE上是有办法解决的, 会判断service的createExternalLoadBalancer属性, 建立LB)&lt;/p&gt;

&lt;p&gt;相关Issue: [[&lt;a href=&#34;https://github.com/GoogleCloudPlatform/kubernetes/issues/1161][#1161]&#34;&gt;https://github.com/GoogleCloudPlatform/kubernetes/issues/1161][#1161]&lt;/a&gt;]&lt;/p&gt;

&lt;h2 id=&#34;服务注入问题&#34;&gt;服务注入问题&lt;/h2&gt;

&lt;p&gt;需要解决Cluster内部Pod依赖外部服务问题, 比如集群间, 不同命名空间, 数据库等,&lt;/p&gt;

&lt;p&gt;相关Issue: [[&lt;a href=&#34;https://github.com/GoogleCloudPlatform/kubernetes/issues/1542][#1542]&#34;&gt;https://github.com/GoogleCloudPlatform/kubernetes/issues/1542][#1542]&lt;/a&gt;], [[&lt;a href=&#34;https://github.com/GoogleCloudPlatform/kubernetes/issues/260][#260]&#34;&gt;https://github.com/GoogleCloudPlatform/kubernetes/issues/260][#260]&lt;/a&gt;], [[&lt;a href=&#34;https://github.com/GoogleCloudPlatform/kubernetes/issues/2358][#2358]&#34;&gt;https://github.com/GoogleCloudPlatform/kubernetes/issues/2358][#2358]&lt;/a&gt;]&lt;/p&gt;

&lt;h2 id=&#34;持久化数据问题&#34;&gt;持久化数据问题&lt;/h2&gt;

&lt;p&gt;相关Issue: [[&lt;a href=&#34;https://github.com/GoogleCloudPlatform/kubernetes/pull/1515][#1515]&#34;&gt;https://github.com/GoogleCloudPlatform/kubernetes/pull/1515][#1515]&lt;/a&gt;]&lt;/p&gt;

&lt;h1 id=&#34;部署中碰到的问题&#34;&gt;部署中碰到的问题&lt;/h1&gt;

&lt;h2 id=&#34;etcd&#34;&gt;etcd&lt;/h2&gt;

&lt;p&gt;etcd 0.5之前的版本使用的go-raft实现有问题, 会导致etcd起不来. 0.5版本之后, etcd实现了自己版本的raft, 解决了该问题, 建议用0.5之后的版本.&lt;/p&gt;

&lt;h2 id=&#34;fleetctl&#34;&gt;fleetctl&lt;/h2&gt;

&lt;p&gt;fleetctl确实非常方便, 但是也有一些问题, 参考这里[fn:3][fn:4], 对于服务的管理还有bug, 期待更稳定&lt;/p&gt;

&lt;h2 id=&#34;kube-register&#34;&gt;kube-register&lt;/h2&gt;

&lt;p&gt;老版本有bug, 会有too much open files问题, 需要自己编译&lt;/p&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;https://code.google.com/p/omaha/][Google&#34;&gt;https://code.google.com/p/omaha/][Google&lt;/a&gt; Omaha]]&lt;/p&gt;

&lt;p&gt;[fn:2] [[&lt;a href=&#34;https://coreos.com/docs/cluster-management/debugging/install-debugging-tools/][Install&#34;&gt;https://coreos.com/docs/cluster-management/debugging/install-debugging-tools/][Install&lt;/a&gt; Debugging Tools]]&lt;/p&gt;

&lt;p&gt;[fn:3] [[&lt;a href=&#34;https://github.com/coreos/fleet/issues/914][How&#34;&gt;https://github.com/coreos/fleet/issues/914][How&lt;/a&gt; to update unit?]]&lt;/p&gt;

&lt;p&gt;[fn:4] [[&lt;a href=&#34;https://github.com/coreos/fleet/pull/866][fleet&#34;&gt;https://github.com/coreos/fleet/pull/866][fleet&lt;/a&gt; agent does not compare contents of units in reconciler]]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>在本地kvm环节下使用cloud image</title>
      <link>http://tacy.github.io/post/cloud-init/</link>
      <pubDate>Fri, 07 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/cloud-init/</guid>
      
        <description>

&lt;h1 id=&#34;在本地kvm环境下使用cloud-image&#34;&gt;在本地kvm环境下使用cloud image&lt;/h1&gt;

&lt;p&gt;大量的cloud image, 其实在本地虚拟环境也能使用, 这里简单介绍一下在我本机kvm环境下使用cloud image的步骤&lt;/p&gt;

&lt;p&gt;这里用的是openvswitch做网络环境配置&lt;/p&gt;

&lt;h2 id=&#34;配置openvswitch-kvm&#34;&gt;配置openvswitch+kvm&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;
apt-get install qemu-kvm openvswitch-switch

vi /etc/network/interface
auto ovsbr0
iface ovsbr0 inet static
   address 172.16.11.1
   network 172.16.11.0
   netmask 255.255.255.0
   broadcast 172.16.11.255

ovs-vsctl add-br ovsbr0

/etc/openvswitch/ovs-ifup
#!/bin/sh
switch=&#39;ovsbr0&#39;
/sbin/ifconfig $1 0.0.0.0 up
ovs-vsctl add-port ${switch} $1

/etc/openvswitch/ovs-ifdown
#!/bin/sh
switch=&#39;ovsbr0&#39;
/sbin/ifconfig $1 0.0.0.0 down
ovs-vsctl del-port ${switch} $1

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;配置ubuntu-cloud-image&#34;&gt;配置ubuntu cloud image&lt;/h2&gt;

&lt;p&gt;去[[&lt;a href=&#34;https://cloud-images.ubuntu.com/releases/14.04.1/release/][Ubuntu网站]&#34;&gt;https://cloud-images.ubuntu.com/releases/14.04.1/release/][Ubuntu网站]&lt;/a&gt;] 下载相对应的image, 我这里用的是1404做测试:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@momo1:~/$ wget https://cloud-images.ubuntu.com/releases/14.04.1/release/ubuntu-14.04-server-cloudimg-amd64-disk1.img

tacy@momo1:~/$ tar zxvf ubuntu-14.04-server-cloudimg-amd64-disk1.img
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;这是一个已经安装好的ubunt 14.04镜像, 文件格式是qcow2, 磁盘空间大小是2.2G, 可以用qemu-img resize.&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;tacy@momo1:~/$ qemu-img resize ubuntu-14.04-server-cloudimg-amd64-disk1.img +8g&lt;/p&gt;&lt;/dd&gt;
&lt;dt&gt;然后我们做一个快照, 用它来启动虚拟机&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;tacy@momo1:~/$ qemu-img create -f qcow2 -b ubuntu-14.04-server-cloudimg-amd64-disk1.img node01.img&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;准备好image, 现在我们来配置本地的cloud init, 让cloud image能启动起来, 也很简单, 建立下面两个文件:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@momo1:~/$ mkdir metadata &amp;amp;&amp;amp; cd metadata
tacy@momo1:~/metadata$ cat meta-data
instance-id: iid-local01
local-hostname: cloudimg
network-interfaces: |
  auto eth0
  iface eth0 inet static
  address 172.16.11.100
  network 172.16.11.0
  netmask 255.255.255.0
  broadcast 172.16.11.255
  gateway 172.16.11.1

tacy@momo1:~/metadata$ cat user-data
#cloud-config
#password: passw0rd
#chpasswd: { expire: False }
#ssh_pwauth: True
ssh_authorized_keys:
  - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCUtDcwkNskzigh0rjirK/BoualyOiuZoBLMpK03MHBUPh/wHgoiSGOUoSGY7RMcVclKECqCQjyv3WN6vJnDwjQ1mEiXFKntnWqqJYZsDETttDfxYwPmV2sA5UBfSFDUuBhmLYVsJg/T9NUf/K/aO8RI2Q7M09Xds6hfilO1rR59h/8/d3fbj8QG/DBnEFe6HxQj7OX5RGPbL/dT9OlLdDLhRf6rPHFHVy7PKTU1SfzIsL89v9MXkAcet+zb5UJcuifSMIQQhSv8MhhWscZibkXQi1btqxNgoxIVguW57fghR7wpVUn6oAHiCnz3KY34N8Nv1UodY6kk4idUmQ0oJiZ xx@xx

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的ssh key是你的公钥, 当然也可以配置密码登陆.&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;生成镜像文件:&lt;/dt&gt;
&lt;dd&gt;genisoimage  -output seed.iso -volid cidata -joliet -rock user-data meta-data&lt;/dd&gt;
&lt;/dl&gt;

&lt;h2 id=&#34;启动虚拟机&#34;&gt;启动虚拟机&lt;/h2&gt;

&lt;p&gt;现在可以启动虚拟机了:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;
sudo kvm -m 2048m -smp 2 \
-drive file=node01.img,if=virtio,cache=none,aio=native \
-drive file=./metadata/seed.iso,if=virtio \
-net nic,vlan=0,model=virtio,macaddr=DE:AD:BE:EF:FC:80 \
-net tap,vlan=0,vhost=on,script=/etc/openvswitch/ovs-ifup,downscript=/etc/openvswitch/ovs-ifdown \
-nographic -curses
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;启动之后, 你的配置信息注入到了虚拟机里面, 你现在可以直接访问了:&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;ssh ubuntu@172.16.11.100&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;想象一下, 这样你自己完全可以diy一个单机的IaaS平台嘛!&lt;/p&gt;

&lt;p&gt;当然这里没有配置虚拟机的网络访问, 如果要实现网络访问, 需要配置虚拟机的resolv.conf和宿主机的路由转发.&lt;/p&gt;

&lt;h2 id=&#34;宿主机路由&#34;&gt;宿主机路由&lt;/h2&gt;

&lt;dl&gt;
&lt;dt&gt;首先打开转发功能, 编辑/etc/sysctl.conf, 打开ip_forward=1那一行, 同时让配置生效:&lt;/dt&gt;
&lt;dd&gt;sysctl -p&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;配置iptables:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;iptables -I FORWARD -j ACCEPT
iptables -t nat -A POSTROUTING -s 172.16.11.0/24 ! -d 172.168.11.0/24 -j MASQUERADE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里只是测试环境, 所以我打开了所有包的转发, 当然你也能细粒度控制包转发.&lt;/p&gt;

&lt;h1 id=&#34;coreos的cloud-config&#34;&gt;CoreOS的cloud config&lt;/h1&gt;

&lt;p&gt;coreos这是个顺应容器时代的操作系统, 他和其他linux发行版完全不一样, 没有提供包管理机制, 预编译升级, 支持很多IaaS平台, 如果你没有IaaS平台, 当然你也能在本地用, 社区有支持版本[fn:1]. 我一般在自己机器上用kvm, 测试了一下, 非常方便, 简单注意几点:&lt;/p&gt;

&lt;h2 id=&#34;cloud-config&#34;&gt;cloud config&lt;/h2&gt;

&lt;p&gt;该文件必须存放在特殊位置, 使用方式如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mkdir -p myconfig/openstack/latest
cp user_data myconfig/openstack/latest/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;user_data就是coreos的cloud config文件, 具体用法请参考CoreOS文档[fn:2]. 必须存放在openstack/latest目录下才行.&lt;/p&gt;

&lt;p&gt;使用方式在kvm启动命令中添加如下启动项:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;-fsdev local,id=conf,security_model=none,readonly,path=~/myconfig \
-device virtio-9p-pci,fsdev=conf,mount_tag=config-2 \
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;kvm启动命令示例&#34;&gt;kvm启动命令示例&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo kvm -m 2048m -smp 2 \
-drive file=coreos-etcd.img,if=virtio,cache=none,aio=native \
-fsdev local,id=conf,security_model=none,readonly,path=~/myconfig \
-device virtio-9p-pci,fsdev=conf,mount_tag=config-2 \
-net nic,vlan=0,model=virtio \
-net tap,vlan=0,vhost=on,script=/etc/openvswitch/ovs-ifup,downscript=/etc/openvswitch/ovs-ifdown \
-nographic &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;日志诊断&#34;&gt;日志诊断&lt;/h2&gt;

&lt;p&gt;CoreOS的日志查看非常简单, 他提供了一个统一的工具: journalctl[fn:3], 通过这个工具, 你能查看单个节点的日志信息.&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;读整个日志, 不需要加任何参数, 直接执行即可. 查看某个服务的日志, 简单通过如下命令:&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;$ journalctl -u apache.service&lt;/p&gt;&lt;/dd&gt;
&lt;dt&gt;读启动日志, 可以查看最晚的启动日志, 方便诊断启动错误(cloud config出现问题可以清楚看到):&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;journalctl &amp;ndash;boot&lt;/p&gt;&lt;/dd&gt;
&lt;dt&gt;你也能用fleetctl读取fleet控制的服务:&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;$ fleetctl &amp;ndash;tunnel 10.10.10.10 journal apache.service&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;当然也能tail ,直接在命令后面加-f参数即可&lt;/p&gt;

&lt;h2 id=&#34;一些问题&#34;&gt;一些问题&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Cloud config容易由于网络问题, 导致配置失败, 估计好多人都碰到了[fn:4].&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;https://coreos.com/docs/#running-coreos][CoreOS&#34;&gt;https://coreos.com/docs/#running-coreos][CoreOS&lt;/a&gt; support platforms]]&lt;/p&gt;

&lt;p&gt;[fn:2] [[&lt;a href=&#34;https://coreos.com/docs/cluster-management/setup/cloudinit-cloud-config/][Cloud&#34;&gt;https://coreos.com/docs/cluster-management/setup/cloudinit-cloud-config/][Cloud&lt;/a&gt; Config]]&lt;/p&gt;

&lt;p&gt;[fn:3] [[&lt;a href=&#34;https://coreos.com/docs/cluster-management/debugging/reading-the-system-log/][Reading&#34;&gt;https://coreos.com/docs/cluster-management/debugging/reading-the-system-log/][Reading&lt;/a&gt; the System Log]]&lt;/p&gt;

&lt;p&gt;[fn:4] [[&lt;a href=&#34;https://github.com/coreos/coreos-cloudinit/issues/205][CoreOS&#34;&gt;https://github.com/coreos/coreos-cloudinit/issues/205][CoreOS&lt;/a&gt; Cloud init #205]]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Raspberry Pi WirelessAP</title>
      <link>http://tacy.github.io/post/raspberry-pi-wirelessap/</link>
      <pubDate>Wed, 29 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/raspberry-pi-wirelessap/</guid>
      
        <description>

&lt;h1 id=&#34;raspberry-pi-wirelessap&#34;&gt;Raspberry Pi WirelessAP&lt;/h1&gt;

&lt;p&gt;有时候, 希望能做一些其他设备的抓包分析, 不想去折腾路由器, 就把手上的Raspberry Pi改造了一下, 当然你也能让他当成翻墙工具, 可以自己扩展.&lt;/p&gt;

&lt;p&gt;网上已经有一大堆文档, 大部分都已经过期了, 所以建议大家在搜索的时候, 尽量选择近期的文档, 这样会比较靠谱一点.&lt;/p&gt;

&lt;p&gt;拿我的设备举例子: 我的无线网卡是RTL8192CU, 网上的大部分帖子都过期了, 上来就让你编译网卡驱动. 其实这个网卡在kernel 3.10之前有bug, 无法正确支持, 但是在后续版本中已经fix了, 我现在用的kernel是3.11, 自动支持.&lt;/p&gt;

&lt;p&gt;主要的问题是hostapd对RT8192CU的支持有点问题, 需要用hack过的版本.&lt;/p&gt;

&lt;h2 id=&#34;环境准备&#34;&gt;环境准备&lt;/h2&gt;

&lt;dl&gt;
&lt;dt&gt;安装相关软件&lt;/dt&gt;
&lt;dd&gt;sudo apt-get install hostapd isc-dhcp-server&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dt&gt;安装相关软件&lt;/dt&gt;
&lt;dd&gt;sudo apt-get install hostapd isc-dhcp-server&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;hostapd isc-dhcp-server&lt;/p&gt;

&lt;h2 id=&#34;配置无线网卡和网络路由&#34;&gt;配置无线网卡和网络路由&lt;/h2&gt;

&lt;p&gt;配置无线网卡为静态地址, 当然不要和eth0地址段冲突了, 如果你家里是192.168.1.0/24, 那么这里你需要设置为该网段以外的其他网段.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pi@raspbmc:/etc/dhcp$ cat /etc/network/interfaces
auto wlan0
allow-hotplug wlan0
iface wlan0 inet static
    address 192.168.42.1
    netmask 255.255.255.0
up iptables-restore &amp;lt; /etc/iptables.ipv4.nat
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;接下来你需要启用ip转发功能, 简单做法是编辑/etc/sysctl.conf, 找到下面这样, 取消注释.&lt;/dt&gt;
&lt;dd&gt;#net.ipv4.ip_forward=1
然后通过下面命令启用:&lt;/dd&gt;
&lt;dd&gt;sysctl -p&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;设置NAT规则, 让包能够正常路由到其他网段:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
sudo iptables -A FORWARD -i eth0 -o wlan0 -m state --state RELATED,ESTABLISHED -j ACCEPT
sudo iptables -A FORWARD -i wlan0 -o eth0 -j ACCEPT
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;保存iptables配置:&lt;/dt&gt;
&lt;dd&gt;sudo sh -c &amp;ldquo;iptables-save &amp;gt; /etc/iptables.ipv4.nat&amp;rdquo;&lt;/dd&gt;
&lt;/dl&gt;

&lt;h2 id=&#34;配置dhcp服务&#34;&gt;配置DHCP服务&lt;/h2&gt;

&lt;p&gt;你需要给连接AP的客户端自动分配ip地址信息, 所有你需要有dhcp服务, 当然你也能手动制定, 但是对于客户端太麻烦了.&lt;/p&gt;

&lt;p&gt;先编写dhcp配置文件, 主要是注释下面两行:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;option domain-name &amp;quot;example.org&amp;quot;;
option domain-name-servers ns1.example.org, ns2.example.org;
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;取消注释下面一行:&lt;/dt&gt;
&lt;dd&gt;#authoritative;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;添加下面内容到文件结尾, 注意这里的ip地址段和无线网卡匹配:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;subnet 192.168.42.0 netmask 255.255.255.0 {
    range 192.168.42.10 192.168.42.50;
    option broadcast-address 192.168.42.255;
    option routers 192.168.42.1;
    default-lease-time 600;
    max-lease-time 7200;
    option domain-name &amp;quot;local&amp;quot;;
    option domain-name-servers 8.8.8.8, 8.8.4.4;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;完整内容如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pi@raspbmc:/etc/dhcp$ cat dhcpd.conf
#
# Sample configuration file for ISC dhcpd for Debian
#
#

# The ddns-updates-style parameter controls whether or not the server will
# attempt to do a DNS update when a lease is confirmed. We default to the
# behavior of the version 2 packages (&#39;none&#39;, since DHCP v2 didn&#39;t
# have support for DDNS.)
ddns-update-style none;

# option definitions common to all supported networks...
#option domain-name &amp;quot;example.org&amp;quot;;
#option domain-name-servers ns1.example.org, ns2.example.org;

default-lease-time 600;
max-lease-time 7200;

# If this DHCP server is the official DHCP server for the local
# network, the authoritative directive should be uncommented.
authoritative;

# Use this to send dhcp log messages to a different log file (you also
# have to hack syslog.conf to complete the redirection).
log-facility local7;

# No service will be given on this subnet, but declaring it helps the
# DHCP server to understand the network topology.

#subnet 10.152.187.0 netmask 255.255.255.0 {
#}

# This is a very basic subnet declaration.

#subnet 10.254.239.0 netmask 255.255.255.224 {
#  range 10.254.239.10 10.254.239.20;
#  option routers rtr-239-0-1.example.org, rtr-239-0-2.example.org;
#}

# This declaration allows BOOTP clients to get dynamic addresses,
# which we don&#39;t really recommend.

#subnet 10.254.239.32 netmask 255.255.255.224 {
#  range dynamic-bootp 10.254.239.40 10.254.239.60;
#  option broadcast-address 10.254.239.31;
#  option routers rtr-239-32-1.example.org;
#}

# A slightly different configuration for an internal subnet.
#subnet 10.5.5.0 netmask 255.255.255.224 {
#  range 10.5.5.26 10.5.5.30;
#  option domain-name-servers ns1.internal.example.org;
#  option domain-name &amp;quot;internal.example.org&amp;quot;;
#  option routers 10.5.5.1;
#  option broadcast-address 10.5.5.31;
#  default-lease-time 600;
#  max-lease-time 7200;
#}

# Hosts which require special configuration options can be listed in
# host statements.   If no address is specified, the address will be
# allocated dynamically (if possible), but the host-specific information
# will still come from the host declaration.

#host passacaglia {
#  hardware ethernet 0:0:c0:5d:bd:95;
#  filename &amp;quot;vmunix.passacaglia&amp;quot;;
#  server-name &amp;quot;toccata.fugue.com&amp;quot;;
#}

# Fixed IP addresses can also be specified for hosts.   These addresses
# should not also be listed as being available for dynamic assignment.
# Hosts for which fixed IP addresses have been specified can boot using
# BOOTP or DHCP.   Hosts for which no fixed address is specified can only
# be booted with DHCP, unless there is an address range on the subnet
# to which a BOOTP client is connected which has the dynamic-bootp flag
# set.
#host fantasia {
#  hardware ethernet 08:00:07:26:c0:a5;
#  fixed-address fantasia.fugue.com;
#}

# You can declare a class of clients and then do address allocation
# based on that.   The example below shows a case where all clients
# in a certain class get addresses on the 10.17.224/24 subnet, and all
# other clients get addresses on the 10.0.29/24 subnet.

#class &amp;quot;foo&amp;quot; {
#  match if substring (option vendor-class-identifier, 0, 4) = &amp;quot;SUNW&amp;quot;;
#}

#shared-network 224-29 {
#  subnet 10.17.224.0 netmask 255.255.255.0 {
#    option routers rtr-224.example.org;
#  }
#  subnet 10.0.29.0 netmask 255.255.255.0 {
#    option routers rtr-29.example.org;
#  }
#  pool {
#    allow members of &amp;quot;foo&amp;quot;;
#    range 10.17.224.10 10.17.224.250;
#  }
#  pool {
#    deny members of &amp;quot;foo&amp;quot;;
#    range 10.0.29.10 10.0.29.230;
#  }
#}

subnet 192.168.42.0 netmask 255.255.255.0 {
    range 192.168.42.10 192.168.42.50;
    option broadcast-address 192.168.42.255;
    option routers 192.168.42.1;
    default-lease-time 600;
    max-lease-time 7200;
    option domain-name &amp;quot;local&amp;quot;;
    option domain-name-servers 8.8.8.8, 8.8.4.4;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接下来需要告诉dhcp, 它需要绑定在哪个网卡上, 简单修改isc-dhcp-server文件, 设置INTERFACES=&amp;ldquo;wlan0&amp;rdquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pi@raspbmc:/etc/dhcp$ cat /etc/default/isc-dhcp-server
# Defaults for isc-dhcp-server initscript
# sourced by /etc/init.d/isc-dhcp-server
# installed at /etc/default/isc-dhcp-server by the maintainer scripts

#
# This is a POSIX shell fragment
#

# Path to dhcpd&#39;s config file (default: /etc/dhcp/dhcpd.conf).
#DHCPD_CONF=/etc/dhcp/dhcpd.conf

# Path to dhcpd&#39;s PID file (default: /var/run/dhcpd.pid).
#DHCPD_PID=/var/run/dhcpd.pid

# Additional options to start dhcpd with.
#	Don&#39;t use options -cf or -pf here; use DHCPD_CONF/ DHCPD_PID instead
#OPTIONS=&amp;quot;&amp;quot;

# On what interfaces should the DHCP server (dhcpd) serve DHCP requests?
#	Separate multiple interfaces with spaces, e.g. &amp;quot;eth0 eth1&amp;quot;.
INTERFACES=&amp;quot;wlan0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;配置hostapd&#34;&gt;配置hostapd&lt;/h2&gt;

&lt;p&gt;编写hostapd.conf文件, 内容如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pi@raspbmc:/etc/hostapd$ cat hostapd.conf
interface=wlan0
driver=rtl871xdrv
ssid=Pi_AP
hw_mode=g
channel=6
macaddr_acl=0
auth_algs=1
ignore_broadcast_ssid=0
wpa=2
wpa_passphrase=Raspberry
wpa_key_mgmt=WPA-PSK
wpa_pairwise=TKIP
rsn_pairwise=CCMP
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改hostapd.conf文件, 指定配置文件位置DAEMON_CONF=&amp;ldquo;/etc/hostapd/hostapd.conf&amp;rdquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pi@raspbmc:/etc/hostapd$ cat /etc/default/hostapd
# Defaults for hostapd initscript
#
# See /usr/share/doc/hostapd/README.Debian for information about alternative
# methods of managing hostapd.
#
# Uncomment and set DAEMON_CONF to the absolute path of a hostapd configuration
# file and hostapd will be started during system boot. An example configuration
# file can be found at /usr/share/doc/hostapd/examples/hostapd.conf.gz
#
DAEMON_CONF=&amp;quot;/etc/hostapd/hostapd.conf&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;用下面hack过的hostapd替换原始的:&lt;/dt&gt;
&lt;dd&gt;wget &lt;a href=&#34;http://www.adafruit.com/downloads/adafruit_hostapd.zip&#34;&gt;http://www.adafruit.com/downloads/adafruit_hostapd.zip&lt;/a&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;用解压之后的文件替换/usr/sbin/hostapd, 记得添加执行权限, 替换之前也可以备份一下原始版本&lt;/p&gt;

&lt;p&gt;完工, 现在检查一下效果, 确认:
1. 无线网卡配置正常(ifconfig, wlan0正常)
2. 确认ip_forward启用(/proc/sys/net/ipv4/ip_forward为1)
3. 确认iptables nat正常(sudo iptables -t nat -S)
3. dhcp服务启动(sudo service dhcp restart)
4. hostapd服务启动(sudo service hostapd restart)&lt;/p&gt;

&lt;p&gt;正常的话, 你在客户端应该能看到一个叫Pi_AP的信号了!&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>marathon in mesos</title>
      <link>http://tacy.github.io/post/marathon-in-mesos/</link>
      <pubDate>Sat, 30 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/marathon-in-mesos/</guid>
      
        <description>

&lt;h1 id=&#34;mesos&#34;&gt;mesos&lt;/h1&gt;

&lt;p&gt;记录一下最近一周的工作，最近一周一直在看PaaS，主要是结合Docker的方案，简单看了
看，成熟的东西没有，基本都有各种问题，可以参考一下lusis写的[[&lt;a href=&#34;http://blog.lusis.org/blog/2014/06/14/paas-for-realists/][PaaS&#34;&gt;http://blog.lusis.org/blog/2014/06/14/paas-for-realists/][PaaS&lt;/a&gt; for Realists]]，&lt;/p&gt;

&lt;p&gt;我没有去试这几个项目，未来有时间可能会做，目前我的重点在mesos上，这是[[&lt;a href=&#34;https://www.google.com/url?sa%3Dt&amp;amp;rct%3Dj&amp;amp;q%3D&amp;amp;esrc%3Ds&amp;amp;source%3Dweb&amp;amp;cd%3D2&amp;amp;cad%3Drja&amp;amp;uact%3D8&amp;amp;ved%3D0CCsQFjAB&amp;amp;url%3Dhttp%253A%252F%252Fresearch.google.com%252Fpubs%252Fpub41684.html&amp;amp;ei%3DIvEBVM_VJI-A8QXIlIDADQ&amp;amp;usg%3DAFQjCNFhre6QW6LnswxdXZu-jLg3WXQ1eQ&amp;amp;sig2%3DFWZK9sf-fke4bqNXZI_Ikg&amp;amp;bvm%3Dbv.74115972,d.dGc][Omega]]的&#34;&gt;https://www.google.com/url?sa%3Dt&amp;amp;rct%3Dj&amp;amp;q%3D&amp;amp;esrc%3Ds&amp;amp;source%3Dweb&amp;amp;cd%3D2&amp;amp;cad%3Drja&amp;amp;uact%3D8&amp;amp;ved%3D0CCsQFjAB&amp;amp;url%3Dhttp%253A%252F%252Fresearch.google.com%252Fpubs%252Fpub41684.html&amp;amp;ei%3DIvEBVM_VJI-A8QXIlIDADQ&amp;amp;usg%3DAFQjCNFhre6QW6LnswxdXZu-jLg3WXQ1eQ&amp;amp;sig2%3DFWZK9sf-fke4bqNXZI_Ikg&amp;amp;bvm%3Dbv.74115972,d.dGc][Omega]]的&lt;/a&gt;
开源实现，支持各种framework，包括hadoop/storm/spark等流行的数据处理框架，当然熟
悉这块的人也知道，资源调度器的另一个更流行的产品是YARN，但是他只支持MapReduce框
架，而mesos支持面更广，他还支持应用运行在上面，具体的比较可以参考[[&lt;a href=&#34;http://www.quora.com/How-does-YARN-compare-to-Mesos][Quora上的帖子：&#34;&gt;http://www.quora.com/How-does-YARN-compare-to-Mesos][Quora上的帖子：&lt;/a&gt;
How does YARN compare to Mesos?]]，另外就是mesos支持docker实现隔离。&lt;/p&gt;

&lt;h1 id=&#34;marathon&#34;&gt;marathon&lt;/h1&gt;

&lt;p&gt;marathon其实就是mesos上的一个framework，一个基于mesos的PaaS实现。通过它能部署应
用，比如java、python、ruby等。利用mesos提供的HA、FT、Scale特性，你的应用天然具备
这些特性。同时应用实现容器级别的资源隔离实现，非常方便。&lt;/p&gt;

&lt;h1 id=&#34;marathon-mesos-docker&#34;&gt;marathon + mesos + docker&lt;/h1&gt;

&lt;p&gt;部署测试了一下，还是比较理想，只是对于docker的支持还有一些问题，下面是一些需要
注意的点：&lt;/p&gt;

&lt;h2 id=&#34;安装注意事项&#34;&gt;安装注意事项&lt;/h2&gt;

&lt;p&gt;首先mesos 0.19版本之前，支持docker都是通过External Containerization特性来支持，
需要依赖Deimos项目，0.20版本（写本文的时候，刚刚发布几天）原声支持，这里用的是
0.20版本&lt;/p&gt;

&lt;p&gt;其次marathon目前发布的版本是0.6.1，不能支持mesos 0.20的docker特性，你需要获取源
码snapshot自己编译。&lt;/p&gt;

&lt;h2 id=&#34;功能上需要注意的点&#34;&gt;功能上需要注意的点&lt;/h2&gt;

&lt;p&gt;首先一个需要注意的地方是mesos对于docker网络的支持，目前之支持host模式，也就意味
着你的应用端口配置上有一些麻烦，你需要在应用启动阶段注入修改应用端口，mesos的下
一个版本（0.20.1）能支持更复杂的网络配置[fn:1]。&lt;/p&gt;

&lt;p&gt;关于网络举例来说，缺省是bridge，docker能做端口expose，docker容器内监听的80端口，
如果外面想访问，只需把端口expose出来。这样对于运行在docker容器内的应用很方便，
不会产生端口冲突问题，但是如果是host模式，docker容器内的监听端口直接监听在宿主
机上，需要考虑同一宿主机的多实例应用端口冲突问题。&lt;/p&gt;

&lt;p&gt;其次是LB的问题也需要注意，目前给出的示例是通过cron方式非实时更新LB配置，不是太理
想，应该可以通过callback方式来走，会比较理想。&lt;/p&gt;

&lt;p&gt;另外一点就是[fn:2]：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Also since we explicitly attempt to pull the image on launch,if the docker image
is only installed locally but not avaialble on the remote repository the launch
will fail as well.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;文档里面提到，如果是本地的image是不行的，必须提交到远程仓库，否则mesos会pull失败&lt;/p&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;http://tnachen.wordpress.com/2014/08/19/docker-in-mesos-0-20/][Docker&#34;&gt;http://tnachen.wordpress.com/2014/08/19/docker-in-mesos-0-20/][Docker&lt;/a&gt; on Mesos 0.20]]&lt;/p&gt;

&lt;p&gt;[fn:2] [[&lt;a href=&#34;http://mesos.apache.org/documentation/latest/docker-containerizer/][Docker&#34;&gt;http://mesos.apache.org/documentation/latest/docker-containerizer/][Docker&lt;/a&gt; Containerizer]]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>wireshark和tcpdump相关笔记</title>
      <link>http://tacy.github.io/post/wireshark-tcpdump/</link>
      <pubDate>Thu, 21 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/wireshark-tcpdump/</guid>
      
        <description>

&lt;h1 id=&#34;一个问题诊断&#34;&gt;一个问题诊断&lt;/h1&gt;

&lt;p&gt;系统做了单点登录，用的是CAS，用户反馈偶尔系统登出之后，重新用其他帐号登入，查询
到的用户资料依然是上一个用户的，只有关闭浏览器之后，才能正常。&lt;/p&gt;

&lt;p&gt;从直观上判断，应该是session问题，询问了一下应用开发人员，确认用户id存放在session
中。只有为啥session没有销毁成功，简单做法就是抓包分析。&lt;/p&gt;

&lt;p&gt;先是用wireshark在客户端做了分析，发现在出现问题的时候，系统去请求出现问题的页面
不会做跳转（初次访问该页面需要去cas登入），也就是说对于业务系统来说，jsessionid
依然有效。&lt;/p&gt;

&lt;p&gt;了解了一下cas的原理：用户去portal平台做登入，从cas获取到TGT。第一次访问业务模块
的时候，由于没有session，会创建一个session，然后重定向到sso做登入。而注销的时候
cas负责销毁创建的session。从故障看，问题就是出现在销毁session上。&lt;/p&gt;

&lt;p&gt;通过tcpdump来抓包：
sso服务器端：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@localhost ~]# tcpdump -p -nn -s 0 tcp port 8088 and host 172.16.102.205  -w sso.dump
tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;应用端：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;[root@trust-test-app ~]# tcpdump -p -nn -s 0 host 172.17.102.106 and not tcp port 8001 -w sso-logout.dump
tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用wireshark分析包，可以看到CAS发出去的销毁session请求被reset，查看了一下环境，问
题出现在apache上，询问了一下，apache是自己编译的，而且配置文件也是乱七八糟，没想
明白为啥被reset而不是connection reject之类的，修改apache配置问题解决。&lt;/p&gt;

&lt;p&gt;当然也不能算彻底解决，CAS关于注销的实现有bug，是一个不可靠实现，需要做一定处理。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>android notes</title>
      <link>http://tacy.github.io/post/android/</link>
      <pubDate>Tue, 29 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/android/</guid>
      
        <description>

&lt;h1 id=&#34;android&#34;&gt;Android&lt;/h1&gt;

&lt;h2 id=&#34;emulator&#34;&gt;emulator&lt;/h2&gt;

&lt;dl&gt;
&lt;dt&gt;只需加载kvm模块，同时启动命令上添加‘-qemu -enable-kvm’ 参数即可，启动命令：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;emulator64-x86 -avd test -data userdata.img -qemu -m 2048 -enable-kvm&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dt&gt;vm’ 参数即可，启动命令：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;emulator64-x86 -avd test -data userdata.img -qemu -m 2048 -enable-kvm&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;其中的data如果没有指定，emulator好像每次都会初始化数据，也就是说重启之后，通过
adb安装的应用就没有了。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;如果启动出现如下信息：&lt;/dt&gt;
&lt;dd&gt;emulator: emulator window was out of view and was recentered
你可以添加&amp;rsquo;-scale auto&amp;rsquo;参数（取值范围0.1-3)，注意，非qemu参数都加在qemu前面。&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;另外avd文件存放在home/.android目录下。&lt;/p&gt;

&lt;p&gt;你可以通过mksdcard创建sd镜像文件。&lt;/p&gt;

&lt;p&gt;通过adb安装app和拷贝文件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;adb push localfile /sdcard/
adb install test.apk
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;启动sdk manager：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;android sdk&lt;/p&gt;&lt;/dd&gt;
&lt;dt&gt;启动avd manager：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;android avd&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;具体的其他子命令可以help，主要是abd和android两个。&lt;/p&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;http://stackoverflow.com/questions/1554099/why-is-the-android-emulator-so-slow][Why&#34;&gt;http://stackoverflow.com/questions/1554099/why-is-the-android-emulator-so-slow][Why&lt;/a&gt; is the Android emulator so slow?]]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Java性能分析之火焰图</title>
      <link>http://tacy.github.io/post/flamegraph/</link>
      <pubDate>Wed, 16 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/flamegraph/</guid>
      
        <description>

&lt;h1 id=&#34;flamegraph&#34;&gt;FlameGraph&lt;/h1&gt;

&lt;p&gt;火焰图[fn:1]，简单通过x轴横条宽度来度量时间指标，y轴代表线程栈的层次，简单明了，
容易找出具体的可优化点，非常方便，当然前提是我们通过profiler工具获取到profiler
数据。&lt;/p&gt;

&lt;h2 id=&#34;java-profiler&#34;&gt;java profiler&lt;/h2&gt;

&lt;p&gt;java性能调优时，我们经常会用到profiler工具，但是很多时候你可能不知道，大部分的
profiler工具都是有问题的[fn:2][fn:3]，简单来说，profiler：增加开销；修改了你的
代码，导致java编译器的优化行为不确定；同时影响了代码的层次，层次越深自然也影响
执行效率。&lt;/p&gt;

&lt;p&gt;当然如果你不是通过上面方式实现，而是通过获取on-cpu线程的线程栈方式，这又会带来
一个麻烦的问题：获取系统范围的线程栈，jvm必须处于safepoint[fn:4]状态，只有当线
程处于safepoint状态的时候，别的线程才能去获取它的线程栈，而这个safepoint是由jvm
控制的，这对于profiler非常不利，有可能一个很热的代码块，jvm不会在该代码块中间放
置safepoint，导致profiler无法获得该线程栈，导致错误的profiler结果。&lt;/p&gt;

&lt;p&gt;上面的问题几个商用的profiler工具都存在，Oracle Solaris studio利用的是jvmti的一
个非标准接口AsyncGetCallTrace来实现，不存在上面问题，Jeremy Manson也利用该接口
实现了一个简单的profiler工具：[[&lt;a href=&#34;https://code.google.com/p/lightweight-java-profiler/wiki/GettingStarted][Lightweight&#34;&gt;https://code.google.com/p/lightweight-java-profiler/wiki/GettingStarted][Lightweight&lt;/a&gt; Asynchronous Sampling Profiler]]，我们
的火焰图的数据来源就是通过它来获取的。&lt;/p&gt;

&lt;h2 id=&#34;lightweight-java-profiler&#34;&gt;lightweight-java-profiler&lt;/h2&gt;

&lt;p&gt;当然，这个工具只支持hotspot的vm，需要你自己编译，有些问题需要注意：
 - 如果你需要在rhel上编译，需要安装4.6以上版本gcc[fn:5]，4.4版本不支持。
 - 如果你需要在ubunt上编译，可能会碰到编译错误[fn:6]。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;编译的时候，需要主要修改BITS参数，如果你要编译64Bit，使用命令：&lt;/dt&gt;
&lt;dd&gt;make BITS=64 all&lt;/dd&gt;
&lt;dt&gt;使用方法很简单，直接在你的启动命令上添加如下参数：&lt;/dt&gt;
&lt;dd&gt;-agentpath:path/to/liblagent.so[:file=name]&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;启动之后，会在启动目录下生成trace.txt文件（缺省），该文件就是我们需要的采样数据。&lt;/p&gt;

&lt;p&gt;另外有几个参数可在编译时修改，都在global.h文件中。首先是采样的频率，缺省是100次
每秒；另外是最大采样的线程栈，缺省3000，超过3000就忽略（对于复杂的应用明显不够）
；最后是栈的深度，缺省是128（对于调用层次深的应用调大）。当然你记录的东西越多，
也会有性能损耗，我调成30000+256，一刻钟生成200M文件。&lt;/p&gt;

&lt;p&gt;另外特别需要注意，trace不是实时写入，而是在应用shutdown的时候才写入的，别kill应
用，否则trace里面什么都没有。&lt;/p&gt;

&lt;h2 id=&#34;生成火焰图&#34;&gt;生成火焰图&lt;/h2&gt;

&lt;p&gt;大神Brendan Gregg[fn:7]已经帮你做好了，直接check大神的项目：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone http://github.com/brendangregg/FlameGraph
cd FlameGraph
./stackcollapse-ljp.awk &amp;lt; ../traces.txt | ./flamegraph.pl &amp;gt; ../traces.svg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;效果图截屏参考：
[[img:flamegraph.png][火焰图]]&lt;/p&gt;

&lt;p&gt;真正火焰图指上去会显示栈信息。&lt;/p&gt;

&lt;p&gt;看火焰图，找到那些长条分析，基本上就有方向了。&lt;/p&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;http://www.brendangregg.com/flamegraphs.html][Flame&#34;&gt;http://www.brendangregg.com/flamegraphs.html][Flame&lt;/a&gt; Graphs]]&lt;/p&gt;

&lt;p&gt;[fn:2] [[&lt;a href=&#34;http://pl.cs.colorado.edu/papers/profilers-pldi10.html][T&#34;&gt;http://pl.cs.colorado.edu/papers/profilers-pldi10.html][T&lt;/a&gt; Mytkowicz, A Diwan, M Hauswirth, PF Sweeney. &amp;ldquo;Evaluating the Accuracy of Java Profilers,&amp;rdquo;]]&lt;/p&gt;

&lt;p&gt;[fn:3] [[&lt;a href=&#34;http://jeremymanson.blogspot.jp/2010/07/why-many-profilers-have-serious.html][Why&#34;&gt;http://jeremymanson.blogspot.jp/2010/07/why-many-profilers-have-serious.html][Why&lt;/a&gt; Many Profilers have Serious Problems ]]&lt;/p&gt;

&lt;p&gt;[fn:4] [[&lt;a href=&#34;http://chriskirk.blogspot.jp/2013/09/what-is-java-safepoint.html][What&#34;&gt;http://chriskirk.blogspot.jp/2013/09/what-is-java-safepoint.html][What&lt;/a&gt; is java safepoint]]&lt;/p&gt;

&lt;p&gt;[fn:5] [[&lt;a href=&#34;http://superuser.com/questions/381160/how-to-install-gcc-4-7-x-4-8-x-on-centos][How&#34;&gt;http://superuser.com/questions/381160/how-to-install-gcc-4-7-x-4-8-x-on-centos][How&lt;/a&gt; to Install gcc 4.7.x/4.8.x on CentOS]]&lt;/p&gt;

&lt;p&gt;[fn:6] [[&lt;a href=&#34;https://code.google.com/p/lightweight-java-profiler/issues/detail?id%3D3][build&#34;&gt;https://code.google.com/p/lightweight-java-profiler/issues/detail?id%3D3][build&lt;/a&gt; error on Ubuntu 13.10 (Saucy)]]&lt;/p&gt;

&lt;p&gt;[fn:7] [[&lt;a href=&#34;http://brendan.gregg.usesthis.com/][Brendan&#34;&gt;http://brendan.gregg.usesthis.com/][Brendan&lt;/a&gt; Gregg]]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>linux kernel</title>
      <link>http://tacy.github.io/post/linux-kernel/</link>
      <pubDate>Thu, 19 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/linux-kernel/</guid>
      
        <description>

&lt;h1 id=&#34;linux-kernel&#34;&gt;linux kernel&lt;/h1&gt;

&lt;h2 id=&#34;vm&#34;&gt;vm&lt;/h2&gt;

&lt;h3 id=&#34;vfs-cache-pressure&#34;&gt;vfs_cache_pressure&lt;/h3&gt;

&lt;p&gt;简单说，就是控制page cache的回收，是优先回收data block还是meta block(page cache
包括这两部分），一般情况下建议还是保留meta block缓存。[fn:2]&lt;/p&gt;

&lt;p&gt;kernel设置该值为100，也就是优先回收meta block，会导致文件浏览类的工具速度变慢，
比如find，nautil[fn:1]。&lt;/p&gt;

&lt;p&gt;建议可以设置到50，优化性能。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vfs_cache_pressure
------------------

This percentage value controls the tendency of the kernel to reclaim
the memory which is used for caching of directory and inode objects.

At the default value of vfs_cache_pressure=100 the kernel will attempt to
reclaim dentries and inodes at a &amp;quot;fair&amp;quot; rate with respect to pagecache and
swapcache reclaim.  Decreasing vfs_cache_pressure causes the kernel to prefer
to retain dentry and inode caches. When vfs_cache_pressure=0, the kernel will
never reclaim dentries and inodes due to memory pressure and this can easily
lead to out-of-memory conditions. Increasing vfs_cache_pressure beyond 100
causes the kernel to prefer to reclaim dentries and inodes.

Increasing vfs_cache_pressure significantly beyond 100 may have negative
performance impact. Reclaim code needs to take various locks to find freeable
directory and inode objects. With vfs_cache_pressure=1000, it will look for
ten times more freeable objects than there are.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;swappiness&#34;&gt;swappiness&lt;/h3&gt;

&lt;p&gt;简单说，就是先回收page cache还是先swapping anonymous page（也即是应用栈，例如
java heap），缺省设置60，也就是先swapping，这样回导致应用变得很慢。&lt;/p&gt;

&lt;p&gt;建议可以设置到10左右，优化性能。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;swappiness

This control is used to define how aggressive the kernel will swap
memory pages.  Higher values will increase agressiveness, lower values
decrease the amount of swap.  A value of 0 instructs the kernel not to
initiate swap until the amount of free and file-backed pages is less
than the high water mark in a zone.

The default value is 60.
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;http://rudd-o.com/linux-and-free-software/tales-from-responsivenessland-why-linux-feels-slow-and-how-to-fix-that][why&#34;&gt;http://rudd-o.com/linux-and-free-software/tales-from-responsivenessland-why-linux-feels-slow-and-how-to-fix-that][why&lt;/a&gt; Linux feels slow, and how to fix that]]&lt;/p&gt;

&lt;p&gt;[fn:2] [[&lt;a href=&#34;https://www.kernel.org/doc/Documentation/sysctl/vm.txt][linux&#34;&gt;https://www.kernel.org/doc/Documentation/sysctl/vm.txt][linux&lt;/a&gt; vm documentation]]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Byteman notes</title>
      <link>http://tacy.github.io/post/byteman/</link>
      <pubDate>Wed, 11 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/byteman/</guid>
      
        <description>

&lt;h1 id=&#34;byteman&#34;&gt;Byteman&lt;/h1&gt;

&lt;p&gt;byteman是jboss下的一个项目，是一个非常方便的java分析工具，能够拦截字节码执行，执
行代码和修改变量，是一个诊断问题的利器。&lt;/p&gt;

&lt;p&gt;在linux下使用起来非常方便，不用对目标应用做任何修改，可以动态打开目标应用的监听
端口，当然仅限于openjdk，hotspot和jrockit，ibm jdk不支持，需要启动时配置监听[fn:1]。&lt;/p&gt;

&lt;p&gt;具体的语法参考文档参见[[&lt;a href=&#34;http://downloads.jboss.org/byteman/2.1.4/ProgrammersGuide.html][Byteman&#34;&gt;http://downloads.jboss.org/byteman/2.1.4/ProgrammersGuide.html][Byteman&lt;/a&gt; Programmer&amp;rsquo;s Guide]]&lt;/p&gt;

&lt;h2 id=&#34;使用&#34;&gt;使用&lt;/h2&gt;

&lt;p&gt;只需要配置BYTEMAN_HOME变量就可以了，正常启动你的应用，然后通过byteman提供的脚本
动态打开byteman agent监听，提交byteman脚本，执行你需要分析的业务功能即可。&lt;/p&gt;

&lt;h2 id=&#34;诊断classloader争用问题&#34;&gt;诊断classloader争用问题&lt;/h2&gt;

&lt;p&gt;一般情况下，我们指定classloader不太容易导致争用，毕竟class只需要加载一次。但是有
些情况下可不向你想象的那样，看下面这个这个线程栈：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;quot;[ACTIVE] ExecuteThread: &#39;1&#39; for queue: &#39;weblogic.kernel.Default (self-tuning)&#39;&amp;quot; daemon prio=10 tid=0x00007fbccc001000 nid=0x6dbc waiting for monitor entry [0x00007fbd11e20000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:270)
	at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:624)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1611)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1516)
	at java.io.ObjectInputStream.readClass(ObjectInputStream.java:1482)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1332)
	at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1705)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1343)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:369)
	at java.util.HashMap.readObject(HashMap.java:1047)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1001)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1892)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1797)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1349)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1989)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1914)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1797)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1349)
	at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1705)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1343)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1989)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1914)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1797)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1349)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:369)
	at com.primeton.access.client.impl.processor.CommonServiceProcessor.process(CommonServiceProcessor.java:49)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;堵在classloader上了，正常情况下，我们当然想知道到底什么class需要这么频繁的加载。
以前你只能debug，加日志调试，现在我们来看看神奇的byteman怎么做到的。&lt;/p&gt;

&lt;p&gt;我们知道加载class必须走java.lang.ClassLoader的loadClass，我们可以用byteman拦截
这个方法的执行，打印出调用栈和方法参数即可。&lt;/p&gt;

&lt;h3 id=&#34;环境配置&#34;&gt;环境配置&lt;/h3&gt;

&lt;p&gt;我这里的测试环境是oracle-jdk6/ubuntu 12.04/weblogic10.3.6，byteman版本是2.1.4。
需要我们设置BYTEMAN_HOME环境变量，并把BYTEMAN_HOME/bin加入到PATH中。&lt;/p&gt;

&lt;h3 id=&#34;动态打开byteman监听&#34;&gt;动态打开byteman监听&lt;/h3&gt;

&lt;p&gt;正常启动需要profile的weblogic应用，之后通过jps获取进程号：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@tacy:/home/tacy/mytools/systemtap# jps -l
14677 org.apache.catalina.startup.Bootstrap
18224 weblogic.Server
28485 /home/tacy/mytools/java/eclipse//plugins/org.eclipse.equinox.launcher_1.2.0.v20110502.jar
18256 sun.tools.jps.
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;获取到weblogic的pid为18224，然后另开一终端，通过bminstall动态打开监听：&lt;/dt&gt;
&lt;dd&gt;root@tacy:~# bminstall.sh -b -Dorg.jboss.byteman.transform.all -Dorg.jboss.byteman.verbose -p 60000 18224
打开之后你能在weblogic的终端看到如下输出：
&lt;code&gt;shell
Setting org.jboss.byteman.transform.all=
Setting org.jboss.byteman.verbose=
&lt;/code&gt;
同时你能通过netstat查看到weblogic增加了一个监听端口在60000上。&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;注意这里我们设置了verbose，真正使用的时候你不需要，主要是前提脚本调试阶段需要看
看规则脚本是否执行了，确定脚本没问题就可以去掉。&lt;/p&gt;

&lt;p&gt;另外就是org.jboss.byteman.transform.all这个参数，如果你要拦截java.lang类似的包，
必须设置，否则拦截不到。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;org.jboss.byteman.transform.all
is set then the agent will allow rules to be injected into methods of classes
in the java.lang hierarchy. Note that this will require the Byteman jar to be
installed in the bootstrap classpath using the boot: option to the -javaagent
JVM command line argument.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;脚本&#34;&gt;脚本&lt;/h3&gt;

&lt;p&gt;接下来我们先写一个如下的byteman脚本：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;RULE classloader profile
CLASS java.lang.ClassLoader
METHOD loadClass(java.lang.String, boolean)
IF callerCheck(&amp;quot;com\.primeton.*&amp;quot;, true, true,true,0,200)
DO traceln(&amp;quot;load class: &amp;quot; + $1),traceStack(&amp;quot;Thread Stack**********************:&amp;quot;)
ENDRULE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体语法我就不解释了，自己看文档，简单说就是拦截loadclass方法，如果发现调用栈里
面有匹配com.primeton.*字符串，就输出方法参数和调用栈。&lt;/p&gt;

&lt;p&gt;脚本是否正确可以通过bmcheck来进行校验。&lt;/p&gt;

&lt;h3 id=&#34;提交脚本&#34;&gt;提交脚本&lt;/h3&gt;

&lt;p&gt;直接使用bmsubmit进行脚本提交：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@tacy:~# bmsubmit.sh -p 60000 -l test.bm
define rule classloader profile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后回到weblogic终端窗口就能看到效果了&lt;/p&gt;

&lt;h3 id=&#34;输出&#34;&gt;输出&lt;/h3&gt;

&lt;p&gt;执行你的业务功能，你可以看到如下输出：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;load class: long
Thread Stack**********************:java.lang.ClassLoader.loadClass(ClassLoader.java:-1)
java.lang.ClassLoader.loadClass(ClassLoader.java:295)
sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
java.lang.ClassLoader.loadClass(ClassLoader.java:295)
java.lang.ClassLoader.loadClass(ClassLoader.java:295)
java.lang.ClassLoader.loadClass(ClassLoader.java:247)
weblogic.utils.classloaders.GenericClassLoader.loadClass(GenericClassLoader.java:179)
weblogic.utils.classloaders.FilteringClassLoader.findClass(FilteringClassLoader.java:101)
weblogic.utils.classloaders.FilteringClassLoader.loadClass(FilteringClassLoader.java:86)
java.lang.ClassLoader.loadClass(ClassLoader.java:295)
java.lang.ClassLoader.loadClass(ClassLoader.java:295)
java.lang.ClassLoader.loadClass(ClassLoader.java:247)
weblogic.utils.classloaders.GenericClassLoader.loadClass(GenericClassLoader.java:179)
weblogic.utils.classloaders.ChangeAwareClassLoader.loadClass(ChangeAwareClassLoader.java:52)
java.lang.Class.forName0(Class.java:-2)
java.lang.Class.forName(Class.java:249)
java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:602)
java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1589)
java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1494)
java.io.ObjectInputStream.readClass(ObjectInputStream.java:1460)
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1310)
java.io.ObjectInputStream.readArray(ObjectInputStream.java:1683)
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1321)
java.io.ObjectInputStream.readObject(ObjectInputStream.java:349)
java.util.HashMap.readObject(HashMap.java:1030)
sun.reflect.GeneratedMethodAccessor2.invoke (Unknown Source)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
java.lang.reflect.Method.invoke(Method.java:597)
java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:969)
java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1871)
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1775)
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1327)
java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1969)
java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1775)
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1327)
java.io.ObjectInputStream.readArray(ObjectInputStream.java:1683)
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1321)
java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1969)
java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1775)
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1327)
java.io.ObjectInputStream.readObject(ObjectInputStream.java:349)
com.primeton.access.client.impl.processor.CommonServiceProcessor.process(CommonServiceProcessor.java:49)
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;问题一目了然了吧，人家在加载long.class，我们知道这是个java的原生类型，哪有啥
class啊，其实这个问题是ObjectInputStream里没有处理好，请看下面代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;    protected Class&amp;lt;?&amp;gt; resolveClass(ObjectStreamClass desc)
	throws IOException, ClassNotFoundException
    {
	String name = desc.getName();
	try {
	    return Class.forName(name, false, latestUserDefinedLoader());
	} catch (ClassNotFoundException ex) {
	    Class cl = (Class) primClasses.get(name);
	    if (cl != null) {
		return cl;
	    } else {
		throw ex;
	    }
	}
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里他先去通过class.forName找，classloader也比较蠢，不分青红皂白，发现没有加载过
，就去加载，发现找不到就扔异常，然后resolvClass尝试看看是不是原生类型。解决这个
问题你可以自己写一个扩展类，把primClasses.get(name)放到前面即可。&lt;/p&gt;

&lt;p&gt;这种问题在小并发情况下其实问题不大，但是当并发量一大的时候，都挂在classloader上
了。&lt;/p&gt;

&lt;h2 id=&#34;property&#34;&gt;property&lt;/h2&gt;

&lt;p&gt;两个和性能相关的property：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;If system property
org.jboss.byteman.compileToBytecode
is set (with any value) then the rule execution engine will compile rules to bytecode before executing them. If this property is unset it will execute rules by interpreting the rule parse tree.
Transformations performed by the agent can be observed by setting several environment variables which cause the transformed bytecode to be dumped to disk.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;If system property
org.jboss.byteman.skip.overriding.rules
is set then the agent will not perform injection into overriding method implementations. If an overriding rule is installed the agent will print a warning to System.err and treat the rule as if it applies only to the class named in the CLASS clause. This setting is not actually provided to allow rules to be misused in this way. It is a performance tuning option. The agent has to check every class as it is loaded in order to see if there are rules which apply to it. It also has to check all loaded classes when rules are dynamically loaded via the agent listener. This requires traversing the superclass chain to locate overriding rules attached to superclasses. This increases the cost of running the agent (testig indicates that the cost goes from negligible (&amp;lt;&amp;lt; 1%) to, at worst, noticeable (~ 2%) but not to significant) So, if you do not intend to use overriding rules then setting this property helps to minimise the extent to which the agent perturbs the timing of application runs. This is particularly important when testing multi-threaded applications where timing is highly significant.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;脚本编写tips&#34;&gt;脚本编写TIPS&lt;/h2&gt;

&lt;p&gt;脚本编写的时候有些地方比较晦涩，下面一些例子&lt;/p&gt;

&lt;h3 id=&#34;callerequals&#34;&gt;callerEquals&lt;/h3&gt;

&lt;dl&gt;
&lt;dd&gt;public boolean callerEquals(String name)
这是要你只要写方法名，不能带其他的东西，比如你只关心某个入口的方法调用效率：&lt;/dd&gt;
&lt;dd&gt;IF callerEquals(&amp;ldquo;methodname&amp;rdquo;)
你也可以可以带上类名，前提是需要用下面方法：&lt;/dd&gt;
&lt;dd&gt;public boolean callerEquals(String name,boolean includeClass)
写法如下：&lt;/dd&gt;
&lt;dd&gt;IF callerEquals(&amp;ldquo;classname.methodname&amp;rdquo;,true)
依此类推，你也可以带上报名，但是千万别这么写：&lt;/dd&gt;
&lt;dd&gt;IF callerEquals(&amp;ldquo;classname.methodname&amp;rdquo;)
这是匹配不上的，byteman会把&amp;rdquo;classname.methodname&amp;rdquo;当成方法名，当然就悲剧了～&lt;/dd&gt;
&lt;/dl&gt;

&lt;h2 id=&#34;脚本例子&#34;&gt;脚本例子&lt;/h2&gt;

&lt;h3 id=&#34;方法执行效率统计-methodexectime&#34;&gt;方法执行效率统计（methodExectime）&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;RULE entey readobject
CLASS com.primeton.access.client.impl.processor.CommonServiceProcessor
METHOD process
AT INVOKE readObject
IF true
DO resetTimer($0)
ENDRULE

RULE exit readobject
CLASS com.primeton.access.client.impl.processor.CommonServiceProcessor
METHOD process
AFTER INVOKE readObject
IF true
DO System.out.println(String.valueOf(getElapsedTimeFromTimer($0)))
ENDRULE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意这里的输出用的是Systemoutprint，byteman内置的traceln有性能问题。&lt;/p&gt;

&lt;h2 id=&#34;自定义rule-helper&#34;&gt;自定义RULE Helper&lt;/h2&gt;

&lt;p&gt;几个参考[fn:2][fn:3][fn:4]&lt;/p&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;https://community.jboss.org/wiki/ABytemanTutorial][A&#34;&gt;https://community.jboss.org/wiki/ABytemanTutorial][A&lt;/a&gt; Byteman Tutorial]]&lt;/p&gt;

&lt;p&gt;[fn:2] [[&lt;a href=&#34;http://www.mastertheboss.com/byteman/byteman-advanced-tutorial][Byteman&#34;&gt;http://www.mastertheboss.com/byteman/byteman-advanced-tutorial][Byteman&lt;/a&gt; advanced tutorial]]&lt;/p&gt;

&lt;p&gt;[fn:3] [[&lt;a href=&#34;http://rreddy.blogspot.jp/2013/08/byteman-oracle-jdbc-tracing.html][Byteman&#34;&gt;http://rreddy.blogspot.jp/2013/08/byteman-oracle-jdbc-tracing.html][Byteman&lt;/a&gt; Oracle JDBC Tracing]]&lt;/p&gt;

&lt;p&gt;[fn:4] [[&lt;a href=&#34;http://blog.c2b2.co.uk/2012/07/using-custom-helpers-with-byteman.html][Using&#34;&gt;http://blog.c2b2.co.uk/2012/07/using-custom-helpers-with-byteman.html][Using&lt;/a&gt; Custom Helpers with Byteman]]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>systemtap notes</title>
      <link>http://tacy.github.io/post/systemtap/</link>
      <pubDate>Tue, 10 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/systemtap/</guid>
      
        <description>

&lt;h1 id=&#34;systemtap&#34;&gt;Systemtap&lt;/h1&gt;

&lt;p&gt;systemtap是红帽开发的一款分析工具，如果你需要使用的话，最好在redhat的系统上，在
Ubuntu上兼容性不好，坑非常多，Ubuntu缺省提供的Kernel无法正常运行Systemtap，只能
跑跑HelloWorld，带的那些脚本都无法跑通，没法用。只能自己重新编译kernel，修改一些
CFLAGS参数。&lt;/p&gt;

&lt;p&gt;我电脑使用的是ubuntu 12.04，kernel用的是trusy版本的3.13，Systemtap缺省版本是1.6
，没法用。&lt;/p&gt;

&lt;h2 id=&#34;使用前提&#34;&gt;使用前提&lt;/h2&gt;

&lt;p&gt;systemtap依赖dbgsym包，你必须安装kernel的dbgsym包，这个包在ubuntu的ddeb源提供[fn:1]，
系统缺省不包括，需要自己添加：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@tacy:~$echo &amp;quot;deb http://ddebs.ubuntu.com $(lsb_release -cs) main restricted universe multiverse
deb http://ddebs.ubuntu.com $(lsb_release -cs)-updates main restricted universe multiverse
deb http://ddebs.ubuntu.com $(lsb_release -cs)-security main restricted universe multiverse
deb http://ddebs.ubuntu.com $(lsb_release -cs)-proposed main restricted universe multiverse&amp;quot; | \
sudo tee -a /etc/apt/sources.list.d/ddebs.list

tacy@tacy:~$sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 428D7C01

tacy@tacy:~$apt-get update
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后你就能看到很多dbgsym包，先安装对应kernel的&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@tacy:~$ uname -a
Linux tacy 3.13.0-27-generic #50~precise1-Ubuntu SMP Fri May 16 20:47:56 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux
tacy@tacy:~$ apt-cache policy linux-image-3.13.0-27-generic
linux-image-3.13.0-27-generic:
  已安装：  3.13.0-27.50~precise1
  候选软件包：3.13.0-27.50~precise1
  版本列表：
### 3.13.0-27.50~precise1 0
        500 http://mirrors.ustc.edu.cn/ubuntu/ precise-updates/main amd64 Packages
        500 http://mirrors.ustc.edu.cn/ubuntu/ precise-security/main amd64 Packages
        100 /var/lib/dpkg/status
tacy@tacy:~$ sudo apt-get install linux-image-3.13.0-27-generic-dbgsym=3.13.0-27.50~precise1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然上面的前提是ubuntu提供的kernel没问题的前提下，如果你想在ubuntu下跑systemtap
可没那么轻松，必须自己编译kernel和dbgsym！&lt;/p&gt;

&lt;h2 id=&#34;编译&#34;&gt;编译&lt;/h2&gt;

&lt;h3 id=&#34;kernel编译&#34;&gt;kernel编译&lt;/h3&gt;

&lt;p&gt;导致ubuntu提供的kernel不能运行的systemtap的根本问题还是gcc，gcc的一些bug导致
产生了错误的debuginfo，无法正确定位变量[fn:3]，产生如下错误信息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;semantic error: not accessible at this address [man error::dwarf] (0xffffffff811b42b0, dieoffset: 0x177422e): identifier &#39;$file&#39; at /usr/share/systemtap/tapset/linux/vfs.stp:855:9
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然systemtap对此问题进行了修正，但是它需要有gcc编译时使用的编译参数才行。gcc提
供了一个参数来记录编译时参数，但是ubuntu编译kernel的时候并没有带上这个参数，导
致systemtap无法正确定位参数的位置，另外gcc的这个参数只有在4.7以上版本才有，而
12.04缺省带的gcc版本是4.6！&lt;/p&gt;

&lt;p&gt;所以基于上面这些问题，我们需要做两件事情，首先是升级gcc版本到4.7，接下来是编译
kernel，同时加上gcc参数来记录编译项。&lt;/p&gt;

&lt;p&gt;升级gcc我就不详细介绍了，直接参考VK的文章[fn:4]。&lt;/p&gt;

&lt;p&gt;编译kernel最关键的是修改gcc编译参数，这个问题搞了好几天，没办法，对kernel还是不
熟。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;首先是你需要知道ubuntu下编译kernel的基本流程[fn:5]。参考引用，我们先获取代码：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;apt-get source linux-image-&lt;code&gt;uname -r&lt;/code&gt;&lt;/p&gt;&lt;/dd&gt;
&lt;dt&gt;接下来你需要进入源码目录，修改最上层目录下的Makefile，我的目录如下：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;/home/tacy/Downloads/linux-lts-trusty-3.13.0/Makefile&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;修改内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;HOSTCFLAGS   = -Wall -Wmissing-prototypes -Wstrict-prototypes -grecord-gcc-switches -O2 -fno-omit-frame-pointer
HOSTCXXFLAGS = -O2 -fno-omit-frame-pointer -grecord-gcc-switches
。。。
KBUILD_CFLAGS   += -O2 -grecord-gcc-switches
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要是添加‘-grecord-gcc-switches‘和’-fno-omit-frame-pointer‘参数。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;接下来就是编译了，如果你需要修改编译模块，直接用下面命令：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;fakeroot debian/rules editconfigs&lt;/p&gt;&lt;/dd&gt;
&lt;dd&gt;&lt;p&gt;fakeroot debian/rules updateconfigs&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;注意下面项需要打开[fn:6]&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# for perf_events:
CONFIG_PERF_EVENTS=y
# for stack traces:
CONFIG_FRAME_POINTER=y
# kernel symbols:
CONFIG_KALLSYMS=y
# tracepoints:
CONFIG_TRACEPOINTS=y
# kernel function trace:
CONFIG_FTRACE=y
# kernel-level dynamic tracing:
CONFIG_KPROBES=y
CONFIG_KPROBE_EVENTS=y
# user-level dynamic tracing:
CONFIG_UPROBES=y
CONFIG_UPROBE_EVENTS=y
# full kernel debug info:
CONFIG_DEBUG_INFO=y
# kernel lock tracing:
CONFIG_LOCKDEP=y
# kernel lock tracing:
CONFIG_LOCK_STAT=y
# kernel dynamic tracepoint variables:
CONFIG_DEBUG_INFO=y
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;编译：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;fakeroot debian/rules binary-generic skipdbg=false&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;然后安装编译包就行了，需要注意的时候编译过程会会占用16G左右的空间，并且编译过程
非常漫长，在我机器上跑了将近一个半小时，考验耐性～&lt;/p&gt;

&lt;h3 id=&#34;systemtap-1&#34;&gt;systemtap&lt;/h3&gt;

&lt;p&gt;没啥特殊的，注意elfutils版本就行，缺省的0.152好像没问题。我编译了systemtap 2.5版
本，可以用，直接下载的源码包编译就行。&lt;/p&gt;

&lt;h2 id=&#34;使用&#34;&gt;使用&lt;/h2&gt;

&lt;p&gt;看看使用效果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@tacy:/usr/local/share/doc/systemtap/examples/io$ sudo stap disktop.stp

Fri Jul  4 15:14:07 2014 , Average:  50Kb/sec, Read:     219Kb, Write:     32Kb

     UID      PID     PPID                       CMD   DEVICE    T        BYTES
    1000     2496     1861                    oracle     sda5    R       131072
    1000     2832        1           unity-panel-ser     sda5    R        76217
    1000     2496     1861                    oracle     sda5    W        32768
    1000     2834        1               hud-service     dm-1    R        16192
    1000     2689        1                   dropbox     sda5    R          894

Fri Jul  4 15:14:12 2014 , Average:  42Kb/sec, Read:     192Kb, Write:     18Kb

     UID      PID     PPID                       CMD   DEVICE    T        BYTES
    1000     2496     1861                    oracle     sda5    R       131072
    1000     8893     1861                    oracle     sda5    R        65944
    1000     2496     1861                    oracle     sda5    W        16384
    1000     5157        1           Chrome_CacheThr     dm-1    W         2033
    1000     2953        1            gnome-terminal     sda5    W         1025
    1000     5157        1           Chrome_CacheThr     dm-1    R           36
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;好了，ubuntu上也能systemtap啦～&lt;/p&gt;

&lt;h2 id=&#34;systemtap-byteman&#34;&gt;systemtap &amp;amp; byteman&lt;/h2&gt;

&lt;p&gt;另外需要注意的是systemtap可以配合byteman使用，但是～，基本上别抱啥希望，我尝试
了一下，问题一堆，能正常编译，无法使用，当然你也可以试试，一些需要注意的点：&lt;/p&gt;

&lt;p&gt;仔细看systemtap源代码中java目录下的readme，这里有好几个坑：&lt;/p&gt;

&lt;p&gt;首先是编译的时候要指定&amp;ndash;with-java选项，否则不支持。&lt;/p&gt;

&lt;p&gt;另一个是BYTEMAN_HOME，你从jboss网站上下载下来的byteman解压之后，jar包在lib目录下，
但是stapbm脚本直接忽略了lib目录，也就是说你找不到jar包，没有任何提示，无法成功。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;有如下内容：&lt;/dt&gt;
&lt;dd&gt;process(\&amp;ldquo;/usr/local/libexec/systemtap/libHelperSDT_amd64.so\&amp;ldquo;).
人家明确写的是systemtap下的so文件，如果你拷贝到jdk目录下，直接无视，泪啊～～～，
为啥在README里面要写copy/link呢？&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;sr/local/libexec/systemtap/libHelperSDT_amd64.so\&amp;ldquo;).
人家明确写的是systemtap下的so文件，如果你拷贝到jdk目录下，直接无视，泪啊～～～，
为啥在README里面要写copy/link呢？&lt;/p&gt;

&lt;p&gt;最后一个，必须是同一个用户的进程才行，也就是说如果你用root去分析其他用户的java进
程，不好意思，同样无视～～～&lt;/p&gt;

&lt;p&gt;解决上面问题之后，简单的例子能跑了[fn:2]，但是我尝试了一下对weblogic做profile，
不行，一直抛如下错误，放弃～&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;org.jboss.byteman.rule.exception.ExecuteException: stap_672db8a0071794f3697f800e2d70a51_22140probe_2237  : caught java.lang.ClassCircularityError: sun/reflect/MethodAccessorImpl
	at org.jboss.byteman.rule.Rule.execute(Rule.java:716)
	at org.jboss.byteman.rule.Rule.execute(Rule.java:653)
	at java.lang.ClassLoader.loadClass(ClassLoader.java)
	at sun.misc.Unsafe.defineClass(Native Method)
	at sun.reflect.ClassDefiner.defineClass(ClassDefiner.java:45)
	at sun.reflect.MethodAccessorGenerator$1.run(MethodAccessorGenerator.java:381)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.reflect.MethodAccessorGenerator.generate(MethodAccessorGenerator.java:377)
	at sun.reflect.MethodAccessorGenerator.generateMethod(MethodAccessorGenerator.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:28)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.jboss.byteman.rule.expression.MethodExpression.interpret(MethodExpression.java:342)
	at org.jboss.byteman.rule.Action.interpret(Action.java:144)
	at org.systemtap.byteman.helper.HelperSDT_HelperAdapter_Interpreted_1.fire(tacy-22167.btm)
	at org.systemtap.byteman.helper.HelperSDT_HelperAdapter_Interpreted_1.execute0(tacy-22167.btm)
	at org.systemtap.byteman.helper.HelperSDT_HelperAdapter_Interpreted_1.execute(tacy-22167.btm)
	at org.jboss.byteman.rule.Rule.execute(Rule.java:684)
	at org.jboss.byteman.rule.Rule.execute(Rule.java:653)
	at java.lang.ClassLoader.loadClass(ClassLoader.java)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:249)
	at sun.rmi.server.LoaderHandler.loadClass(LoaderHandler.java:152)
	at java.rmi.server.RMIClassLoader$2.loadClass(RMIClassLoader.java:620)
	at java.rmi.server.RMIClassLoader.loadClass(RMIClassLoader.java:247)
	at sun.rmi.server.MarshalInputStream.resolveClass(MarshalInputStream.java:201)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1589)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1494)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1748)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1327)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:349)
	at sun.rmi.server.UnicastRef.unmarshalValue(UnicastRef.java:306)
	at sun.rmi.server.UnicastRef.invoke(UnicastRef.java:155)
	at com.sun.jmx.remote.internal.PRef.invoke(Unknown Source)
	at javax.management.remote.rmi.RMIConnectionImpl_Stub.getAttribute(Unknown Source)
	at javax.management.remote.rmi.RMIConnector$RemoteMBeanServerConnection.getAttribute(RMIConnector.java:878)

&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;https://wiki.ubuntu.com/DebuggingProgramCrash][Debugging&#34;&gt;https://wiki.ubuntu.com/DebuggingProgramCrash][Debugging&lt;/a&gt; Program Crash]]&lt;/p&gt;

&lt;p&gt;[fn:2] [[&lt;a href=&#34;http://developerblog.redhat.com/2014/01/10/probing-java-w-systemtap/][Probing&#34;&gt;http://developerblog.redhat.com/2014/01/10/probing-java-w-systemtap/][Probing&lt;/a&gt; java methods with systemtap]]&lt;/p&gt;

&lt;p&gt;[fn:3] [[&lt;a href=&#34;http://sourceware-org.1504.n7.nabble.com/semantic-error-not-accessible-at-this-address-td245602.html][semantic&#34;&gt;http://sourceware-org.1504.n7.nabble.com/semantic-error-not-accessible-at-this-address-td245602.html][semantic&lt;/a&gt; error: not accessible at this address]]&lt;/p&gt;

&lt;p&gt;[fn:4] [[&lt;a href=&#34;http://www.swiftsoftwaregroup.com/upgrade-gcc-4-7-ubuntu-12-04/][How&#34;&gt;http://www.swiftsoftwaregroup.com/upgrade-gcc-4-7-ubuntu-12-04/][How&lt;/a&gt; to upgrade GCC to 4.7+ on Ubuntu 12.04]]&lt;/p&gt;

&lt;p&gt;[fn:5] [[&lt;a href=&#34;https://help.ubuntu.com/community/Kernel/Compile][Ubuntu&#34;&gt;https://help.ubuntu.com/community/Kernel/Compile][Ubuntu&lt;/a&gt; Kernel Compile]]&lt;/p&gt;

&lt;p&gt;[fn:6] [[&lt;a href=&#34;http://www.brendangregg.com/perf.html#Building][perf&#34;&gt;http://www.brendangregg.com/perf.html#Building][perf&lt;/a&gt; Examples]]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>perf notes</title>
      <link>http://tacy.github.io/post/linux-perf/</link>
      <pubDate>Wed, 04 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/linux-perf/</guid>
      
        <description>

&lt;h1 id=&#34;perf&#34;&gt;perf&lt;/h1&gt;

&lt;p&gt;strace相性对于很多熟悉linux的人来说应该都有所了解，使用起来也非常方便，但是他也
有很多问题，容易导致进程响应缓慢等，当然他对于诊断简单问题，比如进程起不来，进程
挂起等，非常好用，但是更深入的性能问题，就需要用到perf了，而perf最好的教程，看大
牛Brendan Gregg写的perf相关文章[fn:1]。我这里主要在使用过程中的一些理解。&lt;/p&gt;

&lt;h2 id=&#34;ubuntu下的perf&#34;&gt;ubuntu下的perf&lt;/h2&gt;

&lt;p&gt;我机器上的ubuntu版本是12.04，但是使用的kernel版本是&lt;/p&gt;

&lt;h1 id=&#34;perf-1&#34;&gt;perf&lt;/h1&gt;

&lt;p&gt;strace相性对于很多熟悉linux的人来说应该都有所了解，使用起来也非常方便，但是他也
有很多问题，容易导致进程响应缓慢等，当然他对于诊断简单问题，比如进程起不来，进程
挂起等，非常好用，但是更深入的性能问题，就需要用到perf了，而perf最好的教程，看大
牛Brendan Gregg写的perf相关文章[fn:1]。我这里主要在使用过程中的一些理解。&lt;/p&gt;

&lt;h2 id=&#34;ubuntu下的perf-1&#34;&gt;ubuntu下的perf&lt;/h2&gt;

&lt;dl&gt;
&lt;dt&gt;我机器上的ubuntu版本是12.04，但是使用的kernel版本是&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;linux-image-generic-lts-trusty: 已安装：  3.13.0.27.23&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;sudo stap -L &amp;lsquo;process(&amp;ldquo;/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server/libjvm.so&amp;rdquo;).function(&amp;rdquo;*&amp;ldquo;)&amp;rsquo;&lt;/p&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;http://www.brendangregg.com/perf.html][perf&#34;&gt;http://www.brendangregg.com/perf.html][perf&lt;/a&gt; Examples]]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>FFmpeg使用笔记</title>
      <link>http://tacy.github.io/post/ffmpeg/</link>
      <pubDate>Mon, 14 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/ffmpeg/</guid>
      
        <description>

&lt;h1 id=&#34;ffmpeg&#34;&gt;FFmpeg&lt;/h1&gt;

&lt;p&gt;视频压缩首先想到的自然是FFmpeg，我用的是Ubuntu，很不幸Ubuntu用Libav提到了FFmpeg
，具体为啥有了Libav建议libav官网八卦去，反正就是一些开发人员对项目管理者不满另起
炉灶啥的，这个暂且不提了[fn:6]。&lt;/p&gt;

&lt;p&gt;关键是，Libav的资料太少了，去官网看了一下WIKI，直接就没兴趣用了，Google上搜索也
没有太多使用经验，虽然和FFmpeg大致相同，但总觉的别扭。我想把视频转成X264加AAC格
式，采用VBR方式（就是动态码率，更好的压缩比和视频质量），看了一下X264没问题，但
是AAC有好几个实现，其中最好的libfdk_aac不是GPL的license，所以Libav提供的版本不支
持，也就是说我需要自己编译[fn:1]。关键是这玩意编译还依赖很多外部包，人家FFmpeg编
译文档写的很清晰，Libav啥都没有。没办法，直接干掉，换FFmpeg来[fn:2]。&lt;/p&gt;

&lt;h1 id=&#34;转码压缩&#34;&gt;转码压缩&lt;/h1&gt;

&lt;dl&gt;
&lt;dt&gt;发现没啥可写的[fn:3][fn:4][fn:5]，别人都写的太清楚了，这里直接上我的命令吧：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;ffmpeg -i IMG_2596.MOV -c:v libx264 -crf 28 -c:a libfdk_aac -vbr 4 output.mp4&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;最后压缩下来，一个7分42秒的视频大概114M左右，之前可是650M，播放了一下，看不出啥
区别，效果不错，就是FFmpeg貌似不是那么高效，CPU都在nice状态，找个时间分析一下。&lt;/p&gt;

&lt;p&gt;这里唯一需要解释一下的就是crf参数，该参数取值范围在0～51，值越低质量越高，当然
文件也越大，缺省值是23，一般18～28之间是比较合适的值，太低文件太大，太高图像质
量不高。该值±6对文件大小的影响基本上是一倍关系，+6文件大小缩小一半，-6文件大小
增加一倍[fn:7]。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;有91M：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;ffmpeg -i IMG_2596.MOV -c:v libx264 -crf 28 -preset:v veryfast -c:a libfdk_aac -vbr 4 output.mp4&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dt&gt;有91M：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;ffmpeg -i IMG_2596.MOV -c:v libx264 -crf 28 -preset:v veryfast -c:a libfdk_aac -vbr 4 output.mp4&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;t.mp4&lt;/p&gt;

&lt;p&gt;两者结果对比：&lt;/p&gt;

&lt;p&gt;命令一：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Stream mapping:
  Stream #0:0 -&amp;gt; #0:0 (h264 -&amp;gt; libx264)
  Stream #0:1 -&amp;gt; #0:1 (aac -&amp;gt; libfdk_aac)
Press [q] to stop, [?] for help
frame=11098 fps= 23 q=-1.0 Lsize=  111968kB time=00:07:42.33 bitrate=1983.9kbits/s dup=0 drop=5
video:107236kB audio:4392kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.304443%
[libx264 @ 0x27d10c0] frame I:70    Avg QP:27.89  size: 48280
[libx264 @ 0x27d10c0] frame P:6228  Avg QP:30.50  size: 13988
[libx264 @ 0x27d10c0] frame B:4800  Avg QP:32.41  size:  4024
[libx264 @ 0x27d10c0] consecutive B-frames: 13.5% 86.4%  0.1%  0.0%
[libx264 @ 0x27d10c0] mb I  I16..4: 15.7% 59.1% 25.2%
[libx264 @ 0x27d10c0] mb P  I16..4:  0.9%  1.8%  0.4%  P16..4: 61.4%  9.1%  8.4%  0.0%  0.0%    skip:18.1%
[libx264 @ 0x27d10c0] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 48.7%  1.1%  0.1%  direct: 1.8%  skip:48.2%  L0:36.7% L1:62.5% BI: 0.8%
[libx264 @ 0x27d10c0] 8x8 transform intra:59.8% inter:73.3%
[libx264 @ 0x27d10c0] coded y,uvDC,uvAC intra: 58.3% 87.3% 46.3% inter: 15.6% 43.4% 2.3%
[libx264 @ 0x27d10c0] i16 v,h,dc,p: 18% 20% 19% 43%
[libx264 @ 0x27d10c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 11% 12% 27%  8% 10%  8% 10%  7%  8%
[libx264 @ 0x27d10c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 15% 18% 27%  7%  8%  6%  7%  5%  6%
[libx264 @ 0x27d10c0] i8c dc,h,v,p: 56% 18% 14% 11%
[libx264 @ 0x27d10c0] Weighted P-Frames: Y:0.2% UV:0.1%
[libx264 @ 0x27d10c0] ref P L0: 65.0% 14.6% 13.7%  6.8%  0.0%
[libx264 @ 0x27d10c0] ref B L0: 91.7%  8.3%  0.0%
[libx264 @ 0x27d10c0] ref B L1: 100.0%  0.0%
[libx264 @ 0x27d10c0] kb/s:1899.73
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;命令二：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Stream mapping:
  Stream #0:0 -&amp;gt; #0:0 (h264 -&amp;gt; libx264)
  Stream #0:1 -&amp;gt; #0:1 (aac -&amp;gt; libfdk_aac)
Press [q] to stop, [?] for help
frame=11098 fps= 68 q=-1.0 Lsize=   89166kB time=00:07:42.33 bitrate=1579.9kbits/s dup=0 drop=5
video:84434kB audio:4392kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.382292%
[libx264 @ 0x367f940] frame I:69    Avg QP:27.91  size: 44978
[libx264 @ 0x367f940] frame P:6244  Avg QP:30.60  size: 11357
[libx264 @ 0x367f940] frame B:4785  Avg QP:32.14  size:  2600
[libx264 @ 0x367f940] consecutive B-frames: 13.8% 86.1%  0.1%  0.0%
[libx264 @ 0x367f940] mb I  I16..4: 45.3% 31.8% 23.0%
[libx264 @ 0x367f940] mb P  I16..4: 16.9%  2.9%  0.1%  P16..4: 38.6% 11.3%  3.8%  0.0%  0.0%    skip:26.3%
[libx264 @ 0x367f940] mb B  I16..4:  0.7%  0.1%  0.0%  B16..8:  9.9%  1.8%  0.1%  direct:17.4%  skip:70.0%  L0:36.8% L1:53.3% BI: 9.9%
[libx264 @ 0x367f940] 8x8 transform intra:15.2% inter:10.3%
[libx264 @ 0x367f940] coded y,uvDC,uvAC intra: 18.6% 73.0% 27.4% inter: 7.1% 29.0% 0.6%
[libx264 @ 0x367f940] i16 v,h,dc,p: 41% 26% 26%  8%
[libx264 @ 0x367f940] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 10% 15% 47%  4%  5%  4%  5%  4%  5%
[libx264 @ 0x367f940] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 15% 20% 25%  8%  8%  6%  7%  5%  7%
[libx264 @ 0x367f940] i8c dc,h,v,p: 59% 19% 17%  5%
[libx264 @ 0x367f940] Weighted P-Frames: Y:0.2% UV:0.1%
[libx264 @ 0x367f940] kb/s:1495.79
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;批量处理目录下的视频：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;for i in $(ls *.MOV); do ffmpeg -i $i -c:v libx264 -crf 28 -preset:v veryfast -c:a libfdk_aac -vbr 4 $i.mp4; done&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;h1 id=&#34;旋转视频&#34;&gt;旋转视频&lt;/h1&gt;

&lt;dl&gt;
&lt;dt&gt;我需要垂直旋转我的视频，命令如下：&lt;/dt&gt;
&lt;dd&gt;fffmpeg -i IMG_0758.MOV -c:v libx264 -crf 28 -preset:v veryfast -c:a libfdk_aac -vbr 4 -vf &amp;ldquo;vflip&amp;rdquo; IMG_0758.MOV.mp4
垂直选择的参数是hflip，其他的90度旋转参考注脚8即可。&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;c -vbr 4 -vf &amp;ldquo;vflip&amp;rdquo; IMG_0758.MOV.mp4
垂直选择的参数是hflip，其他的90度旋转参考注脚8即可。&lt;/p&gt;

&lt;h1 id=&#34;结尾&#34;&gt;结尾&lt;/h1&gt;

&lt;p&gt;总之，FFmpeg是一个非常强大的开源视频处理工具，你能做各种事情（参考ffmpeg-filters
手册），使用它能对你的视频做各种处理，比如去logo，添加字幕，声轨，甚至合并声轨、
裁剪尺寸等，等待你去挖掘了。&lt;/p&gt;

&lt;p&gt;最终我成功把我40G的视频压缩到5G，效果明显。&lt;/p&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;http://unix.stackexchange.com/questions/77687/how-do-i-convert-flac-files-to-aac-preferrably-vbr-320k][How&#34;&gt;http://unix.stackexchange.com/questions/77687/how-do-i-convert-flac-files-to-aac-preferrably-vbr-320k][How&lt;/a&gt; do I convert FLAC files to AAC]]&lt;/p&gt;

&lt;p&gt;[fn:2] [[&lt;a href=&#34;https://trac.ffmpeg.org/wiki/UbuntuCompilationGuide][Compile&#34;&gt;https://trac.ffmpeg.org/wiki/UbuntuCompilationGuide][Compile&lt;/a&gt; FFmpeg on Ubuntu, Debian, or Mint]]&lt;/p&gt;

&lt;p&gt;[fn:3] [[&lt;a href=&#34;http://slhck.info/video-encoding][Video&#34;&gt;http://slhck.info/video-encoding][Video&lt;/a&gt; Encoding]]&lt;/p&gt;

&lt;p&gt;[fn:4] [[&lt;a href=&#34;http://trac.ffmpeg.org/wiki/AACEncodingGuide][FFmpeg&#34;&gt;http://trac.ffmpeg.org/wiki/AACEncodingGuide][FFmpeg&lt;/a&gt; and AAC Encoding Guide]]&lt;/p&gt;

&lt;p&gt;[fn:5] [[&lt;a href=&#34;http://trac.ffmpeg.org/wiki/x264EncodingGuide][FFmpeg&#34;&gt;http://trac.ffmpeg.org/wiki/x264EncodingGuide][FFmpeg&lt;/a&gt; and x264 Encoding Guide]]&lt;/p&gt;

&lt;p&gt;[fn:6] [[&lt;a href=&#34;http://superuser.com/questions/507386/libav-vs-ffmpeg-better-to-use-libav-avconv-today][libav&#34;&gt;http://superuser.com/questions/507386/libav-vs-ffmpeg-better-to-use-libav-avconv-today][libav&lt;/a&gt; vs ffmpeg - better to use libav (avconv) today]]&lt;/p&gt;

&lt;p&gt;[fn:7] [[&lt;a href=&#34;http://slhck.info/articles/crf][CRF&#34;&gt;http://slhck.info/articles/crf][CRF&lt;/a&gt; Guide]]&lt;/p&gt;

&lt;p&gt;[fn:8] [[&lt;a href=&#34;http://stackoverflow.com/questions/3937387/rotating-videos-with-ffmpeg][Rotating&#34;&gt;http://stackoverflow.com/questions/3937387/rotating-videos-with-ffmpeg][Rotating&lt;/a&gt; videos with FFmpeg]]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Docker使用笔记</title>
      <link>http://tacy.github.io/post/docker/</link>
      <pubDate>Fri, 04 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/docker/</guid>
      
        <description>

&lt;h1 id=&#34;docker-fn-1&#34;&gt;Docker[fn:1]&lt;/h1&gt;

&lt;p&gt;Docker是对LXC的一个抽象，依赖于LXC，相比KVM这种Hypervisor，LXC要轻量级很多[fn:2]
，但是LXC很难打包分发，Docker就是解决这个问题，当然还提供了一系列的辅助功能，本
文是自己在使用Docker使用过程中的一些记录。&lt;/p&gt;

&lt;h2 id=&#34;一个例子&#34;&gt;一个例子&lt;/h2&gt;

&lt;p&gt;先来感受一下，我想在我机器上跑一个Oracle，又不想跑在本地。之前都是通过KVM，然后
建一个Ubuntu虚拟机，安装OracleXE版本。用起来也挺方便，但还是觉得有些不爽，一个是
占地方，另外就是耗资源，开销挺大，多开几个就受不了。&lt;/p&gt;

&lt;p&gt;现在我们来看看Docker怎么玩，首先我们在docker仓库查找一下，看看是否有活雷锋：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@tacy:~$ sudo docker search oracle
NAME                              DESCRIPTION                                     STARS     OFFICIAL   TRUSTED
wnameless/oracle-xe-11g           SYS &amp;amp; SYSTEM password: oracle https://inde...   5                    [OK]
alexeiled/docker-oracle-xe-11g    This is a spin off from wnameless/docker-o...   2                    [OK]
haroon/docker-oracle-jdk7         Trusted Oracle JDK7 on Ubuntu:12.10             1                    [OK]
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;很幸运，不用你自己费劲弄了，直接pull下来吧：&lt;/dt&gt;
&lt;dd&gt;sudo docker pull wnameless/oracle-xe-11g
等待下载，时间比较长，接近1G的大小，完成之后来看看：
&lt;code&gt;shell
tacy@tacy:~$ sudo docker images
REPOSITORY                TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
wnameless/oracle-xe-11g   latest              f8d224b82290        17 hours ago        2.389 GB
ubuntu                    13.10               9f676bd305a4        8 weeks ago         178 MB
&lt;/code&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;接下来按照该Image的[[&lt;a href=&#34;https://index.docker.io/u/wnameless/oracle-xe-11g/][文档]]操作，直接启动一个Container（我这里添加了-name参数）：&#34;&gt;https://index.docker.io/u/wnameless/oracle-xe-11g/][文档]]操作，直接启动一个Container（我这里添加了-name参数）：&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@tacy:~$ sudo docker run -name oraclexe -d -p 49160:22 -p 49161:1521 wnameless/oracle-xe-11g
d14110dc542540c4b83a44d8ca7b9d393a9aa4be7a60cd1ca757463bc12df2a9
tacy@tacy:~$ ps -ef|grep docker
root      1599  1588  0 09:58 ?        00:02:43 /usr/bin/docker -d
root     14977  1599  0 16:10 ?        00:00:00 lxc-start -n d14110dc542540c4b83a44d8ca7b9d393a9aa4be7a60cd1ca757463bc12df2a9 -f /var/lib/docker/containers/d14110dc542540c4b83a44d8ca7b9d393a9aa4be7a60cd1ca757463bc12df2a9/config.lxc -- /.dockerinit -g 172.17.42.1 -i 172.17.0.2/16 -mtu 1500 -- /bin/sh -c sed -i -E &amp;quot;s/HOST = [^)]+/HOST = $HOSTNAME/g&amp;quot; /u01/app/oracle/product/11.2.0/xe/network/admin/listener.ora; service oracle-xe start; /usr/sbin/sshd -D
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;秒级启动，数据库连接信息：&lt;/dt&gt;
&lt;dd&gt;hostname: localhost port: 49161 sid: xe username: system password: oracle
sys用户密码是oracle，可以通过ssh连接到container，root密码是admin：
``` shell
tacy@tacy:~$ ssh root@localhost -p 49160
root@localhost&amp;rsquo;s password:
Welcome to Ubuntu 12.04 LTS (GNU/Linux 3.11.0-15-generic x86_64)&lt;/dd&gt;
&lt;/dl&gt;

&lt;h1 id=&#34;documentation-https-help-ubuntu-com&#34;&gt;Documentation:  &lt;a href=&#34;https://help.ubuntu.com/&#34;&gt;https://help.ubuntu.com/&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;root@d14110dc5425:~#&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
连接数据库:
``` shell
root@d14110dc5425:~# su - oracle
oracle@d14110dc5425:~$ sqlplus &#39;/as sysdba&#39;

SQL*Plus: Release 11.2.0.2.0 Production on Fri Apr 4 08:19:36 2014

Copyright (c) 1982, 2011, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Express Edition Release 11.2.0.2.0 - 64bit Production

SQL&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;停止container：&lt;/dt&gt;
&lt;dd&gt;tacy@tacy:~$ sudo docker stop oraclexe
或者：
&lt;code&gt;shell
tacy@tacy:~$ sudo docker ps
CONTAINER ID        IMAGE                            COMMAND                CREATED             STATUS              PORTS                                                      NAMES
d14110dc5425        wnameless/oracle-xe-11g:latest   /bin/sh -c sed -i -E   11 minutes ago      Up 11 minutes       0.0.0.0:49160-&amp;gt;22/tcp, 0.0.0.0:49161-&amp;gt;1521/tcp, 8080/tcp   oraclexe
tacy@tacy:~$ sudo docker stop d14110dc5425
d14110dc5425
tacy@tacy:~$ sudo docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
tacy@tacy:~$
&lt;/code&gt;&lt;/dd&gt;
&lt;dt&gt;重新启动该容器：&lt;/dt&gt;
&lt;dd&gt;tacy@tacy:~$ sudo docker start oraclexe&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;是不是很酷，还不赶紧去试试。&lt;/p&gt;

&lt;h2 id=&#34;运行一个db2-container&#34;&gt;运行一个DB2 Container&lt;/h2&gt;

&lt;p&gt;上面是个简单的例子，让你先对Docker有个认识，现在我们来自己配置一个Container，我
们一步一步来。&lt;/p&gt;

&lt;p&gt;假设说你希望有一个跑DB2 Express-C（DB2的免费版本）的Container，搜索一下，仓库里
没有，只能自己配置一个。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;，首先我们下载BASE的Image：&lt;/dt&gt;
&lt;dd&gt;sudo docker pull ubuntu&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dt&gt;，首先我们下载BASE的Image：&lt;/dt&gt;
&lt;dd&gt;sudo docker pull ubuntu&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dt&gt;Image：&lt;/dt&gt;
&lt;dd&gt;sudo docker pull ubuntu&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;接下来创建并运行一个Container[fn:7]：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@tacy:~$ sudo docker run -i -name db2exc -t ubuntu /bin/bash
root@4e476fda5fb5:/# uname -a
Linux 4e476fda5fb5 3.11.0-15-generic #23~precise1-Ubuntu SMP Tue Dec 10 16:39:48 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kernel版本和宿主机一致。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;们先来找找：&lt;/dt&gt;
&lt;dd&gt;sudo apt-cache search db2exc
显示没有这个包，由于db2exc属于Canonical Partner软件，查看一下apt源配置文件：
&lt;code&gt;shell
root@4e476fda5fb5:/etc/apt# pwd
/etc/apt
root@4e476fda5fb5:/etc/apt# cat sources.list
deb http://archive.ubuntu.com/ubuntu precise main universe
deb http://archive.ubuntu.com/ubuntu precise-updates main universe
deb http://archive.ubuntu.com/ubuntu precise-security main universe
&lt;/code&gt;
源没有包括Partner源，我们从宿主机拷贝配置文件过来（简单编辑一下文件也行），但是
找了一圈，没发现什么好办法直接从Host拷贝文件到Container，不行咱们先装SSH，通过
scp来：
&lt;code&gt;shell
root@4e476fda5fb5:/etc/apt# apt-get install ssh
root@4e476fda5fb5:/etc/apt# scp tacy@172.17.42.1:/etc/apt/sources.list .
tacy@172.17.42.1&#39;s password:
sources.list                                                                                                    100% 2278     2.2KB/s   00:00
root@4e476fda5fb5:/etc/apt# apt-get update
root@4e476fda5fb5:/etc/apt# apt-cache search db2exc
db2exc - DB2 Express-C 9.7 Fix Pack 5 for Linux
&lt;/code&gt;&lt;/dd&gt;
&lt;dt&gt;安装一下：&lt;/dt&gt;
&lt;dd&gt;apt-get install db2exc&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;db2exc
db2exc - DB2 Express-C 9.7 Fix Pack 5 for Linux&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
安装一下：
: apt-get install db2exc

完成之后，切换到db2inst1用户就可以创建数据库了（缺省没有建库），到这里貌似问题
就解决了？事情还没完呢，现在我希望能自动启动SSH服务和DB2，并且可以从外面管理数
据库和访问它。

尝试启动一下SSH服务：
``` shell
root@4e476fda5fb5:/usr/sbin# service ssh start
root@4e476fda5fb5:/usr/sbin# ps -ef|grep ssh
root@4e476fda5fb5:/usr/sbin#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;没反应，其实很正常，Container并没有启动upstart服务，为了保证Container的轻量级，
当你创建一个Container的时候，它只会启动你命令行指定的命令（一般在dockerfile），
我们的Container启动的是/bin/bash，所以如果你要启动ssh，可以通过下面方式启动：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@4e476fda5fb5:/usr/sbin# /usr/sbin/sshd -D
Missing privilege separation directory: /var/run/sshd
root@4e476fda5fb5:/usr/sbin# mkdir /var/run/sshd
root@4e476fda5fb5:/usr/sbin# /usr/sbin/sshd -D &amp;amp;
[1] 14
root@4e476fda5fb5:/usr/sbin# ps -ef|grep sshd
root        14     1  0 06:36 ?        00:00:00 /usr/sbin/sshd -D
root        16     1  0 06:36 ?        00:00:00 grep sshd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;能正常启动了，如果你想从外部连接进去，尝试一下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@tacy:/var/cache/apt/archives$ ssh root@172.17.0.26
ssh: connect to host 172.17.0.26 port 22: Connection refused
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;无法连接，你需要先把端口映射到Host上，另外你也不知道root密码，我们先设置一下密
码，接下来你希望能修改启动参数，但是很不幸，Container启动之后，无法变更命令，你
需要新建一个Container。[fn:3]&lt;/p&gt;

&lt;p&gt;由于你需要基于当前Container的配置新建一个，但是Container只能从Image创建，因此你
需要把当前的工作提交一下，生成一个新的Image，提交Image：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@tacy:/etc/init.d$ sudo docker commit db2exc tacylee/db2exc
250b78860e291ebd71948bbb596f7dfc1a7d61563184a433bb44a8f2363079cb
tacy@tacy:/etc/init.d$ sudo docker images
REPOSITORY                TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
tacylee/db2exc            latest              250b78860e29        24 seconds ago      1.349 GB
wnameless/oracle-xe-11g   latest              f8d224b82290        5 days ago          2.389 GB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;基于我们提交的Image运行一个Container：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@tacy:/etc/init.d$ sudo docker run -d -p 49170:22 -p 49171:50000 -name tt tacylee/db2exc /bin/bash -c &#39;/etc/init.d/db2exc start &amp;amp;&amp;amp; /usr/sbin/sshd -D&#39;
c71ac7f85e167850552809ec12a12e50e064d30dddfeb4d71302d16d0ac34502
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个命令行有几个地方要注意，首先我们通过‘-d’参数让我们的Container运行在detached
模式（也就是后台模式），其次我们通过‘-p’参数把Container端口22和50000映射到Host，
另外就是CMD，这地方比较晕，弄了好久才明白[fn:4][fn:5]。关键点是，每个Container必须
有一个前台服务在运行，如果这个前台服务停止了，Container就停止了[fn:6]，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@tacy:~$ sudo docker run -d ubuntu echo &#39;helloworld&#39;
3088fce883ece6e04282ea965af84ddd4165b67873811e949b543f8930aebe82
tacy@tacy:~$ sudo docker ps -a
CONTAINER ID        IMAGE                            COMMAND                CREATED             STATUS              PORTS                                                      NAMES
3088fce883ec        ubuntu:12.04                     echo helloworld        20 seconds ago      Exit 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，这个Container已经停止了，因为他没有前台进程在跑了，所以如果你需要你的
Container提供服务，你需要一个前台进程，很多时候我们用sshd来实现。接下来是要让我
们的Container启动DB2，使用命令组合实现即可。注意不能让sshd放在前面执行，因为他不
会结束，所以在它后面的命令无法执行。&lt;/p&gt;

&lt;p&gt;到这里，我们貌似已经已经有了一个跑DB2的Container了。但是，这个世界总是没那么美好
，我们先看看Container的启动日志：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@tacy:~$ sudo docker logs tt
tput: No value for $TERM and no -T specified
tput: No value for $TERM and no -T specified
tput: No value for $TERM and no -T specified
tput: No value for $TERM and no -T specified
tput: No value for $TERM and no -T specified
tput: No value for $TERM and no -T specified
error: permission denied on key &#39;kernel.msgmni&#39;
error: permission denied on key &#39;kernel.msgmnb&#39;
error: permission denied on key &#39;kernel.msgmax&#39;
error: permission denied on key &#39;fs.file-max&#39;
# Starting DAS:			failed.

Message: SQL4401C  The DB2 Administration Server encountered an error during startup.

# Instance db2inst1 ( db2c_db2inst1 ):	done.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进去看看/etc/init.d/db2exc脚本，发现它会去修改kernel参数，而Docker为了保证安全
，这些权限是被关闭的。简单做法是在Container里面配置好，然后别让脚本执行Kernel
参数的设置操作，另外如果你不想去配置，可以让你的Container运行在特权模式，只需在
创建Container的时候加上‘-privileged‘参数，这样Container就能执行任何权限指令了。&lt;/p&gt;

&lt;p&gt;Kernel参数问题解决了之后，你通过SSH连接到Container，切换到db2inst1用户，尝试建
立数据库，很不幸，你会碰到下面错误：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;db2inst1@c71ac7f85e16:~$ db2 create db dd
SQL1042C  An unexpected system error occurred.  SQLSTATE=58004
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看DB2日志文件，你会发现如下错误信息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;2014-04-11-11.44.10.392525+000 E100588E1093        LEVEL: Error (OS)
PID     : 369                  TID  : 140502687016704PROC : db2sysc
INSTANCE: db2inst1             NODE : 000          DB   : DD
EDUID   : 79                   EDUNAME: db2loggr (DD)
FUNCTION: DB2 UDB, oper system services, sqloopenp, probe:80
MESSAGE : ZRC=0x870F0002=-2029060094=SQLO_BPSE &amp;quot;Debug logic error detected&amp;quot;
          DIA8501C A buffer pool logic error has occurred.
CALLED  : OS, -, open                             OSERR: EINVAL (22)
DATA #1 : Codepath, 8 bytes
4:11:15:20:22:37
DATA #2 : File name, 63 bytes
/home/db2inst1/db2inst1/NODE0000/SQL00001/SQLOGDIR/S0000000.LOG
DATA #3 : SQO Open File Options, PD_TYPE_SQO_FILE_OPEN_OPTIONS, 4 bytes
SQLO_REVISE, SQLO_READWRITE, SQLO_SHAREREAD, SQLO_WRITETHRU, SQLO_SECTOR_ALIGNED, SQLO_NO_THREAD_LEVEL_FILE_LOCK
DATA #4 : Hex integer, 4 bytes
0x00000180
DATA #5 : signed integer, 4 bytes
0
DATA #6 : signed integer, 4 bytes
16384
DATA #7 : String, 105 bytes
Search for ossError*Analysis probe point after this log entry for further
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;ext4文件系统，并且支持O_DIRECT，最终的Container创建命令如下：&lt;/dt&gt;
&lt;dd&gt;sudo docker run -d -p 49170:22 -p 49171:50000 -v /home/tacy/Docker/db2db:/home/db2inst1/db2db -name db2exc -privileged tacylee/db2exc /bin/bash -c &amp;lsquo;/etc/init.d/db2exc start &amp;amp;&amp;amp; /usr/sbin/sshd -D&amp;rsquo;
然后把数据库创建在/home/db2inst1/db2db目录中即可。&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dt&gt;ext4文件系统，并且支持O_DIRECT，最终的Container创建命令如下：&lt;/dt&gt;
&lt;dd&gt;sudo docker run -d -p 49170:22 -p 49171:50000 -v /home/tacy/Docker/db2db:/home/db2inst1/db2db -name db2exc -privileged tacylee/db2exc /bin/bash -c &amp;lsquo;/etc/init.d/db2exc start &amp;amp;&amp;amp; /usr/sbin/sshd -D&amp;rsquo;
然后把数据库创建在/home/db2inst1/db2db目录中即可。&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;2db:/home/db2inst1/db2db -name db2exc -privileged tacylee/db2exc /bin/bash -c &amp;lsquo;/etc/init.d/db2exc start &amp;amp;&amp;amp; /usr/sbin/sshd -D&amp;rsquo;
然后把数据库创建在/home/db2inst1/db2db目录中即可。&lt;/p&gt;

&lt;p&gt;如果你不想bind-mount Host的目录到Container（毕竟很不灵活），也可以考虑替换Docker
的后台存储为Devicemapper[fn:11]。&lt;/p&gt;

&lt;p&gt;对于这类问题的诊断方法可以通过strace来实现，例如上面的例子：从DB2的日志里面我们
知道是db2sysc需要执行系统的OPEN操作出现问题，你可以通过stace来捕获具体的错误。&lt;/p&gt;

&lt;p&gt;我们先获取db2sysc的进程ID：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@314f5d6aa350:~# ps -ef|grep db2sysc
db2inst1   369   367  0 11:30 ?        00:00:23 db2sysc
root      2894  2881  0 15:12 pts/1    00:00:00 grep --color=auto db2sysc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后用下面命令trace db2sysc的所有open操作：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;root@314f5d6aa350:~# strace -Ff -e open -o trace.out -p 369
Process 369 attached with 36 threads - interrupt to quit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在另一个终端执行数据库创建操作，完成之后，分析trace.out文件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;2973  open(&amp;quot;/home/db2inst1/sqllib/profile.env&amp;quot;, O_RDONLY) = -1 ENOENT (No such file or directory)
2973  open(&amp;quot;/etc/passwd&amp;quot;, O_RDONLY|O_CLOEXEC) = 42
2973  open(&amp;quot;/var/db2/global.reg&amp;quot;, O_RDONLY|O_CREAT, 0644) = 42
2973  open(&amp;quot;/home/db2inst1/db2inst1/NODE0000/SQL00001/SQLOGCTL.LFH.1&amp;quot;, O_RDWR|O_DSYNC) = 42
2973  open(&amp;quot;/home/db2inst1/db2inst1/NODE0000/SQL00001/SQLOGCTL.LFH.2&amp;quot;, O_RDWR|O_DSYNC) = 43
2973  open(&amp;quot;/proc/mounts&amp;quot;, O_RDONLY)    = 45
2973  open(&amp;quot;/home/db2inst1/db2inst1/NODE0000/SQL00001/SQLOGDIR/S0000000.LOG&amp;quot;, O_RDWR|O_DSYNC|O_DIRECT) = -1 EINVAL (Invalid argument)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看截取部分的最后一行，提示open操作的参数错误，基本你就能判断是O_DIRECT无法执行
导致，这属于换个思路解决问题，也很有效果。&lt;/p&gt;

&lt;p&gt;到这里，一个能跑DB2 Express-C的Container才算完成了，唯一的遗憾就是挂着个外部目
录，不方便迁移，等待Docker解决吧。&lt;/p&gt;

&lt;h2 id=&#34;docker仓库&#34;&gt;Docker仓库&lt;/h2&gt;

&lt;p&gt;前面我们提到Docker的仓库，里面有各种Image提供，你也可以把你的Image提交到仓库，供
别人使用，你需要先去[[&lt;a href=&#34;https://index.docker.io/][Docker&#34;&gt;https://index.docker.io/][Docker&lt;/a&gt; Index]]注册一个帐号，然后通过docker login命令登入，再通
过docker push即可，具体我也没有试过，等我把DB2的Image弄好了，或许去提交一个玩玩。&lt;/p&gt;

&lt;h2 id=&#34;tips&#34;&gt;TIPS&lt;/h2&gt;

&lt;h3 id=&#34;进入正在运行的容器&#34;&gt;进入正在运行的容器&lt;/h3&gt;

&lt;p&gt;docker处于运行状态的容器如果在交互模式，你能通过screen/tmux等方式实现新开窗口运
行，完成多任务操作，比如debug等。&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;使用lxc-attach&lt;/dd&gt;
&lt;dd&gt;docker ps &amp;ndash;no-trunc
获取到container id，然后lxc-attach上去。不过0.9版本之后需要修改配置[fn:14]&lt;/dd&gt;
&lt;dd&gt;使用nsenter
使用大神jpetazzo[fn:13]开发的nsenter，很方便&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dd&gt;使用lxc-attach&lt;/dd&gt;
&lt;dd&gt;docker ps &amp;ndash;no-trunc
获取到container id，然后lxc-attach上去。不过0.9版本之后需要修改配置[fn:14]&lt;/dd&gt;
&lt;dd&gt;使用nsenter
使用大神jpetazzo[fn:13]开发的nsenter，很方便&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;，很方便&lt;/p&gt;

&lt;h3 id=&#34;监控docker-cli和server的交互&#34;&gt;监控docker cli和server的交互&lt;/h3&gt;

&lt;p&gt;docker进程启动的时候创建了unix domain socket文件在/var/run/docker.sock,你可以通
过socat/nc之类的工具连接上去,和docker服务进程交互,docker cli也是通过该socket和服
务进程进行交互。&lt;/p&gt;

&lt;p&gt;如果你想写一个自己的客户端，除了参考REST API之外，你也可以通过监控docker cli和
docker服务进程之间的交互来学习。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;要实现这个，你只需要通过socat实现一个docker socket的代理：&lt;/dt&gt;
&lt;dd&gt;sudo socat -t100 -v UNIX-LISTEN:/tmp/docker.sock,mode=777,reuseaddr,fork UNIX-CONNECT:/var/run/docker.sock&lt;/dd&gt;
&lt;dt&gt;然后在另一个终端像如下操作cli：&lt;/dt&gt;
&lt;dd&gt;docker -H unix:///tmp/docker.sock ps&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;你就可以在socat窗口看到交互的内容，你将看到例如下面的输出：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;gt; 2014/09/05 14:04:45.169982  length=130 from=0 to=129
GET /v1.13/containers/json?all=1 HTTP/1.1\r
Host: /tmp/proxysocket.sock\r
User-Agent: Docker-Client/1.1.0\r
Accept-Encoding: gzip\r
\r
&amp;lt; 2014/09/05 14:04:45.171377  length=991 from=0 to=990
HTTP/1.1 200 OK\r
Content-Type: application/json\r
Date: Fri, 05 Sep 2014 06:04:45 GMT\r
Content-Length: 882\r
\r
[{&amp;quot;Command&amp;quot;:&amp;quot;/bin/bash&amp;quot;,&amp;quot;Created&amp;quot;:1405345176,&amp;quot;Id&amp;quot;:&amp;quot;044f8cb3e0d6522ec36e09
c3df0e7ff4bbf2d963d67be6d7faade6c88b5cbbb8&amp;quot;,&amp;quot;Image&amp;quot;:&amp;quot;tianon/centos:5.8&amp;quot;,&amp;quot;
Names&amp;quot;:[&amp;quot;/sad_turing&amp;quot;],&amp;quot;Ports&amp;quot;:[],&amp;quot;Status&amp;quot;:&amp;quot;Exited (1) 6 weeks ago&amp;quot;}
,{&amp;quot;Command&amp;quot;:&amp;quot;/bin/bash -c &#39;/etc/init.d/db2exc start \\u0026\\u0026 /usr/s
bin/sshd -D&#39;&amp;quot;,&amp;quot;Created&amp;quot;:1397215845,&amp;quot;Id&amp;quot;:&amp;quot;314f5d6aa350976b8c9071958ee0c8fd
0e2c700b8b348410be50e1ba77db4a07&amp;quot;,&amp;quot;Image&amp;quot;:&amp;quot;tacylee/db2exc:latest&amp;quot;,&amp;quot;Names&amp;quot;
:[&amp;quot;/db2exc&amp;quot;],&amp;quot;Ports&amp;quot;:[],&amp;quot;Status&amp;quot;:&amp;quot;Exited (137) 4 months ago&amp;quot;}
,{&amp;quot;Command&amp;quot;:&amp;quot;\\&amp;quot;/bin/sh -c &#39;sed -i -E \\&amp;quot;s/HOST = [^)]+/HOST = $HOSTNAME/
g\\&amp;quot; /u01/app/oracle/product/11.2.0/xe/network/admin/listener.ora; servic
e oracle-xe start; /usr/sbin/sshd -D&#39;\\&amp;quot;&amp;quot;,&amp;quot;Created&amp;quot;:1397014650,&amp;quot;Id&amp;quot;:&amp;quot;1379
9635f5ee898e38c0f300475a1eaf3ad3da6e18fc8ea978f54176a96d44c9&amp;quot;,&amp;quot;Image&amp;quot;:&amp;quot;wn
ameless/oracle-xe-11g:latest&amp;quot;,&amp;quot;Names&amp;quot;:[&amp;quot;/oraclexe&amp;quot;],&amp;quot;Ports&amp;quot;:[],&amp;quot;Status&amp;quot;:&amp;quot;
Exited (-1) 6 weeks ago&amp;quot;}
]
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;你也可以建立tcp代理，这样远程客户端也能连接上来：&lt;/dt&gt;
&lt;dd&gt;sudo socat -t100 -v tcp-listen:5050,reuseaddr,fork UNIX-CONNECT:/var/run/docker.sock&lt;/dd&gt;
&lt;dt&gt;现在你可以通过curl发起请求：&lt;/dt&gt;
&lt;dd&gt;curl &lt;a href=&#34;http://localhost:5050/v1.13/containers/json?all=1&#34;&gt;http://localhost:5050/v1.13/containers/json?all=1&lt;/a&gt;&lt;/dd&gt;
&lt;dt&gt;效果和unix domain socket一样，当然你也可以通过docker cli请求：&lt;/dt&gt;
&lt;dd&gt;docker -H tcp://localhost:5050 ps -a&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;另外的方式就是把docker服务进程启动的时候指定tcp监听，然后通过sniffer方式去获取
交互内容。&lt;/p&gt;

&lt;h3 id=&#34;关于层的限制&#34;&gt;关于层的限制&lt;/h3&gt;

&lt;p&gt;注意,docker image限制层高127,也就是说一个image的layer不能超过127,你在build image
的时候必须注意,run和add都会产生层,另外docker存在冗余文件问题,比如你在build文件
里面先做了一个删除,然后在下一个run里面有做了添加操作,这个文件就会存在两份,导致
image非常臃肿.&lt;/p&gt;

&lt;p&gt;关于这个问题的一些参考issue[fn:15][fn:16][fn:17]&lt;/p&gt;

&lt;h3 id=&#34;删除容器&#34;&gt;删除容器&lt;/h3&gt;

&lt;dl&gt;
&lt;dd&gt;sudo docker rm -v &lt;CONTAINER ID&gt;
注意，需要带上&amp;rdquo;-v&amp;rdquo;参数，否则不会删除aufs层文件，造成垃圾数据。&lt;/dd&gt;
&lt;/dl&gt;

&lt;h3 id=&#34;删除一个本地image&#34;&gt;删除一个本地image&lt;/h3&gt;

&lt;dl&gt;
&lt;dt&gt;删除命令如下：&lt;/dt&gt;
&lt;dd&gt;sudo docker rmi &lt;IMAGE ID&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;如果你碰到如下错误：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tacy@tacy:~$ sudo docker rmi 8dbd9e392a96
Error: Conflict, 8dbd9e392a96 wasn&#39;t deleted
2014/04/04 14:07:55 Error: failed to remove one or more images
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;很可能是由于该image正在被使用，你可以通过下面命令查看和操作&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sudo docker ps
sudo docker stop &amp;lt;CONTAINER ID&amp;gt;
sudo docker rm &amp;lt;CONTAINER ID&amp;gt;
sudo docker rmi &amp;lt;IMAGE ID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;centos&#34;&gt;Centos&lt;/h1&gt;

&lt;p&gt;[[&lt;a href=&#34;http://wiki.centos.org/Cloud/Docker][Cloud/Doker&#34;&gt;http://wiki.centos.org/Cloud/Docker][Cloud/Doker&lt;/a&gt; - Centos Wiki]]&lt;/p&gt;

&lt;h1 id=&#34;docker-重要的特性&#34;&gt;Docker 重要的特性&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;支持版本管理&lt;/li&gt;
&lt;li&gt;docker hub 支持自动build image&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;security&#34;&gt;Security&lt;/h1&gt;

&lt;p&gt;Docker的安全还是需要完善，理论上VM的安全性高于Container，Container只要被escalate，就没法幸免，攻击面很大，而VM相对来说又多一层保护，毕竟escalate出去了，依然还有VMM保护，不会危及到整个host，比较所有和底层的交互都需要通过hypercall来实现，攻击面相对较小。&lt;/p&gt;

&lt;p&gt;总的来说，要保证docker的安全，有几件事情需要注意：
- 首先尽量别别运行container在root下，docker目前没有支持user namespace，container里面的root权限和host下的root一致，很危险，而且目前user namespace也是出来不就[fn:22]，有待稳定。
- 如果你需要运行root权限应用，需要使用SELinux/Apparmor配合，控制container root权限。
- net=host不安全，root权限用户可以直接重启host，需要注意。
- 不要从不可信网站下载image
- 禁止不必要的权限，比如non-root升级到root问题可以通过移除文件的suid位
- 使用user namespace（参考docker issue #7906[fn:23]，支持user map&lt;/p&gt;

&lt;p&gt;关于docker安全的一些参考：
- [[&lt;a href=&#34;http://blog.docker.com/2013/08/containers-docker-how-secure-are-they/][Containers&#34;&gt;http://blog.docker.com/2013/08/containers-docker-how-secure-are-they/][Containers&lt;/a&gt; &amp;amp; Docker: How Secure Are They?]]
- [[&lt;a href=&#34;https://news.ycombinator.com/item?id%3D6252182][Hacker&#34;&gt;https://news.ycombinator.com/item?id%3D6252182][Hacker&lt;/a&gt; News discuss - Containers and Docker: how secure are they?]]
- [[&lt;a href=&#34;http://www.projectatomic.io/blog/][Project&#34;&gt;http://www.projectatomic.io/blog/][Project&lt;/a&gt; Atomic News (blog)]]
- [[&lt;a href=&#34;http://opensource.com/business/14/7/docker-security-selinux][Are&#34;&gt;http://opensource.com/business/14/7/docker-security-selinux][Are&lt;/a&gt; Docker containers really secure?]]
- [[&lt;a href=&#34;https://fedorapeople.org/~dwalsh/SELinux/Presentations/DockerSecurity][Docker&#34;&gt;https://fedorapeople.org/~dwalsh/SELinux/Presentations/DockerSecurity][Docker&lt;/a&gt; Security]]
- [[&lt;a href=&#34;http://www.slideshare.net/jpetazzo/docker-linux-containers-lxc-and-security][Docker&#34;&gt;http://www.slideshare.net/jpetazzo/docker-linux-containers-lxc-and-security][Docker&lt;/a&gt;, Linux Containers (LXC), and security]]&lt;/p&gt;

&lt;h1 id=&#34;storage-backend&#34;&gt;Storage backend&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;aufs
使用上注意，这个不能用在产品上，基于文件目录的层，不是COW方式。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;device mapper&lt;/p&gt;

&lt;h2 id=&#34;缺省用的是loop-device-从性能考虑-需要用block-device-fn-24&#34;&gt;缺省用的是loop device，从性能考虑，需要用block device[fn:24]&lt;/h2&gt;

&lt;h1 id=&#34;migration&#34;&gt;Migration&lt;/h1&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CRIU[fn:25]&lt;/p&gt;

&lt;h1 id=&#34;monitor&#34;&gt;Monitor&lt;/h1&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cAdvisor&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;service-discovery&#34;&gt;Service Discovery&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;etcd&lt;/li&gt;
&lt;li&gt;consul

&lt;ul&gt;
&lt;li&gt;Consul will use a load-balancing strategy similar to round-robin when it returns DNS answers&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;self&lt;/li&gt;
&lt;li&gt;zookeeper&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;clusetr-management&#34;&gt;Clusetr Management&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;fleet&lt;/li&gt;
&lt;li&gt;mesos/marathon&lt;/li&gt;
&lt;li&gt;google omega&lt;/li&gt;

&lt;li&gt;&lt;p&gt;yarn&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;[[&lt;a href=&#34;http://aws.amazon.com/blogs/aws/cloud-container-management/][ECS&#34;&gt;http://aws.amazon.com/blogs/aws/cloud-container-management/][ECS&lt;/a&gt; (EC2 Container Service)]]&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;[[&lt;a href=&#34;https://cloud.google.com/container-engine/][Google&#34;&gt;https://cloud.google.com/container-engine/][Google&lt;/a&gt; Container Engine]]&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;[[&lt;a href=&#34;https://wiki.openstack.org/wiki/Docker][Openstack&#34;&gt;https://wiki.openstack.org/wiki/Docker][Openstack&lt;/a&gt; Docker]]&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;docker-registry&#34;&gt;Docker registry&lt;/h1&gt;

&lt;p&gt;[[&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-set-up-a-private-docker-registry-on-ubuntu-14-04][How&#34;&gt;https://www.digitalocean.com/community/tutorials/how-to-set-up-a-private-docker-registry-on-ubuntu-14-04][How&lt;/a&gt; To Set Up a Private Docker Registry]]&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$docker tag dockerfile/redis 172.16.11.1:5000/tacy/redis
$docker push 172.16.11.1:5000/tacy/redis
$docker pull 172.16.11.1:5000/tacy/redis
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;docker-paas&#34;&gt;Docker PaaS&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;flynn&lt;/li&gt;
&lt;li&gt;deis&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;coreos&#34;&gt;Coreos&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;etcd&lt;/li&gt;
&lt;li&gt;fleet&lt;/li&gt;
&lt;li&gt;docker&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;paas&#34;&gt;PaaS&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;marathon&lt;/li&gt;
&lt;li&gt;flynn&lt;/li&gt;
&lt;li&gt;deis&lt;/li&gt;
&lt;li&gt;zenoss control center&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h1&gt;

&lt;h2 id=&#34;pod&#34;&gt;pod&lt;/h2&gt;

&lt;p&gt;pod由同一host上的一组容器构成, 一般是一组紧耦合的进程. 这里不再docker container里面运行多个进程实现, 主要考虑是让docker container尽量轻量级, 不用负责进程管理, 更多的工作让k8完成.&lt;/p&gt;

&lt;p&gt;一个pod是一个最小调度单元, 有自己的ip地址. 同一个pod内的容器共享网络空间.&lt;/p&gt;

&lt;h2 id=&#34;service&#34;&gt;service&lt;/h2&gt;

&lt;h1 id=&#34;ibm-research-report-2014-for-container-and-vm&#34;&gt;IBM Research Report 2014 for Container and VM&lt;/h1&gt;

&lt;p&gt;IBM的一个关于容器和虚拟机的对比报告，主要是性能关注，包括CPU、内存、存储、网络
资源，测试结果显示容器的性能表现全面高于或等于虚拟机，对于IO敏感的应用，两个技
术都需要进行优化&lt;/p&gt;

&lt;p&gt;隔离和资源控制是两个关键的需求对于多种负载类型的应用共享资源池，不能让他们相互
之间影响彼此，同时控制每个应用使用资源的多少，不至于出现资源争抢。&lt;/p&gt;

&lt;h2 id=&#34;背景知识&#34;&gt;背景知识&lt;/h2&gt;

&lt;p&gt;首先了解虚拟化的难点（这里谈论的都是x86）。传统的x86系统都是基于裸硬件设计的，
也就是说OS缺省默认是自己拥有所有的底层硬件资源，CPU在设计的时候，都会把指令按照
安全级别分类，也就是通常说的protection ring[fn:18]，intel用2bit实现，也就是有
ring 0 ~ ring 3四个级别：ring 0权限最大，可以执行所有操作，ring 1 和ring 2 没有
权限操作硬件，ring 3权限最小。主流的x86操作系统都只使用了ring 0 和ring 3，ring 0
也被称为kernel mode，ring 3为user mode，kernel mode封装了一系列的system call，当
user mode需要做特权指令调用的时候，只能通过system call实现，产生ContextSwitch，
带来重的系统开销。&lt;/p&gt;

&lt;p&gt;由于x86操作系统都直接占用了ring 0，对硬件设计没有考虑虚拟化的支持，那么虚拟化软件
厂商就各显神通，早期的虚拟化VMM的实现都是把VMM放到ring 0，guest os放在ring 1执行
，应用跑在ring 3，这样就带来一系列问题：&lt;/p&gt;

&lt;h3 id=&#34;软件虚拟化问题&#34;&gt;软件虚拟化问题&lt;/h3&gt;

&lt;h4 id=&#34;特权指令调用&#34;&gt;特权指令调用&lt;/h4&gt;

&lt;p&gt;最早的vmware采用binary translation解决这个问题，在vmm层模拟所有的系统调用，当
guest os执行systemcall时，vmm捕获执行模拟操作，然后返回结果给guest os kernel，
继续返回给应用。软件实现方式带来很大开销，早期的虚拟化软件性能有很大问题，但是
他又一个好处就是对上层guest os透明，不需要对guest os进行任何修改。&lt;/p&gt;

&lt;p&gt;XEN采用一种不同的方式：Paravitualization[fn:19]，也被称作半虚拟化技术，这种方式
的好处就是性能提升，但是问题就在于需要上层的guest os感知，也就是需要对guest os
就行修改，在芯片厂商的虚拟化支持没有出来之前，这个成为一种主流的方式，使得虚拟
化技术在服务器上运行（后期的vmware应该是个混合体）。&lt;/p&gt;

&lt;h4 id=&#34;内存管理问题-mmu&#34;&gt;内存管理问题（MMU）&lt;/h4&gt;

&lt;p&gt;由于cpu只有一个MMU，guest os上的内存寻址带来问题，需要从GVA-》GPA-》HVA-》HPA，
带来严重的性能开销，解决办法就是Shadow Page Table，vmm维护一个虚拟的TLB，直接
映射GVA-》HPA，但是这样的方式依然有很大开销，需要用软件方式额外维护一个频繁更
新的页表。&lt;/p&gt;

&lt;h4 id=&#34;io问题&#34;&gt;IO问题&lt;/h4&gt;

&lt;p&gt;早期的实现都是基于模拟方式，主流的QEMU实现了全虚拟的驱动设备，但是效率非常地下。
后期主流都采用Paravirtualization实现，但是需要在guest os上安装具体驱动。vmware
需要在guest os上安装vmtools就是这个原因。xen为了支持windows也开发了一套
GPLPV驱动。&lt;/p&gt;

&lt;h3 id=&#34;硬件支持&#34;&gt;硬件支持&lt;/h3&gt;

&lt;p&gt;x86芯片虚拟化自然也是不干落后，首先是vt-x（只说intel，AMD有相应技术）[fn:20]，
第一代的vt-x解决的是特权指令问题，引入了ring -1（也叫Root mode）,VMM跑在Root
mode，但是第一代的vt-x并没有大规模使用，大量的vmexit和vmenter以及太高的消耗（
几百到几千的cycles），导致性能比软件实现还差，只是简化了VMM开发。[fn:21]&lt;/p&gt;

&lt;p&gt;第二代的vt-x优化了实现，并且引入了EMT，硬件上解决内存寻址问题，芯片内置了嵌套
页表，直接缓存GVA-》HPA映射，但是依然会带来一些问题，比如TLB Miss相比非虚拟化
方式开销巨大，芯片的解决办法是引入更大的TLB。虚拟软件厂商也通过采用大页的方式
来缓解这个问题。&lt;/p&gt;

&lt;p&gt;对于IO问题的解决方案intel引入vt-d技术（也被称作IOMMU），直接passthrough硬件到
guest os，但是这种方式带来的问题是虚拟机无法迁移。&lt;/p&gt;

&lt;p&gt;其他的解决方案比如PCIe的SR-IOV，直接支持pci卡的虚拟多设备绑定到guest os，都有
迁移问题。&lt;/p&gt;

&lt;p&gt;IO这块通用的方式更多还是paravirtualization。&lt;/p&gt;

&lt;h3 id=&#34;kvm&#34;&gt;KVM&lt;/h3&gt;

&lt;p&gt;kvm采用的是HVM方式，也就是必须硬件虚拟化支持（vt-x）。IO实现两种模式，一种是通
过QEMU emulator模拟驱动设备，性能很差，基本只做测试，另外一种就是paravirtual（
Virtio），损耗比较低，IO性能能达到95%左右，但是这只是测试，具体使用中会有各种
问题，比如IO对齐，缓存等。&lt;/p&gt;

&lt;p&gt;kvm也支持guest os的vcpu、vram在线伸缩，这些在现有的IaaS中几乎没有看见使用，需
要上层软件支持。&lt;/p&gt;

&lt;p&gt;另外kvm直接利用了linux的已有的资源调度和管理，每一个guest os就是一个process，这
简化了kvm实现，但是也带来的复杂度，比如内存，如果overcommitted，内存管理就无法
很好的swapout，guest os的性能就无法保证。所以很多IaaS也会提供cpu pin和资源不超
售，以及vRAM锁定到RAM的方式提高性能。&lt;/p&gt;

&lt;p&gt;对于VM的安全，由于只能通过hypercalls和虚拟驱动设备和外界交互，而二者都需要通过
VMM，保证了VM的安全隔离，当然也不是说没有安全问题，vmm的安全漏洞也时有发现。&lt;/p&gt;

&lt;p&gt;VM的隔离也带来了其他开销：系统内存，文件系统等，虚拟化厂商也在提供技术解决方案
，比如内存的ballooning，但是这些都会带来其他开销。&lt;/p&gt;

&lt;h3 id=&#34;linux-container&#34;&gt;linux container&lt;/h3&gt;

&lt;p&gt;linux container底层技术就是两个：kernel namespace和control groups。&lt;/p&gt;

&lt;p&gt;linux实现了fs、pid、network、user、ipc和hostname的名称空间，可以实现隔离。例如
每个fs名称空间都有自己的根系统，mount表，表现的就是一个独立的文件系统。每个网络
名称空间能有自己的网卡，自己的路由表等。&lt;/p&gt;

&lt;p&gt;cgroups&lt;/p&gt;

&lt;h1 id=&#34;一些需要注意的问题&#34;&gt;一些需要注意的问题：&lt;/h1&gt;

&lt;h2 id=&#34;net-host安全问题&#34;&gt;net=host安全问题&lt;/h2&gt;

&lt;p&gt;[[&lt;a href=&#34;https://github.com/docker/docker/issues/6401][Rebooting&#34;&gt;https://github.com/docker/docker/issues/6401][Rebooting&lt;/a&gt; within docker container actually reboots the host #6401 ]]&lt;/p&gt;

&lt;h1 id=&#34;好的文章&#34;&gt;好的文章&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;[[&lt;a href=&#34;http://stackoverflow.com/questions/18285212/how-to-scale-docker-containers-in-production][How&#34;&gt;http://stackoverflow.com/questions/18285212/how-to-scale-docker-containers-in-production][How&lt;/a&gt; to scale Docker containers in production]]&lt;/li&gt;
&lt;li&gt;[[&lt;a href=&#34;http://www.centurylinklabs.com/caching-docker-images/?hvid%3D2WaPeN][Working&#34;&gt;http://www.centurylinklabs.com/caching-docker-images/?hvid%3D2WaPeN][Working&lt;/a&gt; With the Docker Image Cache]]&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;http://docs.docker.io/en/latest/faq/][Docker&#34;&gt;http://docs.docker.io/en/latest/faq/][Docker&lt;/a&gt; FAQ]]&lt;/p&gt;

&lt;p&gt;[fn:2] [[&lt;a href=&#34;http://stackoverflow.com/questions/16047306/how-is-docker-io-different-from-a-normal-virtual-machine?rq%3D1][How&#34;&gt;http://stackoverflow.com/questions/16047306/how-is-docker-io-different-from-a-normal-virtual-machine?rq%3D1][How&lt;/a&gt; is Docker.io different from a normal virtual machine?]]&lt;/p&gt;

&lt;p&gt;[fn:3] [[&lt;a href=&#34;https://github.com/dotcloud/docker/issues/1228][running&#34;&gt;https://github.com/dotcloud/docker/issues/1228][running&lt;/a&gt; a different command on an existing container]]&lt;/p&gt;

&lt;p&gt;[fn:4] [[&lt;a href=&#34;https://github.com/dotcloud/docker/issues/1826][After&#34;&gt;https://github.com/dotcloud/docker/issues/1826][After&lt;/a&gt; importing an image, run gives &amp;ldquo;no command specified]]&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[fn:5] [[&lt;a href=&#34;https://groups.google.com/forum/#!topic/docker-user/yv2RAnaXvpk][Using&#34;&gt;https://groups.google.com/forum/#!topic/docker-user/yv2RAnaXvpk][Using&lt;/a&gt; sudo inside Docker image]]&lt;/p&gt;

&lt;p&gt;[fn:6] [[&lt;a href=&#34;http://blog.trifork.com/2014/03/11/using-supervisor-with-docker-to-manage-processes-supporting-image-inheritance/][Using&#34;&gt;http://blog.trifork.com/2014/03/11/using-supervisor-with-docker-to-manage-processes-supporting-image-inheritance/][Using&lt;/a&gt; Supervisor with Docker to manage processes]]&lt;/p&gt;

&lt;p&gt;[fn:7] [[&lt;a href=&#34;http://docs.docker.io/en/latest/reference/run/][Docker&#34;&gt;http://docs.docker.io/en/latest/reference/run/][Docker&lt;/a&gt; Run Reference]]&lt;/p&gt;

&lt;p&gt;[fn:8] [[&lt;a href=&#34;https://github.com/dotcloud/docker/issues/1916][docker&#34;&gt;https://github.com/dotcloud/docker/issues/1916][docker&lt;/a&gt; build should support privileged operations]]&lt;/p&gt;

&lt;p&gt;[fn:9] [[&lt;a href=&#34;https://github.com/dotcloud/docker/issues/3433][User&#34;&gt;https://github.com/dotcloud/docker/issues/3433][User&lt;/a&gt; defined layer mount options]]&lt;/p&gt;

&lt;p&gt;[fn:10] [[&lt;a href=&#34;https://groups.google.com/forum/#!topic/docker-user/1pFhqlfbqQI][DB2&#34;&gt;https://groups.google.com/forum/#!topic/docker-user/1pFhqlfbqQI][DB2&lt;/a&gt; in container can&amp;rsquo;t start unless I mount non-aufs volume from host]]&lt;/p&gt;

&lt;p&gt;[fn:11] [[&lt;a href=&#34;http://muehe.org/posts/switching-docker-from-aufs-to-devicemapper/][Switching&#34;&gt;http://muehe.org/posts/switching-docker-from-aufs-to-devicemapper/][Switching&lt;/a&gt; Docker from aufs to devicemapper]]&lt;/p&gt;

&lt;p&gt;[fn:12] [[&lt;a href=&#34;http://webcache.googleusercontent.com/search?q%3Dcache:tp3o-xrNBycJ:permalink.gmane.org/gmane.comp.sysutils.docker.user/950%2B&amp;amp;cd%3D4&amp;amp;hl%3Den&amp;amp;ct%3Dclnk][Re:&#34;&gt;http://webcache.googleusercontent.com/search?q%3Dcache:tp3o-xrNBycJ:permalink.gmane.org/gmane.comp.sysutils.docker.user/950%2B&amp;amp;cd%3D4&amp;amp;hl%3Den&amp;amp;ct%3Dclnk][Re:&lt;/a&gt; Oracle Database won&amp;rsquo;t run in docker container]]&lt;/p&gt;

&lt;p&gt;[fn:13] [[&lt;a href=&#34;https://github.com/jpetazzo][jpetazzo&#34;&gt;https://github.com/jpetazzo][jpetazzo&lt;/a&gt; blog]]&lt;/p&gt;

&lt;p&gt;[fn:14] [[&lt;a href=&#34;http://jpetazzo.github.io/2014/03/23/lxc-attach-nsinit-nsenter-docker-0-9/][Attaching&#34;&gt;http://jpetazzo.github.io/2014/03/23/lxc-attach-nsinit-nsenter-docker-0-9/][Attaching&lt;/a&gt; to a container with Docker 0.9 and libcontainer]]&lt;/p&gt;

&lt;p&gt;[fn:15] [[&lt;a href=&#34;https://github.com/docker/docker/issues/332][flatten&#34;&gt;https://github.com/docker/docker/issues/332][flatten&lt;/a&gt; images - merge multiple layers into a single one]]&lt;/p&gt;

&lt;p&gt;[fn:16] [[&lt;a href=&#34;https://github.com/docker/docker/issues/2439][Dockerfiles&#34;&gt;https://github.com/docker/docker/issues/2439][Dockerfiles&lt;/a&gt; should have a way to perform multiple build actions in one commit]]&lt;/p&gt;

&lt;p&gt;[fn:17] [[&lt;a href=&#34;https://github.com/docker/docker/pull/4232][Add&#34;&gt;https://github.com/docker/docker/pull/4232][Add&lt;/a&gt; docker squash command]]&lt;/p&gt;

&lt;p&gt;[fn:18] [[&lt;a href=&#34;http://en.wikipedia.org/wiki/Protection_ring][Protection&#34;&gt;http://en.wikipedia.org/wiki/Protection_ring][Protection&lt;/a&gt; ring]]&lt;/p&gt;

&lt;p&gt;[fn:19] [[&lt;a href=&#34;http://en.wikipedia.org/wiki/Paravirtualization][Paravirtualization]&#34;&gt;http://en.wikipedia.org/wiki/Paravirtualization][Paravirtualization]&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;[fn:20] [[&lt;a href=&#34;http://en.wikipedia.org/wiki/X86_virtualization][x86&#34;&gt;http://en.wikipedia.org/wiki/X86_virtualization][x86&lt;/a&gt; virtualization]]&lt;/p&gt;

&lt;p&gt;[fn:21] [[&lt;a href=&#34;http://www.anandtech.com/print/2480/][Hardware&#34;&gt;http://www.anandtech.com/print/2480/][Hardware&lt;/a&gt; Virtualization: the Nuts and Bolts]]&lt;/p&gt;

&lt;p&gt;[fn:22] [[&lt;a href=&#34;http://lwn.net/Articles/532593/][Namespaces&#34;&gt;http://lwn.net/Articles/532593/][Namespaces&lt;/a&gt; in operation, part 5: User namespaces]]&lt;/p&gt;

&lt;p&gt;[fn:23] [[&lt;a href=&#34;https://github.com/docker/docker/issues/7906][Proposal:&#34;&gt;https://github.com/docker/docker/issues/7906][Proposal:&lt;/a&gt; Support for user namespaces]]&lt;/p&gt;

&lt;p&gt;[fn:24] [[&lt;a href=&#34;http://jpetazzo.github.io/2014/01/29/docker-device-mapper-resize/][Resizing&#34;&gt;http://jpetazzo.github.io/2014/01/29/docker-device-mapper-resize/][Resizing&lt;/a&gt; Docker containers with the Device Mapper plugin]]&lt;/p&gt;

&lt;p&gt;[fn:25] [[&lt;a href=&#34;http://en.wikipedia.org/wiki/CRIU][CRIU]&#34;&gt;http://en.wikipedia.org/wiki/CRIU][CRIU]&lt;/a&gt;]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>DB2锁和隔离级别</title>
      <link>http://tacy.github.io/post/db2-locks-and-isolation-level/</link>
      <pubDate>Tue, 01 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/db2-locks-and-isolation-level/</guid>
      
        <description>

&lt;h1 id=&#34;db2的锁&#34;&gt;DB2的锁&lt;/h1&gt;

&lt;p&gt;DB2的锁实现机制很复杂，它没有实现类似Oracle的undo机制，导致操作之间容易阻塞，
比如你经常会听到有人说DB2查询阻塞更新，更新不同记录导致阻塞等！这其中到底是
如何导致的？是否有迹可循？Oracle的应用迁移到DB2是否就是简单的SQL兼容测试？同
样的应用逻辑为何在DB2上会发生死锁？如何能够提高DB2的并发能力？针对这些问题，
本文尝试做一些解读。&lt;/p&gt;

&lt;h2 id=&#34;锁列表-fn-1&#34;&gt;锁列表[fn:1]&lt;/h2&gt;

&lt;p&gt;首先我们先来看看DB2的锁列表，下表里面列出了DB2使用到的所有锁。表中的Lock Mode
一列是锁的名称；第二列Applicable Object Type表示锁适用的对象范围，例如IN不是
一个Row锁；第三列Description是对锁的一个简单描述。&lt;/p&gt;

&lt;p&gt;首先我们来看锁名称，DB2将锁分为Intent Locks和Non-intent Locks，也就是人们通常
所说的意向锁和非意向锁，锁名称中带“I”子母的都是意向锁，剩下的都是非意向锁，
意向锁是粗粒度锁，不能锁行。从字面意思理解，表示有意向做什么操作，举个例子：
我有一条Update语句希望对A表做Update操作，那么DB2会首先对A表加IX（意象排他）锁
，然后结合行级X锁实现（具体会更复杂，后面我们会讲到）。除了IN锁之外，其他的意
向锁（IS，IX，SIX）都需要结合行级锁实现具体操作。IN锁是一个特例，基本可以理解
为不锁（只是排他Z锁，后续的兼容列表可以看到，UR隔离级别使用）。&lt;/p&gt;

&lt;p&gt;非意向锁中，NS、S、U为读请求锁，其中：NS是行级别锁，只使用在RS和CS隔离级别，RR
隔离级别直接加S锁；select for update语句对行加U锁，表级U锁使用于比如LOAD、REORG
。X、Z、NW为写请求锁，Z锁基本都是DDL操作，X锁也是排他的，只有UR隔离级别允许读，
NW锁应该不常发生，只有在RR隔离级别做索引扫描的时候，同时对扫描的索引插入一个Key
，这时插入操作无法完成，需要等待事物完成，这时候，插入操作会在插入Key的下一个
Key加NW锁。&lt;/p&gt;

&lt;p&gt;锁适用的对象范围表示锁能加在哪些对象上。对于锁的描述我也不重复了。&lt;/p&gt;

&lt;p&gt;|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-|
| Lock Mode              | Applicable Object Type  | Description                                     |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-|
| IN(Intent None)        | Table spaces, blocks,   | The lock owner can read any data in the         |
|                        | tables, data partitions | object, including uncommitted data, but         |
|                        |                         | cannot update any of it. Other concurrent       |
|                        |                         | applications can read or update the table.      |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-|
| IS (Intent Share)      | Table spaces, blocks,   | The lock owner can read data in the locked      |
|                        | tables, data partitions | table. but cannot update this data. Other       |
|                        |                         | applications can read or update the table.      |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-|
| IX (Intent Exclusive)  | Table spaces, blocks,   | The lock owner and concurrent applications      |
|                        | tables, data partitions | can read and update data. Other concurrent      |
|                        |                         | applications can both read and update the       |
|                        |                         | table.                                          |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-|
| NS (Scan Share)        | Rows                    | The lock owner and all concurrent applica-      |
|                        |                         | -tions can read, but not update, the locked     |
|                        |                         | row. This lock is acquired on rows of a ta-     |
|                        |                         | -ble, instead of an S lock, where the isol-     |
|                        |                         | -ation level of the application is either RS    |
|                        |                         | or CS.                                          |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-|
| NW (Next Key Weak      | Rows                    | When a row is inserted into an index, an NW     |
| Exclusive)             |                         | lock is acquired on the next row. This occurs   |
|                        |                         | only if the next row is currently locked by an  |
|                        |                         | RR scan. The lock owner can read but not update |
|                        |                         | the locked row. This lock mode is similar to an |
|                        |                         | X lock, except that it is also compatible with  |
|                        |                         | NS locks.                                       |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-|
| S (Share)              | Rows, blocks, tables,   | The lock owner and all concurrent applications  |
|                        | data partitions         | can read, but not update, the locked data.      |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-|
| SIX (Share with intent | Tables, blocks, data    | The lock owner can read and update data. Other  |
| Exclusive)             | partitions              | concurrent applications can read the table.     |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-|
| U (Update)             | Rows, blocks, tables,   | The lock owner can update data. Other units of  |
|                        | data partitions         | work can read the data in the locked object,    |
|                        |                         | but cannot update it.                           |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-|
| X (Exclusive)          | Rows, blocks, tables,   | The lock owner can both read and update data in |
|                        | buffer pools, data      | the locked object. Only uncommitted read (UR)   |
|                        | partitions              | applications can access the locked object.      |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-|
| Z (Supper Exclusive)   | Tables spaces, tables,  | This lock is acquired on a table under certain  |
|                        | data partitions, blocks | conditions, such as when the table is altered   |
|                        |                         | or dropped, an index on the table is created or |
|                        |                         | dropped, or for some types of table reorganiza- |
|                        |                         | -tion. No other concurrent application can read |
|                        |                         | or update the table.                            |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-|&lt;/p&gt;

&lt;h2 id=&#34;锁兼容表-fn-2&#34;&gt;锁兼容表[fn:2]&lt;/h2&gt;

&lt;p&gt;当A请求获取了某个对象的锁，B请求同时需要对该对象申请加锁的时候，如果两个锁不
兼容，B请求需要等待，直到A请求释放该锁。&lt;/p&gt;

&lt;p&gt;下表列出了锁之间的兼容关系，横轴表示对象上已有的锁，纵轴表示申请在该对象上加锁&lt;/p&gt;

&lt;p&gt;|      | None | IN | IS | NS | S | IX | SIX | U | X | Z | NW |
|&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;+&amp;mdash;-+&amp;mdash;-+&amp;mdash;-+&amp;mdash;+&amp;mdash;-+&amp;mdash;&amp;ndash;+&amp;mdash;+&amp;mdash;+&amp;mdash;+&amp;mdash;-|
| None | Y    | Y  | Y  | Y  | Y | Y  | Y   | Y | Y | Y | Y  |
| IN   | Y    | Y  | Y  | Y  | Y | Y  | Y   | Y | Y | N | Y  |
| IS   | Y    | Y  | Y  | Y  | Y | Y  | Y   | Y | N | N | N  |
| NS   | Y    | Y  | Y  | Y  | Y | N  | N   | Y | N | N | Y  |
| S    | Y    | Y  | Y  | Y  | Y | N  | N   | Y | N | N | N  |
| IX   | Y    | Y  | Y  | N  | N | Y  | N   | N | N | N | N  |
| SIX  | Y    | Y  | Y  | N  | N | N  | N   | N | N | N | N  |
| U    | Y    | Y  | Y  | Y  | Y | N  | N   | N | N | N | N  |
| X    | Y    | Y  | N  | N  | N | N  | N   | N | N | N | N  |
| Z    | Y    | N  | N  | N  | N | N  | N   | N | N | N | N  |
| NW   | Y    | Y  | N  | Y  | N | N  | N   | N | N | N | N  |&lt;/p&gt;

&lt;h2 id=&#34;执行计划-锁和隔离级别之间的关系-fn-3&#34;&gt;执行计划、锁和隔离级别之间的关系[fn:3]&lt;/h2&gt;

&lt;p&gt;对于DB2开发人员来说，掌握执行计划、锁和隔离级别之间的关系，可以很好的避免应用程
序deadlock/timeout wait(SQLCODE -911 reason 2 和SQLCODE -911 reason 68)，增加应
用程序并发能力。&lt;/p&gt;

&lt;p&gt;首先DB2的隔离级别分为RR、RS、CS、UR四种，具体的区别这里不做详细描述，有兴趣的人
可以自己搜索相关资料了解。&lt;/p&gt;

&lt;p&gt;对于同样一条SQL语句，隔离级别和SQL执行计划都能影响到锁的使用，下面列出了相互之
间的关系表。&lt;/p&gt;

&lt;p&gt;下面列表中斜杠前面的是表锁，斜杠后面的是行锁，&amp;rsquo;-&amp;lsquo;表示不加锁。&lt;/p&gt;

&lt;p&gt;在说明的时候，会用到TEST表，表数据如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;db2inst1@tacy:~$ db2 &#39;select * from test&#39;
A           B
----------- -----------
          1           1
          2           2
          3           3
          4           4
          5           5
          6           6
          7           7
          8           8
          9           9

  9 record(s) selected.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;lock-modes-for-table-scans-with-no-predicates&#34;&gt;Lock Modes for Table Scans with No Predicates&lt;/h3&gt;

&lt;dl&gt;
&lt;dt&gt;DB2使用扫描表的方式执行SQL，同时SQL没有谓词，例如：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;select * from test 或者 update test set a=1&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;锁的使用情况如下表：&lt;/p&gt;

&lt;p&gt;[[img:db2-locks-1.png][db2locks table 1]]&lt;/p&gt;

&lt;p&gt;[[../images/db2-locks-1.png]]&lt;/p&gt;

&lt;p&gt;如果是只读的操作，比如Select，RR隔离级别时，直接对表加S锁；RS/CS是先对表加IS锁
，然后对行加NS锁。UR隔离级别只对表加IN锁，兼容除Z以外的所有锁，并发性很高，但是
要慎用，有脏读问题。&lt;/p&gt;

&lt;p&gt;如果是修改操作，比如Update，需要指出的是，数据库在执行Update操作的时候，会分为
Scan和Update两部分：先是找到需要更新的行，然后对行做更新操作。Scan阶段，DB2会对
所有需要扫描的数据行加锁，如果发现不是目标，则释放该行上的锁，换句话说，DB2会对
所有需要扫描的数据加锁，不管是不是目标，理解这一点非常重要。Update阶段则保持目
标行上的锁，或者升级锁（如果Scan阶段在目标行上锁级别不够，这种情况后续可以看到）
。由于没有谓词，是对全表操作，RR隔离级别直接对表加X锁，RS/CS/UR先对表加IX锁，然
后对行加X锁，两阶段锁一致。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;例如下面语句：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;update test set a=1 where current of cursor_name&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dt&gt;例如下面语句：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;update test set a=1 where current of cursor_name&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;where current of cursor_name&lt;/p&gt;

&lt;p&gt;效果类似select for update操作，他们两者加锁的情况一致。&lt;/p&gt;

&lt;p&gt;针对上表的情况，建议你在事务中尽量不要对表做没有谓词的查询，如果你做了类似的操
作，DB2会对表中的每条记录加NS/S锁，那么其他对该表的修改请求全部阻塞，因为X锁和
NS/S锁不兼容，除非你使用UR隔离级别（IN兼容X）。&lt;/p&gt;

&lt;h3 id=&#34;lock-modes-for-table-scans-with-predicates&#34;&gt;Lock Modes for Table Scans with Predicates&lt;/h3&gt;

&lt;dl&gt;
&lt;dt&gt;DB2使用表扫描方式执行SQL，带谓词，条件字段无索引，例如:&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;select * from test where a=1 或者 update test set b=4 where a=1&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;针对test表的操作，a字段上无索引。&lt;/p&gt;

&lt;p&gt;[[img:db2-locks-2.png][db2locks table 2]]&lt;/p&gt;

&lt;p&gt;[[../images/db2-locks-2.png]]&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;事务一先执行操作：&lt;/dt&gt;
&lt;dd&gt;select * from test where a=1
事物二后执行操作：&lt;/dd&gt;
&lt;dd&gt;update test set b=10 where a=3
由于NS锁兼容U锁，当事物一在test表中”a=1“的行上加NS锁之后，允许事物二的Update语
句对事物一锁定的行加U锁，当他发现这些行不是它需要更新的行时，就不会升级成X锁，这
样他们相安无事。&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dd&gt;update test set b=10 where a=3
由于NS锁兼容U锁，当事物一在test表中”a=1“的行上加NS锁之后，允许事物二的Update语
句对事物一锁定的行加U锁，当他发现这些行不是它需要更新的行时，就不会升级成X锁，这
样他们相安无事。&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;但是你思考一下，反过来这里可就不行了。如果是事物二先执行，事物一后执行，情况就
不妙了。由于没有索引条件，两条语句必须扫描表，如果Update先执行，会对符合条件的
行加X锁，Select后续扫描这些行的时候，虽然不是它的目标行，但是它需要先尝试加NS
锁，X锁和NS锁不兼容，只能等待。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;事物一执行：&lt;/dt&gt;
&lt;dd&gt;update test set b=11 where a=1
事物二执行：&lt;/dd&gt;
&lt;dd&gt;update test set b=12 where a=2&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dt&gt;事物二执行：&lt;/dt&gt;
&lt;dd&gt;update test set b=12 where a=2&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;update test set b=12 where a=2&lt;/p&gt;

&lt;h3 id=&#34;lock-modes-for-rid-index-scans-with-no-predicates&#34;&gt;Lock Modes for RID Index Scans with No Predicates&lt;/h3&gt;

&lt;dl&gt;
&lt;dt&gt;DB2使用索引扫描方式执行SQL，不带谓词，例如：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;select a from test 或者 update test set a=1&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;这里，我们的test表上，对a字段有索引。&lt;/p&gt;

&lt;p&gt;[[img:db2-locks-3.png][db2locks table 3]]
[[../images/db2-locks-3.png]]&lt;/p&gt;

&lt;p&gt;和前两者的区别在于，这里不再是扫表了，而是扫描索引，但是由于没有任何条件，都是
全表操作，并发能力和表一类似。&lt;/p&gt;

&lt;h3 id=&#34;lock-modes-for-rid-index-scans-with-a-single-qualifying-row&#34;&gt;Lock Modes for RID Index Scans with a Single Qualifying Row&lt;/h3&gt;

&lt;dl&gt;
&lt;dt&gt;DB2使用索引扫描方式执行SQL，带谓词，例如：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;select a from test where a=2 或者 update test set b=1 where a=4&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;这里，我们的test表上，对a字段有索引。&lt;/p&gt;

&lt;p&gt;[[img:db2-locks-4.png][db2locks table 4]]
[[../images/db2-locks-4.png]]&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;这种情况下，表二中的情况都能并行，但是别太乐观，如果我们往表里面增加一条记录：&lt;/dt&gt;
&lt;dd&gt;insert into test values(6,0)
这个时候你再尝试先在事务一执行：&lt;/dd&gt;
&lt;dd&gt;update test set b=11 where a=5 with rs
然后在事务二执行：&lt;/dd&gt;
&lt;dd&gt;update test set b=11 where a=9 and a=3 with rs
不幸的是，事务二被阻塞了，你可以通过db2top获取事务二SQL的执行计划就知道原因，该
update没有走索引，而是使用了全表扫描。&lt;/dd&gt;
&lt;/dl&gt;

&lt;h3 id=&#34;lock-modes-for-rid-index-scans-with-start-and-stop-predicates-only&#34;&gt;Lock Modes for RID Index Scans with Start and Stop Predicates Only&lt;/h3&gt;

&lt;dl&gt;
&lt;dt&gt;DB2使用索引扫描方式执行SQL，带谓词，类似语句：&lt;/dt&gt;
&lt;dd&gt;select * from test where a&amp;gt;1 and a&amp;lt;5&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;基本情况都和上面类似，就不详述了，关键点就是执行计划会影响锁的使用。&lt;/p&gt;

&lt;p&gt;[[img:db2-locks-5.png][db2locks table 5]]
[[../images/db2-locks-5.png]]&lt;/p&gt;

&lt;h3 id=&#34;lock-modes-for-rid-index-scans-with-index-and-other-predicates-sargs-resids-only&#34;&gt;Lock Modes for RID Index Scans with Index and Other Predicates (sargs, resids) Only&lt;/h3&gt;

&lt;p&gt;[[img:db2-locks-6.png][db2locks table 6]]
[[../images/db2-locks-6.png]]&lt;/p&gt;

&lt;h3 id=&#34;lock-modes-for-index-scans-used-for-deferred-data-page-access-rid-index-scan-with-no-predicates&#34;&gt;Lock Modes for Index Scans Used for Deferred Data Page Access: RID Index Scan with No Predicates&lt;/h3&gt;

&lt;p&gt;后续的表主要理解Deferred Data Page Access这个概念，说的应该是多索引情况，感觉和
前面的情况没有明显区别，可能情况更复杂点，比如先扫描A索引，获取ROW的bitmap和后
续索引的bitmap做逻辑运算，获取最后结果，有可能更复杂，有待深入了解。&lt;/p&gt;

&lt;p&gt;[[img:db2-locks-7.png][db2locks table 7]]
[[../images/db2-locks-7.png]]&lt;/p&gt;

&lt;h3 id=&#34;lock-modes-for-index-scans-used-for-deferred-data-page-access-after-a-rid-index-scan-with-no-predicates&#34;&gt;Lock Modes for Index Scans Used for Deferred Data Page Access: After a RID Index Scan with No Predicates&lt;/h3&gt;

&lt;p&gt;[[img:db2-locks-8.png][db2locks table 8]]
[[../images/db2-locks-8.png]]&lt;/p&gt;

&lt;h3 id=&#34;lock-modes-for-index-scans-used-for-deferred-data-page-access-rid-index-scan-with-predicates-sargs-resids&#34;&gt;Lock Modes for Index Scans Used for Deferred Data Page Access: RID Index Scan with Predicates (sargs, resids)&lt;/h3&gt;

&lt;p&gt;[[img:db2-locks-9.png][db2locks table 9]]
[[../images/db2-locks-9.png]]&lt;/p&gt;

&lt;h3 id=&#34;lock-modes-for-index-scans-used-for-deferred-data-page-access-after-a-rid-index-scan-with-predicates-sargs-resids&#34;&gt;Lock Modes for Index Scans Used for Deferred Data Page Access: After a RID Index Scan with Predicates (sargs, resids)&lt;/h3&gt;

&lt;p&gt;[[img:db2-locks-10.png][db2locks table 10]]
[[../images/db2-locks-10.png]]&lt;/p&gt;

&lt;h3 id=&#34;lock-modes-for-index-scans-used-for-deferred-data-page-access-rid-index-scan-with-start-and-stop-predicates-only&#34;&gt;Lock Modes for Index Scans Used for Deferred Data Page Access: RID Index Scan with Start and Stop Predicates Only&lt;/h3&gt;

&lt;p&gt;[[img:db2-locks-11.png][db2locks table 11]]
[[../images/db2-locks-11.png]]&lt;/p&gt;

&lt;h3 id=&#34;lock-modes-for-index-scans-used-for-deferred-data-page-access-after-a-rid-index-scan-with-start-and-stop-predicates-only&#34;&gt;Lock Modes for Index Scans Used for Deferred Data Page Access: After a RID Index Scan with Start and Stop Predicates Only&lt;/h3&gt;

&lt;p&gt;[[img:db2-locks-12.png][db2locks table 12]]
[[../images/db2-locks-12.png]]&lt;/p&gt;

&lt;h2 id=&#34;研究锁的一些方法&#34;&gt;研究锁的一些方法&lt;/h2&gt;

&lt;dl&gt;
&lt;dt&gt;验证RS隔离级别下两个SQL的并发情况，只需要写类似如下的SQL：&lt;/dt&gt;
&lt;dd&gt;db2 +c &amp;lsquo;select * from test where a=1 with rs&amp;rsquo;
该SQL表明不自动提交，同时使用RS隔离级别。&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dt&gt;验证RS隔离级别下两个SQL的并发情况，只需要写类似如下的SQL：&lt;/dt&gt;
&lt;dd&gt;db2 +c &amp;lsquo;select * from test where a=1 with rs&amp;rsquo;
该SQL表明不自动提交，同时使用RS隔离级别。&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;，同时使用RS隔离级别。&lt;/p&gt;

&lt;p&gt;观察锁的情况，通过db2pd即可，比如我要观察阻塞的锁：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;db2inst1@tacy:~$ db2pd -d tacy -wlocks
Database Partition 0 -- Database TACY -- Active -- Up 0 days 02:21:36 -- Date 04/03/2014 22:16:53

Locks being waited on :
AppHandl [nod-index] TranHdl    Lockname                   Type       Mode Conv Sts CoorEDU    AppName  AuthID   AppID
552      [000-00552] 12         02000400080000000000000052 Row        ..X       G   78         db2bp    DB2INST1 *LOCAL.db2inst1.140403115529
541      [000-00541] 2          02000400080000000000000052 Row        ..U       W   20         db2bp    DB2INST1 *LOCAL.db2inst1.140403115517
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;简单解读一下，Lockname一致，表明他们希望是同样对象的锁，TranHdl表明事务ID，事务
12持有Row上的X锁（Sts状态为G，表明获得锁），事务2等待（Sts状态未W，表明等待锁）
。更详细信息可以通过下面命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;db2inst1@tacy:~$ db2pd -db tacy -locks showlock wait

Database Partition 0 -- Database TACY -- Active -- Up 0 days 02:31:33 -- Date 04/03/2014 22:26:50

Locks:
Address            TranHdl    Lockname                   Type       Mode Sts Owner      Dur HoldCount  Att        ReleaseFlg rrIID
0x00007F0B562B1780 2          02000400080000000000000052 Row        ..U  W   12         1   0          0x00000000 0x40000000 0     	TbspaceID 2     TableID 4      PartitionID 0 Page 0 Slot 8
0x00007F0B562B5A00 12         02000400080000000000000052 Row        ..X  G   12         1   0          0x00000000 0x40000000 0     	TbspaceID 2     TableID 4      PartitionID 0 Page 0 Slot 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;他们锁在了表空间ID为2上的一个表上的一行，该表的ID是4，行的位置在Page 0的Slot 8
上。从锁的情况看，可能是一个Update语句阻塞了另一个Update语句，后一个Update语句
走了全表扫描。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;如果你想看看具体该SQL语句的执行计划，你可以通过db2top工具，使用方法是：&lt;/dt&gt;
&lt;dd&gt;db2top -d tacy
首先进入Dyanmic sql视图；按‘/’键，输入‘test’，会列出所有包含‘test’关键字的SQL；
键入‘L’键，输入对应SQL的‘SQL_Statement HashValue‘，会显示该SQL全文；键入‘e’键
，能够得到该SQL的执行计划。如果想更详细了解db2top，请参考官方文档。&lt;/dd&gt;
&lt;dt&gt;更进一步，如果你想了解他们锁的对象以及锁在哪一行上，前者比较简单，通过下面SQL语
句即可：&lt;/dt&gt;
&lt;dd&gt;select tabname,tbspace from syscat.tables where tableid=? and tbspaceid=?
后者需要通过db2dart工具来实现，不过db2dart一般无法在生产环境使用，因为他要求数
据库上不能有任何连接。如果你想知道上面的SQL到底阻塞在哪一行，可以使用下面命令：&lt;/dd&gt;
&lt;dd&gt;db2dart tacy /dd /oi 4 /tsi 2 /ps 0 /np 1 /v y
工具会生成一个RPT文件，直接文本编辑器打开，找到‘Slot 8‘条目即可。&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;如果你不熟悉db2的系统表，用下面命令做个简单了解：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;db2 list tables for all
db2 describe table syscat.tables
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;结尾&#34;&gt;结尾&lt;/h2&gt;

&lt;p&gt;到这里结束本文，希望能对你了解DB2有一点帮助，当然了解的最好方法还是自己动手实验
，DB2提供免费的C-Express版本，在Ubuntu上直接安装db2exc包即可，非常方便，做测试
这个版本就够了。最后需要强调一点，不清楚的地方找DB2的InformationCenter。&lt;/p&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;https://www.dropbox.com/sh/1wse9pmgvl81eay/35A7yi_49L/Lock%2520attributes.pdf][Lock&#34;&gt;https://www.dropbox.com/sh/1wse9pmgvl81eay/35A7yi_49L/Lock%2520attributes.pdf][Lock&lt;/a&gt; attributes]]&lt;/p&gt;

&lt;p&gt;[fn:2] [[&lt;a href=&#34;https://www.dropbox.com/sh/1wse9pmgvl81eay/52lfCfqavV/Lock%2520type%2520compatibility.pdf][Lock&#34;&gt;https://www.dropbox.com/sh/1wse9pmgvl81eay/52lfCfqavV/Lock%2520type%2520compatibility.pdf][Lock&lt;/a&gt; type compatibility]]&lt;/p&gt;

&lt;p&gt;[fn:3] [[&lt;a href=&#34;https://www.dropbox.com/sh/1wse9pmgvl81eay/DQeN41RvmW/Lock%25C2%25A0modes%25C2%25A0and%25C2%25A0access%25C2%25A0plans%25C2%25A0for%25C2%25A0standard%25C2%25A0tables.pdf][Lock&#34;&gt;https://www.dropbox.com/sh/1wse9pmgvl81eay/DQeN41RvmW/Lock%25C2%25A0modes%25C2%25A0and%25C2%25A0access%25C2%25A0plans%25C2%25A0for%25C2%25A0standard%25C2%25A0tables.pdf][Lock&lt;/a&gt; modes and access plans for standard tables]]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>HotSpot GC日志解读</title>
      <link>http://tacy.github.io/post/hotspot-gc/</link>
      <pubDate>Mon, 24 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/hotspot-gc/</guid>
      
        <description>

&lt;h1 id=&#34;hotspot-gc&#34;&gt;HotSpot GC&lt;/h1&gt;

&lt;p&gt;对于Java应用的优化，GC是重要的一环，而读懂GC日志是调优GC的关键，本文尝试对GC
做一些解读，测试使用的JVM版本是1.6.0_45-b06（64Bit）。&lt;/p&gt;

&lt;h2 id=&#34;几个概念&#34;&gt;几个概念&lt;/h2&gt;

&lt;h3 id=&#34;serial-parallel&#34;&gt;Serial &amp;amp; Parallel&lt;/h3&gt;

&lt;p&gt;Serial收集意味着单线程操作，而Parallel是尽可能的并行，在多CPU机器上，切分收集
任务到多个CPU运行，能够更快的完成收集操作，相对更复杂。&lt;/p&gt;

&lt;h3 id=&#34;concurrent-stop-the-world&#34;&gt;Concurrent &amp;amp; Stop-the-world&lt;/h3&gt;

&lt;p&gt;STW收集策略指在GC期间，应用挂起，完成GC操作之后，应用继续运行，Concurrent策略
是指GC操作和应用并行，只是在做一些必要操作的时候挂起应用。STP相比Concurrent简
单，因为STW冻结了VM Heap，收集期间对象不会改变，能更快的完成GC操作，缺点是带来
比较长时间的应用挂起，有些应用无法接受；而Concurrent在收集期间应用同时运行，会
带来VM Heap内对象的变化，设计起来更复杂，需要更大的VM Heap来完成，调优起来也更
复杂。&lt;/p&gt;

&lt;h3 id=&#34;compacting-non-compacting-copying&#34;&gt;Compacting &amp;amp; Non-compacting &amp;amp; Copying&lt;/h3&gt;

&lt;p&gt;Compacting是指GC之后，移动所有的活着的对象到一起，形成连续的空闲空间，能够高效
的完成后续的对象分配任务，只需简单的移动指针。Non-compacting则是就地释放对象，
也不会移动活着的对象，相对Compacting能更快完成，缺点是分配对象复杂，需要管理
碎片空间。Copying是指拷贝存活对象到另外的内存空间，清空源内存空间，后续对象分配
更容易，缺点是拷贝对象的开销。&lt;/p&gt;

&lt;h2 id=&#34;hotspot-jvm组成&#34;&gt;HotSpot JVM组成&lt;/h2&gt;

&lt;p&gt;包括两块，一块是JVM heap，另一块是Permanent Generation，主要我们关注JVM heap，
JVM heap又分为两块：Young Generation和Old Generation（Tenured）。新分配对象和
短生命周期对象一般都在Young Generation（大对象会直接分配到Old Generation中）,
Old Generation主要是长生命周期的对象。&lt;/p&gt;

&lt;p&gt;JVM heap大小通过-Xms和-Xmx控制，一般生产环境会设置相同的值，如果不是设置相同
大小，每一次JVM调整heap时候都会导致Full GC，对系统运行产生一定影响。&lt;/p&gt;

&lt;p&gt;Permanent Generation大小通过-XX:PermSize和-XX：MaxPermSize控制，大小主要看
项目jar包的多少，这里主要存放的是class元数据和VM自己运行的数据，设置大小一致
能避免Permanent空间调整导致的Full GC。&lt;/p&gt;

&lt;p&gt;Young Generation分为三块，一块是Eden space，另外两块是大小相等的Survivor space，
我们这里简称S0、S1。Young Generation大小的控制有下面参数：
-XX:NewSize / -XX:MaxNewSize (最大最小）
-XX:NewRatio=3 指定Young Generation和Old Generation的比例是1：3
-Xmn 最大最小保持一致
JVM也提供了自适应的调整策略，如果你没有明确指定这些值，JVM会自己调整大小（搜索
HotSport VM Adaptive）。&lt;/p&gt;

&lt;p&gt;Eden space和Survivor space大小通过-XX:SurvivorRatio=6参数可以控制，等于6表示
Survivor space大小是Eden Space的1/6，是整个Young Generation的1/8（注意是两个
Survivor space）。一般这个参数不会设置，JVM会自动计算最优比例，如果设置不合理
容易导致Survivor space overflow（过小）或者Survivor space浪费(过大），Overflow
的后果会导致放不下的对象直接迁移到Old Generation，带来不必要的Full GC。具体的
行为可以通过-XX:+PrintTenuringDistribution观察。&lt;/p&gt;

&lt;h2 id=&#34;gc的策略&#34;&gt;GC的策略&lt;/h2&gt;

&lt;p&gt;记住几点：
- GC的回收策略有不同的作用区域；
- 所有的Serial和Parallel策略都是STW的；
- 所有对Young Gen的回收都是Copying策略；
- Concurrent策略都是非STW的；&lt;/p&gt;

&lt;p&gt;作用域和参数参考下表[fn:5]：&lt;/p&gt;

&lt;p&gt;| Young Collector   | Old Collector               | JVM Option             |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;|
| Serial(DefNew)    | Serial Mark-Sweep-Compact   | -XX:+UseSerialGC       |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;|
| Parallel scavenge | Serial Mark-Sweep-Compact   | -XX:+UseParallelGC     |
| (PSYoungGen)      | (PSOldGen)                  |                        |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;|
| Parallel scavenge | Parallel Mark-Sweep-Compact | -XX:+UseParallelOldGC  |
| (PSYoungGen)      | (ParOldGen)                 |                        |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;|
| Parallel(ParNew)  | Serial Mark-Sweep-Compact   | -XX:+UseParNewGC       |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;|
| Serial(DefNew)    | Concurrent Mark Sweep       | -XX:UseConcMarkSweepGC |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;|
| Parallel(ParNew)  | Concurrent Mark Sweep       | -XX:UseConcMarkSweepGC |
|                   |                             | -XX:+UseParNewGC       |
|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;|
| G1                | G1                          | -XX:+UseG1             |&lt;/p&gt;

&lt;h3 id=&#34;serialgc&#34;&gt;SerialGC&lt;/h3&gt;

&lt;p&gt;YoungGen和OldGen回收策略，GC使用单线程，回收期间STP，适用于单处理器服务器和小的
堆（一两百兆）。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;10.590: [GC 10.590: [DefNew: 34944K-&amp;gt;3140K(39296K), 0.0171370 secs] 95253K-&amp;gt;63449K(126720K), 0.0171930 secs] [Times: user=0.02 sys=0.00, real=0.02 secs]
10.787: [GC 10.787: [DefNew: 38084K-&amp;gt;1913K(39296K), 0.0242650 secs] 98393K-&amp;gt;65358K(126720K), 0.0243320 secs] [Times: user=0.02 sys=0.00, real=0.02 secs]
10.842: [GC 10.842: [DefNew: 36857K-&amp;gt;3477K(39296K), 0.0134890 secs] 100302K-&amp;gt;66922K(126720K), 0.0136120 secs] [Times: user=0.01 sys=0.00, real=0.02 secs]
11.012: [Full GC 11.012: [Tenured: 63445K-&amp;gt;67278K(87424K), 0.2908000 secs] 82061K-&amp;gt;67278K(126720K), [Perm : 64767K-&amp;gt;64760K(64768K)], 0.2908740 secs] [Times: user=0.29 sys=0.00, real=0.29 secs]
11.954: [Full GC 11.954: [Tenured: 67278K-&amp;gt;69894K(87424K), 0.2313190 secs] 91392K-&amp;gt;69894K(126720K), [Perm : 70207K-&amp;gt;70207K(70208K)], 0.2313890 secs] [Times: user=0.24 sys=0.00, real=0.23 secs]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;日志中的DefNew表示Serial回收，OldGen回收也是采用Serial Mark-Sweep-Compact。从日
志里面能获取到很多信息：
看第一行，34944K表示回收之前YoungGen对象大小，3140K表示回收之后存活的对象大小(结
合后续MinorGC小节里面的TargetSurvivorRatio可以准确计算出Survivor space大小），耗
时0.017930S，95253K表示回收之前JVM Heap对象占用空间大小，63449K表示回收之后堆内对
象大小，126720K表示整个堆大小。（126720K-39296K）=87424K是Old Gen大小，被回收的
垃圾对象为（95253K-63449K）=31804K，移动到OldGen对象（34944K-3140K-31804K）=0K，
回收所用的User时间为0.02S，系统调用时间0S，时间周期0.02S，三个值区别参考[fn:10]。
看第四行，你会发现Old Gen还有空间，触发GC的是Perm Gen，已经满了，尝试回收，发现
回收不了64767K -&amp;gt; 64760K，扩容Perm Gen，触发Full GC。&lt;/p&gt;

&lt;h3 id=&#34;parallel-scavenge&#34;&gt;Parallel Scavenge&lt;/h3&gt;

&lt;p&gt;Young Gen回收策略，并发回收，回收期间STW。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;13.782: [GC [PSYoungGen: 18768K-&amp;gt;3368K(29632K)] 93584K-&amp;gt;80361K(117056K), 0.0082680 secs] [Times: user=0.03 sys=0.00, real=0.01 secs]
14.015: [GC [PSYoungGen: 19944K-&amp;gt;5449K(31424K)] 96937K-&amp;gt;85551K(118848K), 0.0097840 secs] [Times: user=0.03 sys=0.00, real=0.01 secs]
14.024: [Full GC [PSYoungGen: 5449K-&amp;gt;0K(31424K)] [PSOldGen: 80101K-&amp;gt;85415K(87424K)] 85551K-&amp;gt;85415K(118848K) [PSPermGen: 76528K-&amp;gt;76528K(153344K)], 0.2642610 secs] [Times: user=0.27 sys=0.00, real=0.27 secs]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;日志中的PSYoungGen表示Parallel Scavenge，并行对YoungGen回收，PSOldGen表示Serial
Mark-Sweep-Compact，单线程对OldGen进行回收。这里Minor GC中的user时间大于real时
间是由于多线程并行导致。&lt;/p&gt;

&lt;h3 id=&#34;parallel-mark-sweep-compact&#34;&gt;Parallel Mark-Sweep-Compact&lt;/h3&gt;

&lt;p&gt;Old Gen回收策略，并发回收，回收期间STW。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;14.488: [GC [PSYoungGen: 19568K-&amp;gt;7759K(29760K)] 96421K-&amp;gt;87358K(117184K), 0.0180290 secs] [Times: user=0.06 sys=0.00, real=0.02 secs]
14.632: [GC [PSYoungGen: 25551K-&amp;gt;288K(30720K)] 105150K-&amp;gt;87492K(118144K), 0.0135020 secs] [Times: user=0.03 sys=0.00, real=0.02 secs]
14.646: [Full GC [PSYoungGen: 288K-&amp;gt;0K(30720K)] [ParOldGen: 87204K-&amp;gt;66401K(87424K)] 87492K-&amp;gt;66401K(118144K) [PSPermGen: 76492K-&amp;gt;76370K(153408K)], 0.8717190 secs] [Times: user=2.76 sys=0.00, real=0.87 secs]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;日志中的ParOldGen表示Paralle Mark-Sweep-Compact，并行对OldGen进行回收。&lt;/p&gt;

&lt;p&gt;两个Parallel策略也被称为Throught回收策略，由于并行进行GC操作，提高GC效率，获取
更高的应用吞吐量，但是Parallel同时会导致比较长的STW，对延迟敏感的应用不适用。&lt;/p&gt;

&lt;h3 id=&#34;concurrent-mark-sweep&#34;&gt;Concurrent-Mark-Sweep&lt;/h3&gt;

&lt;p&gt;Old Gen回收策略，也被称为低延迟的GC策略，很少的STP操作，但是需要Old Gen保持一定
的空闲空间来防止碎片问题（没有Compact，YoungGen promotion进来的对象需要连续的空
间，容易导致fragmentation）。它分为六个步骤执行[fn:6]：
- Initial Mark (STW)
  标记root object直接引用的对象
- Concurrent Mark
  应用线程继续响应，标记第一步标记对象引用的所有对象。
- Concurrent Preclean
- Remark (STW)
- Concurrent Sweep
- Concurrent Reset
打开CMS同时缺省打开ParNewGC策略对YoungGen进行并行回收。
下面日志是一个完整的CMS周期，详细解释请参考[fn:7]，注意这里的日志是JDK8的，
主要是大牛写的很详细，我就懒得自己整理了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1.[GC [1 CMS-initial-mark: 463236K(515960K)] 464178K(522488K), 0.0018216 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]
2.[GC[ParNew: 6528K-&amp;gt;702K(6528K), 0.0130227 secs] 469764K-&amp;gt;465500K(522488K), 0.0130578 secs] [Times: user=0.05 sys=0.00,real=0.01 secs]
3.[GC[ParNew: 6526K-&amp;gt;702K(6528K), 0.0136447 secs] 471324K-&amp;gt;467077K(522488K), 0.0136804 secs] [Times: user=0.04 sys=0.01,real=0.01 secs]
4.[GC[ParNew: 6526K-&amp;gt;702K(6528K), 0.0161873 secs] 472901K-&amp;gt;468830K(522488K), 0.0162411 secs] [Times: user=0.05 sys=0.00,real=0.02 secs]
5.[GC[ParNew: 6526K-&amp;gt;702K(6528K), 0.0152107 secs] 474654K-&amp;gt;470569K(522488K), 0.0152543 secs] [Times: user=0.05 sys=0.00,real=0.02 secs]
...
6.[GC[ParNew: 6526K-&amp;gt;702K(6528K), 0.0144212 secs] 481073K-&amp;gt;476809K(522488K), 0.0144719 secs] [Times: user=0.05 sys=0.00,real=0.01 secs]
7.[CMS-concurrent-mark: 1.039/1.154 secs] [Times: user=2.32 sys=0.02, real=1.15 secs]
8.[CMS-concurrent-preclean: 0.006/0.007 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]
9.[GC[ParNew: 6526K-&amp;gt;702K(6528K), 0.0141896 secs] 482633K-&amp;gt;478368K(522488K), 0.0142292 secs] [Times: user=0.04 sys=0.00,real=0.01 secs]
10.[GC[ParNew: 6526K-&amp;gt;702K(6528K), 0.0162142 secs] 484192K-&amp;gt;480082K(522488K), 0.0162509 secs] [Times: user=0.05 sys=0.00,real=0.02 secs]
11.[CMS-concurrent-abortable-preclean: 0.022/0.175 secs] [Times: user=0.36 sys=0.00, real=0.17 secs]
12.[GC[YG occupancy: 820 K (6528 K)][Rescan (parallel) , 0.0024157 secs][weak refs processing, 0.0000143 secs][scrub string table, 0.0000258 secs] [1 CMS-remark: 479379K(515960K)] 480200K(522488K), 0.0025249 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]
13.[GC[ParNew: 6526K-&amp;gt;702K(6528K), 0.0133250 secs] 441217K-&amp;gt;437145K(522488K), 0.0133739 secs] [Times: user=0.04 sys=0.00, real=0.01 secs]
14.[GC[ParNew: 6526K-&amp;gt;702K(6528K), 0.0125530 secs] 407061K-&amp;gt;402841K(522488K), 0.0125880 secs] [Times: user=0.04 sys=0.00,real=0.01 secs]
...
15.[GC[ParNew: 6526K-&amp;gt;702K(6528K), 0.0121435 secs] 330503K-&amp;gt;326239K(522488K), 0.0121996 secs] [Times: user=0.04 sys=0.00,real=0.01 secs]
16.[CMS-concurrent-sweep: 0.756/0.833 secs] [Times: user=1.68 sys=0.01, real=0.83 secs]
17.[CMS-concurrent-reset: 0.009/0.009 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里时间统计多说一句，比如倒数第二行中的0.&lt;sup&gt;756&lt;/sup&gt;&amp;frasl;&lt;sub&gt;0&lt;/sub&gt;.833 secs，0.756表示运行sweep
时间，0.833表示时钟运行的时间（等于real），由于sweep操作是并行的，所以user大
于real。&lt;/p&gt;

&lt;p&gt;CMS周期期间，因为Minor GC会继续运行（Minor GC进入会挂起CMS的concurrent操作），
会出现Minor GC promotion failure的情况（YoungOld中的长生命周期对象需要移动到
Old Gen中，但是Old Gen空间不足或者没有连续的空间块来容纳移动的对象），这会导
致CMS中断，同时触发Full GC操作，参考下面日志：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;64.528: [GC 64.528: [ParNew: 19128K-&amp;gt;2112K(19136K), 0.0088010 secs] 108133K-&amp;gt;94575K(128960K), 0.0088840 secs] [Times: user=0.02 sys=0.01, real=0.01 secs]
64.538: [GC [1 CMS-initial-mark: 92463K(109824K)] 94693K(128960K), 0.0057310 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]
64.544: [CMS-concurrent-mark-start]
64.732: [GC 64.732: [ParNew: 19122K-&amp;gt;2112K(19136K), 0.0158700 secs] 111585K-&amp;gt;98845K(128960K), 0.0159520 secs] [Times: user=0.06 sys=0.00, real=0.02 secs]
64.874: [CMS-concurrent-mark: 0.312/0.330 secs] [Times: user=1.17 sys=0.02, real=0.34 secs]
64.874: [CMS-concurrent-preclean-start]
64.886: [CMS-concurrent-preclean: 0.012/0.012 secs] [Times: user=0.05 sys=0.00, real=0.01 secs]
64.886: [CMS-concurrent-abortable-preclean-start]
64.933: [GC 64.933: [ParNew: 19136K-&amp;gt;2112K(19136K), 0.0106420 secs] 115869K-&amp;gt;102790K(128960K), 0.0107100 secs] [Times: user=0.03 sys=0.00, real=0.01 secs]
65.060: [GC 65.060: [ParNew: 19136K-&amp;gt;2112K(19136K), 0.0145130 secs] 119814K-&amp;gt;105946K(128960K), 0.0146300 secs] [Times: user=0.04 sys=0.00, real=0.02 secs]
65.156: [CMS-concurrent-abortable-preclean: 0.151/0.269 secs] [Times: user=0.89 sys=0.01, real=0.27 secs]
65.156: [GC[YG occupancy: 11152 K (19136 K)]65.156: [Rescan (parallel) , 0.0068730 secs]65.163: [weak refs processing, 0.0000630 secs] [1 CMS-remark: 103834K(109824K)] 114987K(128960K), 0.0070350 secs] [Times: user=0.02 sys=0.00, real=0.00 secs]
65.163: [CMS-concurrent-sweep-start]
65.250: [GC 65.250: [ParNew (promotion failed): 19136K-&amp;gt;19136K(19136K), 0.8336480 secs]66.084: [CMS66.109: [CMS-concurrent-sweep: 0.112/0.946 secs] [Times: user=1.50 sys=0.22, real=0.95 secs]
 (concurrent mode failure): 107755K-&amp;gt;92385K(109824K), 0.4802380 secs] 121588K-&amp;gt;92385K(128960K), [CMS Perm : 80068K-&amp;gt;78975K(133032K)], 1.3140100 secs] [Times: user=1.61 sys=0.22, real=1.31 secs]
66.816: [GC 66.816: [ParNew: 17024K-&amp;gt;2112K(19136K), 0.0097300 secs] 109409K-&amp;gt;95636K(128960K), 0.0098010 secs] [Times: user=0.03 sys=0.00, real=0.01 secs]
&lt;/code&gt;&lt;/pre&gt;

&lt;dl&gt;
&lt;dt&gt;值JVM会动态调整，你可以通过观察日志计算它，比如下面日志中：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;29.542: [GC [1 CMS-initial-mark: 56351K(109824K)] 58400K(128960K), 0.0031880 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dt&gt;值JVM会动态调整，你可以通过观察日志计算它，比如下面日志中：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;29.542: [GC [1 CMS-initial-mark: 56351K(109824K)] 58400K(128960K), 0.0031880 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;dl&gt;
&lt;dt&gt;整，你可以通过观察日志计算它，比如下面日志中：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;29.542: [GC [1 CMS-initial-mark: 56351K(109824K)] 58400K(128960K), 0.0031880 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;该值在51左右（56351/109824=0.51），如果需要提前触发CMS，通过下面两个参数：
CMSInitiatingOccupancyFraction和UseCMSInitiatingOccupancyOnly（需要两个都设置，
否则只是第一次生效，后续JVM还是会自己调整）。另外就是避免对象移动过快，通过调优
Young Gen参数实现，当然治标的办法自然是减少对象分配速度。当然你也能增加OldGen。&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;前面一样：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;62.231: [GC 62.231: [ParNew (promotion failed): 19137K-&amp;gt;19136K(19136K), 0.0403870 secs]62.271: [CMS: 99459K-&amp;gt;77486K(109824K), 0.4331580 secs] 116817K-&amp;gt;77486K(128960K), [CMS Perm : 80178K-&amp;gt;79817K(132164K)], 0.4737430 secs] [Times: user=0.50 sys=0.01, real=0.47 secs]&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;), [CMS Perm : 80178K-&amp;gt;79817K(132164K)], 0.4737430 secs] [Times: user=0.50 sys=0.01, real=0.47 secs]&lt;/p&gt;

&lt;p&gt;另外一个触发Full GC的是PermGen，CMS缺省不会收集PermGen，容易导致Perm空间满，你
可以设置参数CMSClassUnloadingEnabled，让CMS也对PermGen进行收集：&lt;/p&gt;

&lt;p&gt;还有一个参数‑XX:+ExplicitGCInvokesConcurrent，该参数可以让System.gc()不会触发
Full GC，这个比较有用。貌似-XX:+DisableExplicitGC会带来DirectByteMemory OOM问
题，如果你的程序中大量用了NIO。&lt;/p&gt;

&lt;h2 id=&#34;gc&#34;&gt;GC&lt;/h2&gt;

&lt;p&gt;GC分为Minor GC、Full GC（Major GC）。&lt;/p&gt;

&lt;h3 id=&#34;minor-gc&#34;&gt;Minor GC&lt;/h3&gt;

&lt;p&gt;主要对Young Generation进行回收，Minor GC之后，eden space和一块survivor
space清空，一些生命周期长的对象会移动到Old Generation，另外的对象都会移动到另一
块Survivor space中（如果之前是S0清空，那么所有活着的对象都会被移动到S1，反之同
理），理解这一点对于分析GC log非常关键。&lt;/p&gt;

&lt;p&gt;多长生命周期的对象会被移动[fn:4]，通俗点来说就是通过年龄控制。对象经历一次Minor GC增
加一岁。至于说多大年龄的对象会被移动，通过几个参数控制：TargetSurvivorRatio、
Survivor space size、MaxTenuringThreshold。每次Minor GC都会计算Survivor space
中期望保留的对象多少，通过（TargetSurvivorRatio * Survivor space size）计算得出
，具体的值可以通过打开-XX:+PrintTenuringDistribution参数查看日志中的Desired
survivor size。如果保留的对象大小超出期望的值，TenuringThreshold（对象年龄阀值
，超出会被迁移）就会降低，让更多的对象移动到Old Gen中，如果小于期望的值，当前值
不变。TenuringThreshold最大值通过MaxTenuringThreshold控制，范围是0～15。
TargetSurvivorRatio缺省是50，MaxTenuringThreshold缺省是15（ParalleGC,CMS是4）。&lt;/p&gt;

&lt;p&gt;VM中的对象分配都在Eden中进行，由于每次Minor GC都会清空Eden，所以Eden中的
空间都是连续的（没有碎片），为了保证分配对象的高效[fn:1][fn:3]，VM使用了两个技术：
- bump-the-pointer
  由于是连续的空间，VM只需记住最晚分配对象的空间地址（在Eden顶上），下次分配的时
  候，只需变更地址就行。
- Thread-Local Allocation Buffers (TLAB)
  考虑到多线程的情况，如果多个线程去更新保存的地址，需要加锁，为了避免锁VM引入了
  TLAB技术，每个线程都会有一块自己的空间（TLAB）来分配对象（也采用BTP技术，TLAB
  位于Eden），这样就不需要引入锁。当一个TLAB分配满了之后（或者Minor GC来临），
  TLAB释放，GC完成之后，线程会在需要分配对象的时候申请TLAB。如果线程的TLAB满了需
  要继续申请对象，同时Eden还有空间的时候，那就要锁了。关于TLAB相关细节可以参考[fn:2]&lt;/p&gt;

&lt;p&gt;考虑到有些Young Gen中的对象会被Old Gen引用，Minor GC也需要扫描Old Gen，未了避免
扫描整个Old Gen，VM采用Card table技术，尽量减少扫描的范围。VM会把Old Gen分隔为
512 bytes的块，card table是一个byte array，一个byte对应一个块，如果块的对象引用
到Young Gen对象，标示该card为dirty，这样Minor GC的时候只需要扫描dirty的table。&lt;/p&gt;

&lt;h3 id=&#34;full-gc&#34;&gt;Full GC&lt;/h3&gt;

&lt;p&gt;会对整个JVM Heap进行回收，包括YoungGen、OldGen、PermGen。主要是由Old Generation
空间不足触发（当然有很多种触发因素，比如system.gc()调用、Remote distributed GC
等），耗时会比较长，而且是STW操作（停止应用响应）。&lt;/p&gt;

&lt;h3 id=&#34;concurrent-gc&#34;&gt;Concurrent GC&lt;/h3&gt;

&lt;p&gt;另外这里特别说明一下，Concurrent应该算是一个独立的GC类型，只对OldGen收集（可以包
括PernGen，目的就是尽量减少FullGC操作（对延迟敏感的应用无法忍受这么长的STP）。&lt;/p&gt;

&lt;h2 id=&#34;几个相关参数&#34;&gt;几个相关参数&lt;/h2&gt;

&lt;h3 id=&#34;gc日志&#34;&gt;GC日志&lt;/h3&gt;

&lt;dl&gt;
&lt;dt&gt;打印GC日志，建议在线上环境打开，开销很小，调优GC必不可少：&lt;/dt&gt;
&lt;dd&gt;-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintTenuringDistribution -Xloggc:file
更多的信息：&lt;/dd&gt;
&lt;dd&gt;-XX:+PrintHeapAtGC -XX:+PrintTLAB&lt;/dd&gt;
&lt;/dl&gt;

&lt;h3 id=&#34;vm参数查看&#34;&gt;VM参数查看&lt;/h3&gt;

&lt;dl&gt;
&lt;dt&gt;研究，也可以参考这篇blog[fn:9]，说明了输出的一些细节：&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;-XX:+PrintCommandLineFlags
这个参数的作用是显示出VM初始化完毕后所有跟最初的默认值不同的参数及它们的值。这
个参数至少在Sun JDK 5上已经开始支持，Oracle/Sun JDK 6以及Oracle JDK 7上也可以使
用。Sun JDK 1.4.2还不支持这个参数。&lt;/p&gt;&lt;/dd&gt;
&lt;dd&gt;&lt;p&gt;-XX:+PrintFlagsFinal
前一个参数只显示跟默认值不同的，而这个参数则可以显示所有可设置的参数及它们的值。
不过这个参数本身只从JDK 6 update 21开始才可以用，之前的Oracle/Sun JDK则用不了。
可以设置的参数默认是不包括diagnostic或experimental系的。要在-XX:+PrintFlagsFinal
的输出里看到这两种参数的信息，分别需要显式指定-XX:+UnlockDiagnosticVMOptions /
-XX:+UnlockExperimentalVMOptions 。&lt;/p&gt;&lt;/dd&gt;
&lt;dd&gt;&lt;p&gt;-XX:+PrintFlagsInitial
这个参数显示在处理参数之前所有可设置的参数及它们的值，然后直接退出程序。“参数
处理”包括许多步骤，例如说检查参数之间是否有冲突，通过ergonomics调整某些参数的值
，之类的。结合-XX:+PrintFlagsInitial与-XX:+PrintFlagsFinal，对比两者的差异，就可
以知道ergonomics对哪些参数做了怎样的调整。&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;+PrintFlagsFinal，对比两者的差异，就可
以知道ergonomics对哪些参数做了怎样的调整。&lt;/p&gt;

&lt;h2 id=&#34;其他推荐阅读&#34;&gt;其他推荐阅读&lt;/h2&gt;

&lt;h3 id=&#34;一些值得阅读的blog-待补全&#34;&gt;一些值得阅读的blog，待补全&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;[[&lt;a href=&#34;https://blogs.oracle.com/jonthecollector/][Jon&#34;&gt;https://blogs.oracle.com/jonthecollector/][Jon&lt;/a&gt; Masamitsu&amp;rsquo;s Weblog]]&lt;/li&gt;
&lt;li&gt;[[&lt;a href=&#34;http://rednaxelafx.iteye.com][Script&#34;&gt;http://rednaxelafx.iteye.com][Script&lt;/a&gt; Ahead, Code Behind]]&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;footnotes&#34;&gt;Footnotes&lt;/h1&gt;

&lt;p&gt;[fn:1] [[&lt;a href=&#34;http://www.cubrid.org/blog/dev-platform/understanding-java-garbage-collection/][Understanding&#34;&gt;http://www.cubrid.org/blog/dev-platform/understanding-java-garbage-collection/][Understanding&lt;/a&gt; Java Garbage Collection]]&lt;/p&gt;

&lt;p&gt;[fn:3] [[&lt;a href=&#34;http://www.oracle.com/technetwork/java/javase/tech/memorymanagement-whitepaper-1-150020.pdf][Memory&#34;&gt;http://www.oracle.com/technetwork/java/javase/tech/memorymanagement-whitepaper-1-150020.pdf][Memory&lt;/a&gt; Management in the Java Hotspot VM]]&lt;/p&gt;

&lt;p&gt;[fn:4] Java performance by Charlie Hunt, Binu John&lt;/p&gt;

&lt;p&gt;[fn:5] [[&lt;a href=&#34;http://blog.ragozin.info/2011/09/hotspot-jvm-garbage-collection-options.html][HotSpot&#34;&gt;http://blog.ragozin.info/2011/09/hotspot-jvm-garbage-collection-options.html][HotSpot&lt;/a&gt; JVM garbage collection options cheat sheet]]&lt;/p&gt;

&lt;p&gt;[fn:6] [[&lt;a href=&#34;https://blogs.oracle.com/jonthecollector/entry/hey_joe_phases_of_cms][The&#34;&gt;https://blogs.oracle.com/jonthecollector/entry/hey_joe_phases_of_cms][The&lt;/a&gt; Unspoken - Phases of CMS]]&lt;/p&gt;

&lt;p&gt;[fn:7] [[&lt;a href=&#34;https://blogs.oracle.com/jonthecollector/entry/the_unspoken_cms_and_printgcdetails][The&#34;&gt;https://blogs.oracle.com/jonthecollector/entry/the_unspoken_cms_and_printgcdetails][The&lt;/a&gt; Unspoken - CMS and PrintGCDetails]]&lt;/p&gt;

&lt;p&gt;[fn:8] [[&lt;a href=&#34;http://hllvm.group.iteye.com/group/topic/27945][JVM调优的&amp;quot;标准参数&amp;quot;的各种陷阱]&#34;&gt;http://hllvm.group.iteye.com/group/topic/27945][JVM调优的&amp;quot;标准参数&amp;quot;的各种陷阱]&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;[fn:2] [[&lt;a href=&#34;https://blogs.oracle.com/jonthecollector/entry/the_real_thing][The&#34;&gt;https://blogs.oracle.com/jonthecollector/entry/the_real_thing][The&lt;/a&gt; real thing]]&lt;/p&gt;

&lt;p&gt;[fn:9] [[&lt;a href=&#34;https://blog.codecentric.de/en/2012/07/useful-jvm-flags-part-3-printing-all-xx-flags-and-their-values/][Useful&#34;&gt;https://blog.codecentric.de/en/2012/07/useful-jvm-flags-part-3-printing-all-xx-flags-and-their-values/][Useful&lt;/a&gt; JVM Flags – Part 3 (Printing all XX Flags and their Values)]]&lt;/p&gt;

&lt;p&gt;[fn:10] [[&lt;a href=&#34;http://stackoverflow.com/questions/556405/what-do-real-user-and-sys-mean-in-the-output-of-time1][What&#34;&gt;http://stackoverflow.com/questions/556405/what-do-real-user-and-sys-mean-in-the-output-of-time1][What&lt;/a&gt; do &amp;lsquo;real&amp;rsquo;, &amp;lsquo;user&amp;rsquo; and &amp;lsquo;sys&amp;rsquo; mean]]&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>理解Oracle AWR报告</title>
      <link>http://tacy.github.io/post/oracle-awr/</link>
      <pubDate>Mon, 24 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>http://tacy.github.io/post/oracle-awr/</guid>
      
        <description>

&lt;h1 id=&#34;oracle-awr报告&#34;&gt;Oracle AWR报告&lt;/h1&gt;
</description>
      
    </item>
    
  </channel>
</rss>